{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, LSTM, BatchNormalization, CuDNNLSTM, CuDNNGRU, Activation, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/data.dat', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 509us/step - loss: 0.0723 - mean_squared_error: 0.0723 - val_loss: 0.1257 - val_mean_squared_error: 0.1257\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0460 - mean_squared_error: 0.0460 - val_loss: 0.1172 - val_mean_squared_error: 0.1172\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.1252 - val_mean_squared_error: 0.1252\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.1367 - val_mean_squared_error: 0.1367\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.1347 - val_mean_squared_error: 0.1347\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - ETA: 0s - loss: 0.0201 - mean_squared_error: 0.02 - 0s 29us/step - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.1353 - val_mean_squared_error: 0.1353\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.1451 - val_mean_squared_error: 0.1451\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.1358 - val_mean_squared_error: 0.1358\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.1397 - val_mean_squared_error: 0.1397\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.1253 - val_mean_squared_error: 0.1253\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.1547 - val_mean_squared_error: 0.1547\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.1173 - val_mean_squared_error: 0.1173\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.1529 - val_mean_squared_error: 0.1529\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.1355 - val_mean_squared_error: 0.1355\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.1417 - val_mean_squared_error: 0.1417\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.1540 - val_mean_squared_error: 0.1540\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.1060 - val_mean_squared_error: 0.1060\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.1915 - val_mean_squared_error: 0.1915\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.1162 - val_mean_squared_error: 0.1162\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1355 - val_mean_squared_error: 0.1355\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.1544 - val_mean_squared_error: 0.1544\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.1181 - val_mean_squared_error: 0.1181\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1690 - val_mean_squared_error: 0.1690\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.1273 - val_mean_squared_error: 0.1273\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1392 - val_mean_squared_error: 0.1392\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1413 - val_mean_squared_error: 0.1413\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1442 - val_mean_squared_error: 0.1442\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 58us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1372 - val_mean_squared_error: 0.1372\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 67us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1240 - val_mean_squared_error: 0.1240\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 58us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1701 - val_mean_squared_error: 0.1701\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 58us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1257 - val_mean_squared_error: 0.1257\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 63us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1440 - val_mean_squared_error: 0.1440\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 62us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1791 - val_mean_squared_error: 0.1791\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1296 - val_mean_squared_error: 0.1296\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1457 - val_mean_squared_error: 0.1457\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1475 - val_mean_squared_error: 0.1475\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1571 - val_mean_squared_error: 0.1571\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1392 - val_mean_squared_error: 0.1392\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1663 - val_mean_squared_error: 0.1663\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1263 - val_mean_squared_error: 0.1263\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1581 - val_mean_squared_error: 0.1581\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1641 - val_mean_squared_error: 0.1641\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1724 - val_mean_squared_error: 0.1724\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1399 - val_mean_squared_error: 0.1399\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1641 - val_mean_squared_error: 0.1641\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1990 - val_mean_squared_error: 0.1990\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1348 - val_mean_squared_error: 0.1348\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1377 - val_mean_squared_error: 0.1377\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.2289 - val_mean_squared_error: 0.2289\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 52us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1677 - val_mean_squared_error: 0.1677\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1337 - val_mean_squared_error: 0.1337\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1881 - val_mean_squared_error: 0.1881\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1802 - val_mean_squared_error: 0.1802\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1739 - val_mean_squared_error: 0.1739\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1572 - val_mean_squared_error: 0.1572\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1984 - val_mean_squared_error: 0.1984\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1918 - val_mean_squared_error: 0.1918\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1664 - val_mean_squared_error: 0.1664\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.2006 - val_mean_squared_error: 0.2006\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1756 - val_mean_squared_error: 0.1756\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1926 - val_mean_squared_error: 0.1926\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1968 - val_mean_squared_error: 0.1968\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1831 - val_mean_squared_error: 0.1831\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1965 - val_mean_squared_error: 0.1965\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.2056 - val_mean_squared_error: 0.2056\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.2026 - val_mean_squared_error: 0.2026\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.2125 - val_mean_squared_error: 0.2125\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1693 - val_mean_squared_error: 0.1693\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1986 - val_mean_squared_error: 0.1986\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1885 - val_mean_squared_error: 0.1885\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2020 - val_mean_squared_error: 0.2020\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2101 - val_mean_squared_error: 0.2101\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 26us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2093 - val_mean_squared_error: 0.2093\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2290 - val_mean_squared_error: 0.2290\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 26us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1956 - val_mean_squared_error: 0.1956\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1771 - val_mean_squared_error: 0.1771\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 26us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2266 - val_mean_squared_error: 0.2266\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2127 - val_mean_squared_error: 0.2127\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1963 - val_mean_squared_error: 0.1963\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2454 - val_mean_squared_error: 0.2454\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2546 - val_mean_squared_error: 0.2546\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2326 - val_mean_squared_error: 0.2326\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2251 - val_mean_squared_error: 0.2251\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1727 - val_mean_squared_error: 0.1727\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2244 - val_mean_squared_error: 0.2244\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2615 - val_mean_squared_error: 0.2615\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2723 - val_mean_squared_error: 0.2723\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2505 - val_mean_squared_error: 0.2505\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1957 - val_mean_squared_error: 0.1957\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2309 - val_mean_squared_error: 0.2309\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2469 - val_mean_squared_error: 0.2469\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2542 - val_mean_squared_error: 0.2542\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2470 - val_mean_squared_error: 0.2470\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2495 - val_mean_squared_error: 0.2495\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2652 - val_mean_squared_error: 0.2652\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2144 - val_mean_squared_error: 0.2144\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2120 - val_mean_squared_error: 0.2120\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2931 - val_mean_squared_error: 0.2931\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.2736 - val_mean_squared_error: 0.2736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2325 - val_mean_squared_error: 0.2325\n",
      "It has been 1.767333984375 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 546us/step - loss: 0.2881 - mean_squared_error: 0.2881 - val_loss: 0.2652 - val_mean_squared_error: 0.2652\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.1089 - mean_squared_error: 0.1089 - val_loss: 0.6478 - val_mean_squared_error: 0.6478\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0910 - mean_squared_error: 0.0910 - val_loss: 0.2429 - val_mean_squared_error: 0.2429\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0563 - mean_squared_error: 0.0563 - val_loss: 0.1313 - val_mean_squared_error: 0.1313\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0479 - mean_squared_error: 0.0479 - val_loss: 0.1314 - val_mean_squared_error: 0.1314\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0397 - mean_squared_error: 0.0397 - val_loss: 0.1332 - val_mean_squared_error: 0.1332\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.1127 - val_mean_squared_error: 0.1127\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 26us/step - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.1043 - val_mean_squared_error: 0.1043\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.1001 - val_mean_squared_error: 0.1001\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0309 - mean_squared_error: 0.0309 - val_loss: 0.0969 - val_mean_squared_error: 0.0969\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0298 - mean_squared_error: 0.0298 - val_loss: 0.0947 - val_mean_squared_error: 0.0947\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0931 - val_mean_squared_error: 0.0931\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0278 - mean_squared_error: 0.0278 - val_loss: 0.0926 - val_mean_squared_error: 0.0926\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 26us/step - loss: 0.0269 - mean_squared_error: 0.0269 - val_loss: 0.0913 - val_mean_squared_error: 0.0913\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0260 - mean_squared_error: 0.0260 - val_loss: 0.0902 - val_mean_squared_error: 0.0902\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0903 - val_mean_squared_error: 0.0903\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0892 - val_mean_squared_error: 0.0892\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0902 - val_mean_squared_error: 0.0902\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0878 - val_mean_squared_error: 0.0878\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0967 - val_mean_squared_error: 0.0967\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0917 - val_mean_squared_error: 0.0917\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0920 - val_mean_squared_error: 0.0920\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0950 - val_mean_squared_error: 0.0950\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0936 - val_mean_squared_error: 0.0936\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.1066 - val_mean_squared_error: 0.1066\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0903 - val_mean_squared_error: 0.0903\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.1060 - val_mean_squared_error: 0.1060\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.1014 - val_mean_squared_error: 0.1014\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0998 - val_mean_squared_error: 0.0998\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.1103 - val_mean_squared_error: 0.1103\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.1081 - val_mean_squared_error: 0.1081\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.1107 - val_mean_squared_error: 0.1107\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.1109 - val_mean_squared_error: 0.1109\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1111 - val_mean_squared_error: 0.1111\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.1143 - val_mean_squared_error: 0.1143\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.1215 - val_mean_squared_error: 0.1215\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.1124 - val_mean_squared_error: 0.1124\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.1274 - val_mean_squared_error: 0.1274\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1191 - val_mean_squared_error: 0.1191\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1211 - val_mean_squared_error: 0.1211\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.1368 - val_mean_squared_error: 0.1368\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.1295 - val_mean_squared_error: 0.1295\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.1380 - val_mean_squared_error: 0.1380\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.1334 - val_mean_squared_error: 0.1334\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.1406 - val_mean_squared_error: 0.1406\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 29us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1451 - val_mean_squared_error: 0.1451\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1419 - val_mean_squared_error: 0.1419\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1648 - val_mean_squared_error: 0.1648\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1525 - val_mean_squared_error: 0.1525\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.1602 - val_mean_squared_error: 0.1602\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.1592 - val_mean_squared_error: 0.1592\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1615 - val_mean_squared_error: 0.1615\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1688 - val_mean_squared_error: 0.1688\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.1621 - val_mean_squared_error: 0.1621\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1937 - val_mean_squared_error: 0.1937\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1745 - val_mean_squared_error: 0.1745\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1708 - val_mean_squared_error: 0.1708\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.1836 - val_mean_squared_error: 0.1836\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1839 - val_mean_squared_error: 0.1839\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1931 - val_mean_squared_error: 0.1931\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1903 - val_mean_squared_error: 0.1903\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1834 - val_mean_squared_error: 0.1834\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.2041 - val_mean_squared_error: 0.2041\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1840 - val_mean_squared_error: 0.1840\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.2272 - val_mean_squared_error: 0.2272\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.2043 - val_mean_squared_error: 0.2043\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.2229 - val_mean_squared_error: 0.2229\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1984 - val_mean_squared_error: 0.1984\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.2153 - val_mean_squared_error: 0.2153\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.2199 - val_mean_squared_error: 0.2199\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.2249 - val_mean_squared_error: 0.2249\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.2354 - val_mean_squared_error: 0.2354\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.2207 - val_mean_squared_error: 0.2207\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.2345 - val_mean_squared_error: 0.2345\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.2323 - val_mean_squared_error: 0.2323\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.2224 - val_mean_squared_error: 0.2224\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.2564 - val_mean_squared_error: 0.2564\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2236 - val_mean_squared_error: 0.2236\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.2513 - val_mean_squared_error: 0.2513\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.2376 - val_mean_squared_error: 0.2376\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2872 - val_mean_squared_error: 0.2872\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.2484 - val_mean_squared_error: 0.2484\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2525 - val_mean_squared_error: 0.2525\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2491 - val_mean_squared_error: 0.2491\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2991 - val_mean_squared_error: 0.2991\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2602 - val_mean_squared_error: 0.2602\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.2820 - val_mean_squared_error: 0.2820\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2760 - val_mean_squared_error: 0.2760\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2791 - val_mean_squared_error: 0.2791\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2795 - val_mean_squared_error: 0.2795\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2720 - val_mean_squared_error: 0.2720\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2867 - val_mean_squared_error: 0.2867\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2967 - val_mean_squared_error: 0.2967\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2918 - val_mean_squared_error: 0.2918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.3117 - val_mean_squared_error: 0.3117\n",
      "It has been 1.6000728607177734 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 601us/step - loss: 0.1160 - mean_squared_error: 0.1160 - val_loss: 0.1410 - val_mean_squared_error: 0.1410\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0705 - mean_squared_error: 0.0705 - val_loss: 0.2248 - val_mean_squared_error: 0.2248\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0460 - mean_squared_error: 0.0460 - val_loss: 0.3586 - val_mean_squared_error: 0.3586\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.2266 - val_mean_squared_error: 0.2266\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 26us/step - loss: 0.0283 - mean_squared_error: 0.0283 - val_loss: 0.3326 - val_mean_squared_error: 0.3326\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.2880 - val_mean_squared_error: 0.2880\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 26us/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.2985 - val_mean_squared_error: 0.2985\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.3028 - val_mean_squared_error: 0.3028\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.3041 - val_mean_squared_error: 0.3041\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.3145 - val_mean_squared_error: 0.3145\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.3317 - val_mean_squared_error: 0.3317\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.3102 - val_mean_squared_error: 0.3102\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.3373 - val_mean_squared_error: 0.3373\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.3263 - val_mean_squared_error: 0.3263\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.3578 - val_mean_squared_error: 0.3578\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.3357 - val_mean_squared_error: 0.3357\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.3809 - val_mean_squared_error: 0.3809\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.3363 - val_mean_squared_error: 0.3363\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.3728 - val_mean_squared_error: 0.3728\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.3742 - val_mean_squared_error: 0.3742\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.3548 - val_mean_squared_error: 0.3548\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.4332 - val_mean_squared_error: 0.4332\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.3654 - val_mean_squared_error: 0.3654\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.3976 - val_mean_squared_error: 0.3976\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.4318 - val_mean_squared_error: 0.4318\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.3995 - val_mean_squared_error: 0.3995\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.3979 - val_mean_squared_error: 0.3979\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.3915 - val_mean_squared_error: 0.3915\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.4325 - val_mean_squared_error: 0.4325\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.3831 - val_mean_squared_error: 0.3831\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.4650 - val_mean_squared_error: 0.4650\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.3848 - val_mean_squared_error: 0.3848\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.4349 - val_mean_squared_error: 0.4349\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.4569 - val_mean_squared_error: 0.4569\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.4684 - val_mean_squared_error: 0.4684\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.4113 - val_mean_squared_error: 0.4113\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.4507 - val_mean_squared_error: 0.4507\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 25us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.4805 - val_mean_squared_error: 0.4805\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.4454 - val_mean_squared_error: 0.4454\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.4604 - val_mean_squared_error: 0.4604\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.4185 - val_mean_squared_error: 0.4185\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.4715 - val_mean_squared_error: 0.4715\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.4674 - val_mean_squared_error: 0.4674\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.4527 - val_mean_squared_error: 0.4527\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.4573 - val_mean_squared_error: 0.4573\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.5376 - val_mean_squared_error: 0.5376\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.4232 - val_mean_squared_error: 0.4232\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.4890 - val_mean_squared_error: 0.4890\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.4973 - val_mean_squared_error: 0.4973\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 31us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.4181 - val_mean_squared_error: 0.4181\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.5494 - val_mean_squared_error: 0.5494\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.4540 - val_mean_squared_error: 0.4540\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.5080 - val_mean_squared_error: 0.5080\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.5016 - val_mean_squared_error: 0.5016\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.5039 - val_mean_squared_error: 0.5039\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.4727 - val_mean_squared_error: 0.4727\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.4549 - val_mean_squared_error: 0.4549\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.5378 - val_mean_squared_error: 0.5378\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.4585 - val_mean_squared_error: 0.4585\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.5681 - val_mean_squared_error: 0.5681\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.5193 - val_mean_squared_error: 0.5193\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.5131 - val_mean_squared_error: 0.5131\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.5333 - val_mean_squared_error: 0.5333\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.5164 - val_mean_squared_error: 0.5164\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.5907 - val_mean_squared_error: 0.5907\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.5171 - val_mean_squared_error: 0.5171\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.5299 - val_mean_squared_error: 0.5299\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.5423 - val_mean_squared_error: 0.5423\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.5246 - val_mean_squared_error: 0.5246\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.5600 - val_mean_squared_error: 0.5600\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.5392 - val_mean_squared_error: 0.5392\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.5200 - val_mean_squared_error: 0.5200\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.5067 - val_mean_squared_error: 0.5067\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.5665 - val_mean_squared_error: 0.5665\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.5476 - val_mean_squared_error: 0.5476\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 26us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.5496 - val_mean_squared_error: 0.5496\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.5284 - val_mean_squared_error: 0.5284\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.5503 - val_mean_squared_error: 0.5503\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.5827 - val_mean_squared_error: 0.5827\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.5874 - val_mean_squared_error: 0.5874\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.5528 - val_mean_squared_error: 0.5528\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.5097 - val_mean_squared_error: 0.5097\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.5942 - val_mean_squared_error: 0.5942\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.6208 - val_mean_squared_error: 0.6208\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.5184 - val_mean_squared_error: 0.5184\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.5317 - val_mean_squared_error: 0.5317\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.5539 - val_mean_squared_error: 0.5539\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.6417 - val_mean_squared_error: 0.6417\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.5725 - val_mean_squared_error: 0.5725\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.5295 - val_mean_squared_error: 0.5295\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.6249 - val_mean_squared_error: 0.6249\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.5718 - val_mean_squared_error: 0.5718\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.5377 - val_mean_squared_error: 0.5377\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.6339 - val_mean_squared_error: 0.6339\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.6085 - val_mean_squared_error: 0.6085\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.5387 - val_mean_squared_error: 0.5387\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.5741 - val_mean_squared_error: 0.5741\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.6055 - val_mean_squared_error: 0.6055\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.6214 - val_mean_squared_error: 0.6214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.6153 - val_mean_squared_error: 0.6153\n",
      "It has been 1.6204049587249756 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 671us/step - loss: 0.3830 - mean_squared_error: 0.3830 - val_loss: 0.5771 - val_mean_squared_error: 0.5771\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0629 - mean_squared_error: 0.0629 - val_loss: 0.1323 - val_mean_squared_error: 0.1323\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0693 - mean_squared_error: 0.0693 - val_loss: 0.1288 - val_mean_squared_error: 0.1288\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.1484 - val_mean_squared_error: 0.1484\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.1826 - val_mean_squared_error: 0.1826\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0294 - mean_squared_error: 0.0294 - val_loss: 0.1309 - val_mean_squared_error: 0.1309\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.1210 - val_mean_squared_error: 0.1210\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.1314 - val_mean_squared_error: 0.1314\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.1369 - val_mean_squared_error: 0.1369\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.1296 - val_mean_squared_error: 0.1296\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.1264 - val_mean_squared_error: 0.1264\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.1358 - val_mean_squared_error: 0.1358\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.1281 - val_mean_squared_error: 0.1281\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.1243 - val_mean_squared_error: 0.1243\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.1300 - val_mean_squared_error: 0.1300\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.1276 - val_mean_squared_error: 0.1276\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.1251 - val_mean_squared_error: 0.1251\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.1266 - val_mean_squared_error: 0.1266\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.1306 - val_mean_squared_error: 0.1306\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.1283 - val_mean_squared_error: 0.1283\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.1246 - val_mean_squared_error: 0.1246\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.1245 - val_mean_squared_error: 0.1245\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.1349 - val_mean_squared_error: 0.1349\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.1301 - val_mean_squared_error: 0.1301\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.1239 - val_mean_squared_error: 0.1239\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.1379 - val_mean_squared_error: 0.1379\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.1231 - val_mean_squared_error: 0.1231\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.1392 - val_mean_squared_error: 0.1392\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.1312 - val_mean_squared_error: 0.1312\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.1275 - val_mean_squared_error: 0.1275\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1461 - val_mean_squared_error: 0.1461\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.1239 - val_mean_squared_error: 0.1239\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.1385 - val_mean_squared_error: 0.1385\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.1440 - val_mean_squared_error: 0.1440\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.1224 - val_mean_squared_error: 0.1224\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.1608 - val_mean_squared_error: 0.1608\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1208 - val_mean_squared_error: 0.1208\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1415 - val_mean_squared_error: 0.1415\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.1431 - val_mean_squared_error: 0.1431\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.1368 - val_mean_squared_error: 0.1368\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.1505 - val_mean_squared_error: 0.1505\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1378 - val_mean_squared_error: 0.1378\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1598 - val_mean_squared_error: 0.1598\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1446 - val_mean_squared_error: 0.1446\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1411 - val_mean_squared_error: 0.1411\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1612 - val_mean_squared_error: 0.1612\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1390 - val_mean_squared_error: 0.1390\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.1692 - val_mean_squared_error: 0.1692\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 28us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.1450 - val_mean_squared_error: 0.1450\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1558 - val_mean_squared_error: 0.1558\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.1552 - val_mean_squared_error: 0.1552\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1646 - val_mean_squared_error: 0.1646\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1678 - val_mean_squared_error: 0.1678\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1596 - val_mean_squared_error: 0.1596\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.1570 - val_mean_squared_error: 0.1570\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1662 - val_mean_squared_error: 0.1662\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1612 - val_mean_squared_error: 0.1612\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1725 - val_mean_squared_error: 0.1725\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.1613 - val_mean_squared_error: 0.1613\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.1710 - val_mean_squared_error: 0.1710\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1733 - val_mean_squared_error: 0.1733\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1760 - val_mean_squared_error: 0.1760\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1694 - val_mean_squared_error: 0.1694\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1769 - val_mean_squared_error: 0.1769\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1877 - val_mean_squared_error: 0.1877\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1701 - val_mean_squared_error: 0.1701\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1710 - val_mean_squared_error: 0.1710\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1889 - val_mean_squared_error: 0.1889\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1925 - val_mean_squared_error: 0.1925\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1801 - val_mean_squared_error: 0.1801\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1811 - val_mean_squared_error: 0.1811\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1842 - val_mean_squared_error: 0.1842\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 26us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.2000 - val_mean_squared_error: 0.2000\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1861 - val_mean_squared_error: 0.1861\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1969 - val_mean_squared_error: 0.1969\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1946 - val_mean_squared_error: 0.1946\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1937 - val_mean_squared_error: 0.1937\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1908 - val_mean_squared_error: 0.1908\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.2022 - val_mean_squared_error: 0.2022\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.2022 - val_mean_squared_error: 0.2022\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.2013 - val_mean_squared_error: 0.2013\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.2030 - val_mean_squared_error: 0.2030\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.2064 - val_mean_squared_error: 0.2064\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2057 - val_mean_squared_error: 0.2057\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2108 - val_mean_squared_error: 0.2108\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2169 - val_mean_squared_error: 0.2169\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2108 - val_mean_squared_error: 0.2108\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2244 - val_mean_squared_error: 0.2244\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2051 - val_mean_squared_error: 0.2051\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2208 - val_mean_squared_error: 0.2208\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.2227 - val_mean_squared_error: 0.2227\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.2305 - val_mean_squared_error: 0.2305\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.2264 - val_mean_squared_error: 0.2264\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2257 - val_mean_squared_error: 0.2257\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2280 - val_mean_squared_error: 0.2280\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2370 - val_mean_squared_error: 0.2370\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2162 - val_mean_squared_error: 0.2162\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2454 - val_mean_squared_error: 0.2454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2199 - val_mean_squared_error: 0.2199\n",
      "It has been 1.6625051498413086 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 728us/step - loss: 0.0624 - mean_squared_error: 0.0624 - val_loss: 0.2912 - val_mean_squared_error: 0.2912\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.1226 - val_mean_squared_error: 0.1226\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0996 - val_mean_squared_error: 0.0996\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.1348 - val_mean_squared_error: 0.1348\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.1017 - val_mean_squared_error: 0.1017\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.1072 - val_mean_squared_error: 0.1072\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.1047 - val_mean_squared_error: 0.1047\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.1007 - val_mean_squared_error: 0.1007\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 26us/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0997 - val_mean_squared_error: 0.0997\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0970 - val_mean_squared_error: 0.0970\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0985 - val_mean_squared_error: 0.0985\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0961 - val_mean_squared_error: 0.0961\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0961 - val_mean_squared_error: 0.0961\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0949 - val_mean_squared_error: 0.0949\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0948 - val_mean_squared_error: 0.0948\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0952 - val_mean_squared_error: 0.0952\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0941 - val_mean_squared_error: 0.0941\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0935 - val_mean_squared_error: 0.0935\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0943 - val_mean_squared_error: 0.0943\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0933 - val_mean_squared_error: 0.0933\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0981 - val_mean_squared_error: 0.0981\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0933 - val_mean_squared_error: 0.0933\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0921 - val_mean_squared_error: 0.0921\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0964 - val_mean_squared_error: 0.0964\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0959 - val_mean_squared_error: 0.0959\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0910 - val_mean_squared_error: 0.0910\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.1048 - val_mean_squared_error: 0.1048\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0901 - val_mean_squared_error: 0.0901\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.1045 - val_mean_squared_error: 0.1045\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0981 - val_mean_squared_error: 0.0981\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0952 - val_mean_squared_error: 0.0952\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1017 - val_mean_squared_error: 0.1017\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0936 - val_mean_squared_error: 0.0936\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.1059 - val_mean_squared_error: 0.1059\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0973 - val_mean_squared_error: 0.0973\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1016 - val_mean_squared_error: 0.1016\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1035 - val_mean_squared_error: 0.1035\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1036 - val_mean_squared_error: 0.1036\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1138 - val_mean_squared_error: 0.1138\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1035 - val_mean_squared_error: 0.1035\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1182 - val_mean_squared_error: 0.1182\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1041 - val_mean_squared_error: 0.1041\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1109 - val_mean_squared_error: 0.1109\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1291 - val_mean_squared_error: 0.1291\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1090 - val_mean_squared_error: 0.1090\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1191 - val_mean_squared_error: 0.1191\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1166 - val_mean_squared_error: 0.1166\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 29us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1168 - val_mean_squared_error: 0.1168\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1133 - val_mean_squared_error: 0.1133\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1258 - val_mean_squared_error: 0.1258\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1260 - val_mean_squared_error: 0.1260\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1249 - val_mean_squared_error: 0.1249\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1270 - val_mean_squared_error: 0.1270\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1290 - val_mean_squared_error: 0.1290\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1480 - val_mean_squared_error: 0.1480\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1209 - val_mean_squared_error: 0.1209\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1401 - val_mean_squared_error: 0.1401\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1399 - val_mean_squared_error: 0.1399\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1392 - val_mean_squared_error: 0.1392\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1438 - val_mean_squared_error: 0.1438\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1321 - val_mean_squared_error: 0.1321\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1477 - val_mean_squared_error: 0.1477\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1646 - val_mean_squared_error: 0.1646\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1350 - val_mean_squared_error: 0.1350\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1458 - val_mean_squared_error: 0.1458\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1576 - val_mean_squared_error: 0.1576\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1472 - val_mean_squared_error: 0.1472\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1830 - val_mean_squared_error: 0.1830\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1764 - val_mean_squared_error: 0.1764\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1451 - val_mean_squared_error: 0.1451\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1557 - val_mean_squared_error: 0.1557\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1803 - val_mean_squared_error: 0.1803\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1854 - val_mean_squared_error: 0.1854\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1657 - val_mean_squared_error: 0.1657\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1504 - val_mean_squared_error: 0.1504\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1692 - val_mean_squared_error: 0.1692\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1982 - val_mean_squared_error: 0.1982\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1616 - val_mean_squared_error: 0.1616\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1916 - val_mean_squared_error: 0.1916\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1814 - val_mean_squared_error: 0.1814\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1983 - val_mean_squared_error: 0.1983\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1734 - val_mean_squared_error: 0.1734\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1876 - val_mean_squared_error: 0.1876\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2222 - val_mean_squared_error: 0.2222\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1734 - val_mean_squared_error: 0.1734\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2058 - val_mean_squared_error: 0.2058\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2116 - val_mean_squared_error: 0.2116\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2231 - val_mean_squared_error: 0.2231\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1934 - val_mean_squared_error: 0.1934\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2099 - val_mean_squared_error: 0.2099\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2105 - val_mean_squared_error: 0.2105\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2387 - val_mean_squared_error: 0.2387\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2069 - val_mean_squared_error: 0.2069\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1942 - val_mean_squared_error: 0.1942\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2191 - val_mean_squared_error: 0.2191\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2653 - val_mean_squared_error: 0.2653\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.00 - 0s 33us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2294 - val_mean_squared_error: 0.2294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2208 - val_mean_squared_error: 0.2208\n",
      "It has been 1.711219072341919 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 779us/step - loss: 0.0635 - mean_squared_error: 0.0635 - val_loss: 0.1525 - val_mean_squared_error: 0.1525\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.1070 - val_mean_squared_error: 0.1070\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0297 - mean_squared_error: 0.0297 - val_loss: 0.0916 - val_mean_squared_error: 0.0916\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0964 - val_mean_squared_error: 0.0964\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0820 - val_mean_squared_error: 0.0820\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0898 - val_mean_squared_error: 0.0898\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.0746 - val_mean_squared_error: 0.0746\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0837 - val_mean_squared_error: 0.0837\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0749 - val_mean_squared_error: 0.0749\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0764 - val_mean_squared_error: 0.0764\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0759 - val_mean_squared_error: 0.0759\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0743 - val_mean_squared_error: 0.0743\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0743 - val_mean_squared_error: 0.0743\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0760 - val_mean_squared_error: 0.0760\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0778 - val_mean_squared_error: 0.0778\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0712 - val_mean_squared_error: 0.0712\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0706 - val_mean_squared_error: 0.0706\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0807 - val_mean_squared_error: 0.0807\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0691 - val_mean_squared_error: 0.0691\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0717 - val_mean_squared_error: 0.0717\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0756 - val_mean_squared_error: 0.0756\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0724 - val_mean_squared_error: 0.0724\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0708 - val_mean_squared_error: 0.0708\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0775 - val_mean_squared_error: 0.0775\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0683 - val_mean_squared_error: 0.0683\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0659 - val_mean_squared_error: 0.0659\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0866 - val_mean_squared_error: 0.0866\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0671 - val_mean_squared_error: 0.0671\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0718 - val_mean_squared_error: 0.0718\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0724 - val_mean_squared_error: 0.0724\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0677 - val_mean_squared_error: 0.0677\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0776 - val_mean_squared_error: 0.0776\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0724 - val_mean_squared_error: 0.0724\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0940 - val_mean_squared_error: 0.0940\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0669 - val_mean_squared_error: 0.0669\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0708 - val_mean_squared_error: 0.0708\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0872 - val_mean_squared_error: 0.0872\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0756 - val_mean_squared_error: 0.0756\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0660 - val_mean_squared_error: 0.0660\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0887 - val_mean_squared_error: 0.0887\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0739 - val_mean_squared_error: 0.0739\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0677 - val_mean_squared_error: 0.0677\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0697 - val_mean_squared_error: 0.0697\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0935 - val_mean_squared_error: 0.0935\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0847 - val_mean_squared_error: 0.0847\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0759 - val_mean_squared_error: 0.0759\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 31us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0770 - val_mean_squared_error: 0.0770\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0988 - val_mean_squared_error: 0.0988\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0744 - val_mean_squared_error: 0.0744\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1001 - val_mean_squared_error: 0.1001\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0991 - val_mean_squared_error: 0.0991\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0840 - val_mean_squared_error: 0.0840\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0800 - val_mean_squared_error: 0.0800\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0894 - val_mean_squared_error: 0.0894\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0866 - val_mean_squared_error: 0.0866\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0920 - val_mean_squared_error: 0.0920\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0909 - val_mean_squared_error: 0.0909\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0728 - val_mean_squared_error: 0.0728\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0750 - val_mean_squared_error: 0.0750\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1009 - val_mean_squared_error: 0.1009\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0937 - val_mean_squared_error: 0.0937\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0783 - val_mean_squared_error: 0.0783\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0939 - val_mean_squared_error: 0.0939\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0925 - val_mean_squared_error: 0.0925\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0962 - val_mean_squared_error: 0.0962\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1039 - val_mean_squared_error: 0.1039\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0983 - val_mean_squared_error: 0.0983\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0773 - val_mean_squared_error: 0.0773\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1056 - val_mean_squared_error: 0.1056\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1045 - val_mean_squared_error: 0.1045\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0769 - val_mean_squared_error: 0.0769\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1049 - val_mean_squared_error: 0.1049\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0999 - val_mean_squared_error: 0.0999\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0957 - val_mean_squared_error: 0.0957\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1069 - val_mean_squared_error: 0.1069\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0899 - val_mean_squared_error: 0.0899\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0883 - val_mean_squared_error: 0.0883\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1105 - val_mean_squared_error: 0.1105\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1036 - val_mean_squared_error: 0.1036\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0956 - val_mean_squared_error: 0.0956\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0988 - val_mean_squared_error: 0.0988\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1123 - val_mean_squared_error: 0.1123\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1093 - val_mean_squared_error: 0.1093\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0910 - val_mean_squared_error: 0.0910\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0841 - val_mean_squared_error: 0.0841\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1168 - val_mean_squared_error: 0.1168\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1148 - val_mean_squared_error: 0.1148\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1177 - val_mean_squared_error: 0.1177\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.1070 - val_mean_squared_error: 0.1070\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0986 - val_mean_squared_error: 0.0986\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.1200 - val_mean_squared_error: 0.1200\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1004 - val_mean_squared_error: 0.1004\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.1014 - val_mean_squared_error: 0.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1002 - val_mean_squared_error: 0.1002\n",
      "It has been 1.7610259056091309 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 859us/step - loss: 0.1229 - mean_squared_error: 0.1229 - val_loss: 0.3804 - val_mean_squared_error: 0.3804\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0650 - mean_squared_error: 0.0650 - val_loss: 0.2062 - val_mean_squared_error: 0.2062\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.1690 - val_mean_squared_error: 0.1690\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.1499 - val_mean_squared_error: 0.1499\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.1497 - val_mean_squared_error: 0.1497\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.1536 - val_mean_squared_error: 0.1536\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.1356 - val_mean_squared_error: 0.1356\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.1653 - val_mean_squared_error: 0.1653\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.1400 - val_mean_squared_error: 0.1400\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.1391 - val_mean_squared_error: 0.1391\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.1363 - val_mean_squared_error: 0.1363\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.1219 - val_mean_squared_error: 0.1219\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.1444 - val_mean_squared_error: 0.1444\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.1263 - val_mean_squared_error: 0.1263\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.1134 - val_mean_squared_error: 0.1134\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.1240 - val_mean_squared_error: 0.1240\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1134 - val_mean_squared_error: 0.1134\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.1290 - val_mean_squared_error: 0.1290\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.1010 - val_mean_squared_error: 0.1010\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.1163 - val_mean_squared_error: 0.1163\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.1003 - val_mean_squared_error: 0.1003\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0987 - val_mean_squared_error: 0.0987\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1046 - val_mean_squared_error: 0.1046\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0948 - val_mean_squared_error: 0.0948\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0978 - val_mean_squared_error: 0.0978\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0900 - val_mean_squared_error: 0.0900\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0914 - val_mean_squared_error: 0.0914\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0858 - val_mean_squared_error: 0.0858\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0898 - val_mean_squared_error: 0.0898\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0876 - val_mean_squared_error: 0.0876\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0854 - val_mean_squared_error: 0.0854\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0804 - val_mean_squared_error: 0.0804\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0810 - val_mean_squared_error: 0.0810\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0798 - val_mean_squared_error: 0.0798\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0837 - val_mean_squared_error: 0.0837\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0776 - val_mean_squared_error: 0.0776\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0779 - val_mean_squared_error: 0.0779\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0773 - val_mean_squared_error: 0.0773\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0754 - val_mean_squared_error: 0.0754\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0789 - val_mean_squared_error: 0.0789\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0767 - val_mean_squared_error: 0.0767\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0758 - val_mean_squared_error: 0.0758\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0743 - val_mean_squared_error: 0.0743\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0733 - val_mean_squared_error: 0.0733\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0761 - val_mean_squared_error: 0.0761\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0730 - val_mean_squared_error: 0.0730\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0743 - val_mean_squared_error: 0.0743\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0755 - val_mean_squared_error: 0.0755\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 33us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0720 - val_mean_squared_error: 0.0720\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0713 - val_mean_squared_error: 0.0713\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0747 - val_mean_squared_error: 0.0747\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0751 - val_mean_squared_error: 0.0751\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0708 - val_mean_squared_error: 0.0708\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0708 - val_mean_squared_error: 0.0708\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0809 - val_mean_squared_error: 0.0809\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0693 - val_mean_squared_error: 0.0693\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0726 - val_mean_squared_error: 0.0726\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0751 - val_mean_squared_error: 0.0751\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0758 - val_mean_squared_error: 0.0758\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0719 - val_mean_squared_error: 0.0719\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0721 - val_mean_squared_error: 0.0721\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0724 - val_mean_squared_error: 0.0724\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0854 - val_mean_squared_error: 0.0854\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0786 - val_mean_squared_error: 0.0786\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0754 - val_mean_squared_error: 0.0754\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0773 - val_mean_squared_error: 0.0773\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0762 - val_mean_squared_error: 0.0762\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0808 - val_mean_squared_error: 0.0808\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0852 - val_mean_squared_error: 0.0852\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0739 - val_mean_squared_error: 0.0739\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0731 - val_mean_squared_error: 0.0731\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0817 - val_mean_squared_error: 0.0817\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0781 - val_mean_squared_error: 0.0781\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0743 - val_mean_squared_error: 0.0743\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0916 - val_mean_squared_error: 0.0916\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0857 - val_mean_squared_error: 0.0857\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0822 - val_mean_squared_error: 0.0822\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0831 - val_mean_squared_error: 0.0831\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0839 - val_mean_squared_error: 0.0839\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1018 - val_mean_squared_error: 0.1018\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0871 - val_mean_squared_error: 0.0871\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0944 - val_mean_squared_error: 0.0944\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0834 - val_mean_squared_error: 0.0834\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0846 - val_mean_squared_error: 0.0846\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0992 - val_mean_squared_error: 0.0992\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0970 - val_mean_squared_error: 0.0970\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0909 - val_mean_squared_error: 0.0909\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0929 - val_mean_squared_error: 0.0929\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0951 - val_mean_squared_error: 0.0951\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1083 - val_mean_squared_error: 0.1083\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0971 - val_mean_squared_error: 0.0971\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0937 - val_mean_squared_error: 0.0937\n",
      "It has been 1.8373682498931885 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 1000us/step - loss: 0.1336 - mean_squared_error: 0.1336 - val_loss: 0.4699 - val_mean_squared_error: 0.4699\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0832 - mean_squared_error: 0.0832 - val_loss: 0.4157 - val_mean_squared_error: 0.4157\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0539 - mean_squared_error: 0.0539 - val_loss: 0.1585 - val_mean_squared_error: 0.1585\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0472 - mean_squared_error: 0.0472 - val_loss: 0.1878 - val_mean_squared_error: 0.1878\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.2034 - val_mean_squared_error: 0.2034\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.1592 - val_mean_squared_error: 0.1592\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.1661 - val_mean_squared_error: 0.1661\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.1629 - val_mean_squared_error: 0.1629\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.1587 - val_mean_squared_error: 0.1587\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.1482 - val_mean_squared_error: 0.1482\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.1503 - val_mean_squared_error: 0.1503\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.1465 - val_mean_squared_error: 0.1465\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.1435 - val_mean_squared_error: 0.1435\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.1407 - val_mean_squared_error: 0.1407\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.1367 - val_mean_squared_error: 0.1367\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.1342 - val_mean_squared_error: 0.1342\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.1308 - val_mean_squared_error: 0.1308\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.1290 - val_mean_squared_error: 0.1290\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.1268 - val_mean_squared_error: 0.1268\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1238 - val_mean_squared_error: 0.1238\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.1218 - val_mean_squared_error: 0.1218\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.1205 - val_mean_squared_error: 0.1205\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.1170 - val_mean_squared_error: 0.1170\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1150 - val_mean_squared_error: 0.1150\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.1123 - val_mean_squared_error: 0.1123\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.1120 - val_mean_squared_error: 0.1120\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.1096 - val_mean_squared_error: 0.1096\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1091 - val_mean_squared_error: 0.1091\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1056 - val_mean_squared_error: 0.1056\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.1063 - val_mean_squared_error: 0.1063\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.1035 - val_mean_squared_error: 0.1035\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.1015 - val_mean_squared_error: 0.1015\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.1003 - val_mean_squared_error: 0.1003\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0987 - val_mean_squared_error: 0.0987\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1006 - val_mean_squared_error: 0.1006\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0952 - val_mean_squared_error: 0.0952\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0973 - val_mean_squared_error: 0.0973\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0919 - val_mean_squared_error: 0.0919\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0972 - val_mean_squared_error: 0.0972\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0963 - val_mean_squared_error: 0.0963\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0918 - val_mean_squared_error: 0.0918\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0936 - val_mean_squared_error: 0.0936\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0909 - val_mean_squared_error: 0.0909\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0924 - val_mean_squared_error: 0.0924\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0935 - val_mean_squared_error: 0.0935\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0839 - val_mean_squared_error: 0.0839\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0965 - val_mean_squared_error: 0.0965\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0907 - val_mean_squared_error: 0.0907\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0872 - val_mean_squared_error: 0.0872\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 31us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0930 - val_mean_squared_error: 0.0930\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0882 - val_mean_squared_error: 0.0882\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0897 - val_mean_squared_error: 0.0897\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0894 - val_mean_squared_error: 0.0894\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0883 - val_mean_squared_error: 0.0883\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0869 - val_mean_squared_error: 0.0869\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0944 - val_mean_squared_error: 0.0944\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0840 - val_mean_squared_error: 0.0840\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1037 - val_mean_squared_error: 0.1037\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0899 - val_mean_squared_error: 0.0899\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0876 - val_mean_squared_error: 0.0876\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0858 - val_mean_squared_error: 0.0858\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0931 - val_mean_squared_error: 0.0931\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0852 - val_mean_squared_error: 0.0852\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1006 - val_mean_squared_error: 0.1006\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0803 - val_mean_squared_error: 0.0803\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0971 - val_mean_squared_error: 0.0971\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0925 - val_mean_squared_error: 0.0925\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0912 - val_mean_squared_error: 0.0912\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1011 - val_mean_squared_error: 0.1011\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0880 - val_mean_squared_error: 0.0880\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1078 - val_mean_squared_error: 0.1078\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0973 - val_mean_squared_error: 0.0973\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0888 - val_mean_squared_error: 0.0888\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0967 - val_mean_squared_error: 0.0967\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0956 - val_mean_squared_error: 0.0956\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1092 - val_mean_squared_error: 0.1092\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0886 - val_mean_squared_error: 0.0886\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1121 - val_mean_squared_error: 0.1121\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0973 - val_mean_squared_error: 0.0973\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1012 - val_mean_squared_error: 0.1012\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0997 - val_mean_squared_error: 0.0997\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1082 - val_mean_squared_error: 0.1082\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0976 - val_mean_squared_error: 0.0976\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1090 - val_mean_squared_error: 0.1090\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1008 - val_mean_squared_error: 0.1008\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1116 - val_mean_squared_error: 0.1116\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1134 - val_mean_squared_error: 0.1134\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1171 - val_mean_squared_error: 0.1171\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1038 - val_mean_squared_error: 0.1038\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0969 - val_mean_squared_error: 0.0969\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1222 - val_mean_squared_error: 0.1222\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1217 - val_mean_squared_error: 0.1217\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1251 - val_mean_squared_error: 0.1251\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1190 - val_mean_squared_error: 0.1190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "It has been 1.9341950416564941 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 1000us/step - loss: 0.0689 - mean_squared_error: 0.0689 - val_loss: 0.1583 - val_mean_squared_error: 0.1583\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.1850 - val_mean_squared_error: 0.1850\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.1943 - val_mean_squared_error: 0.1943\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.1641 - val_mean_squared_error: 0.1641\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.1518 - val_mean_squared_error: 0.1518\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.1430 - val_mean_squared_error: 0.1430\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.1474 - val_mean_squared_error: 0.1474\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.1400 - val_mean_squared_error: 0.1400\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.1377 - val_mean_squared_error: 0.1377\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.1378 - val_mean_squared_error: 0.1378\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.1311 - val_mean_squared_error: 0.1311\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.1389 - val_mean_squared_error: 0.1389\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.1227 - val_mean_squared_error: 0.1227\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.1243 - val_mean_squared_error: 0.1243\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.1271 - val_mean_squared_error: 0.1271\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.1393 - val_mean_squared_error: 0.1393\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.1376 - val_mean_squared_error: 0.1376\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.1237 - val_mean_squared_error: 0.1237\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.1184 - val_mean_squared_error: 0.1184\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1178 - val_mean_squared_error: 0.1178\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.1248 - val_mean_squared_error: 0.1248\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.1239 - val_mean_squared_error: 0.1239\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1243 - val_mean_squared_error: 0.1243\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1239 - val_mean_squared_error: 0.1239\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1196 - val_mean_squared_error: 0.1196\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1476 - val_mean_squared_error: 0.1476\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1387 - val_mean_squared_error: 0.1387\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.1066 - val_mean_squared_error: 0.1066\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.1327 - val_mean_squared_error: 0.1327\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1265 - val_mean_squared_error: 0.1265\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1459 - val_mean_squared_error: 0.1459\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.1248 - val_mean_squared_error: 0.1248\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1285 - val_mean_squared_error: 0.1285\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1375 - val_mean_squared_error: 0.1375\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1724 - val_mean_squared_error: 0.1724\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1292 - val_mean_squared_error: 0.1292\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1325 - val_mean_squared_error: 0.1325\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1465 - val_mean_squared_error: 0.1465\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1443 - val_mean_squared_error: 0.1443\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1402 - val_mean_squared_error: 0.1402\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1579 - val_mean_squared_error: 0.1579\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1547 - val_mean_squared_error: 0.1547\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1302 - val_mean_squared_error: 0.1302\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1902 - val_mean_squared_error: 0.1902\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1489 - val_mean_squared_error: 0.1489\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1432 - val_mean_squared_error: 0.1432\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.2154 - val_mean_squared_error: 0.2154\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1654 - val_mean_squared_error: 0.1654\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 30us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1514 - val_mean_squared_error: 0.1514\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1782 - val_mean_squared_error: 0.1782\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1793 - val_mean_squared_error: 0.1793\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1879 - val_mean_squared_error: 0.1879\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2013 - val_mean_squared_error: 0.2013\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2047 - val_mean_squared_error: 0.2047\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1836 - val_mean_squared_error: 0.1836\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2086 - val_mean_squared_error: 0.2086\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2318 - val_mean_squared_error: 0.2318\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1638 - val_mean_squared_error: 0.1638\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.2075 - val_mean_squared_error: 0.2075\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2151 - val_mean_squared_error: 0.2151\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 27us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2357 - val_mean_squared_error: 0.2357\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.2218 - val_mean_squared_error: 0.2218\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2141 - val_mean_squared_error: 0.2141\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2383 - val_mean_squared_error: 0.2383\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2593 - val_mean_squared_error: 0.2593\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2324 - val_mean_squared_error: 0.2324\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.2003 - val_mean_squared_error: 0.2003\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2237 - val_mean_squared_error: 0.2237\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2383 - val_mean_squared_error: 0.2383\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2275 - val_mean_squared_error: 0.2275\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2348 - val_mean_squared_error: 0.2348\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2833 - val_mean_squared_error: 0.2833\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2526 - val_mean_squared_error: 0.2526\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2478 - val_mean_squared_error: 0.2478\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2634 - val_mean_squared_error: 0.2634\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2961 - val_mean_squared_error: 0.2961\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2965 - val_mean_squared_error: 0.2965\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2335 - val_mean_squared_error: 0.2335\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2754 - val_mean_squared_error: 0.2754\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2926 - val_mean_squared_error: 0.2926\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2868 - val_mean_squared_error: 0.2868\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2675 - val_mean_squared_error: 0.2675\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2297 - val_mean_squared_error: 0.2297\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2822 - val_mean_squared_error: 0.2822\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.3090 - val_mean_squared_error: 0.3090\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3172 - val_mean_squared_error: 0.3172\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.2874 - val_mean_squared_error: 0.2874\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2970 - val_mean_squared_error: 0.2970\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.3309 - val_mean_squared_error: 0.3309\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.3173 - val_mean_squared_error: 0.3173\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2967 - val_mean_squared_error: 0.2967\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2873 - val_mean_squared_error: 0.2873\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.3164 - val_mean_squared_error: 0.3164\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3833 - val_mean_squared_error: 0.3833\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.3860 - val_mean_squared_error: 0.3860\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.3169 - val_mean_squared_error: 0.3169\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2962 - val_mean_squared_error: 0.2962\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.3030 - val_mean_squared_error: 0.3030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.3808 - val_mean_squared_error: 0.3808\n",
      "It has been 1.9061949253082275 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 1ms/step - loss: 0.1276 - mean_squared_error: 0.1276 - val_loss: 0.2527 - val_mean_squared_error: 0.2527\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0687 - mean_squared_error: 0.0687 - val_loss: 0.3247 - val_mean_squared_error: 0.3247\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0451 - mean_squared_error: 0.0451 - val_loss: 0.1243 - val_mean_squared_error: 0.1243\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.1262 - val_mean_squared_error: 0.1262\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0285 - mean_squared_error: 0.0285 - val_loss: 0.1252 - val_mean_squared_error: 0.1252\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.1246 - val_mean_squared_error: 0.1246\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.1238 - val_mean_squared_error: 0.1238\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.1230 - val_mean_squared_error: 0.1230\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.1224 - val_mean_squared_error: 0.1224\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.1212 - val_mean_squared_error: 0.1212\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.1205 - val_mean_squared_error: 0.1205\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.1200 - val_mean_squared_error: 0.1200\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.1205 - val_mean_squared_error: 0.1205\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.1189 - val_mean_squared_error: 0.1189\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.1172 - val_mean_squared_error: 0.1172\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.1205 - val_mean_squared_error: 0.1205\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.1159 - val_mean_squared_error: 0.1159\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.1202 - val_mean_squared_error: 0.1202\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.1134 - val_mean_squared_error: 0.1134\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.1175 - val_mean_squared_error: 0.1175\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1150 - val_mean_squared_error: 0.1150\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.1120 - val_mean_squared_error: 0.1120\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1143 - val_mean_squared_error: 0.1143\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.1118 - val_mean_squared_error: 0.1118\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.1146 - val_mean_squared_error: 0.1146\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.1118 - val_mean_squared_error: 0.1118\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1139 - val_mean_squared_error: 0.1139\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.1060 - val_mean_squared_error: 0.1060\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.1156 - val_mean_squared_error: 0.1156\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.1091 - val_mean_squared_error: 0.1091\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.1123 - val_mean_squared_error: 0.1123\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.1048 - val_mean_squared_error: 0.1048\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1055 - val_mean_squared_error: 0.1055\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1107 - val_mean_squared_error: 0.1107\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.1101 - val_mean_squared_error: 0.1101\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1057 - val_mean_squared_error: 0.1057\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.1052 - val_mean_squared_error: 0.1052\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1115 - val_mean_squared_error: 0.1115\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1001 - val_mean_squared_error: 0.1001\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.1106 - val_mean_squared_error: 0.1106\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0975 - val_mean_squared_error: 0.0975\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.1081 - val_mean_squared_error: 0.1081\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1077 - val_mean_squared_error: 0.1077\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1110 - val_mean_squared_error: 0.1110\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1053 - val_mean_squared_error: 0.1053\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1106 - val_mean_squared_error: 0.1106\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 32us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.1064 - val_mean_squared_error: 0.1064\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1069 - val_mean_squared_error: 0.1069\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1141 - val_mean_squared_error: 0.1141\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0972 - val_mean_squared_error: 0.0972\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1160 - val_mean_squared_error: 0.1160\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1084 - val_mean_squared_error: 0.1084\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1085 - val_mean_squared_error: 0.1085\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1037 - val_mean_squared_error: 0.1037\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1139 - val_mean_squared_error: 0.1139\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1145 - val_mean_squared_error: 0.1145\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1100 - val_mean_squared_error: 0.1100\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1061 - val_mean_squared_error: 0.1061\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1248 - val_mean_squared_error: 0.1248\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0937 - val_mean_squared_error: 0.0937\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1331 - val_mean_squared_error: 0.1331\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1121 - val_mean_squared_error: 0.1121\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1134 - val_mean_squared_error: 0.1134\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1170 - val_mean_squared_error: 0.1170\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0979 - val_mean_squared_error: 0.0979\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1479 - val_mean_squared_error: 0.1479\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0985 - val_mean_squared_error: 0.0985\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1113 - val_mean_squared_error: 0.1113\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1228 - val_mean_squared_error: 0.1228\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1105 - val_mean_squared_error: 0.1105\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1168 - val_mean_squared_error: 0.1168\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1391 - val_mean_squared_error: 0.1391\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1056 - val_mean_squared_error: 0.1056\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1266 - val_mean_squared_error: 0.1266\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1234 - val_mean_squared_error: 0.1234\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1348 - val_mean_squared_error: 0.1348\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1016 - val_mean_squared_error: 0.1016\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1384 - val_mean_squared_error: 0.1384\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1182 - val_mean_squared_error: 0.1182\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1243 - val_mean_squared_error: 0.1243\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1271 - val_mean_squared_error: 0.1271\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1076 - val_mean_squared_error: 0.1076\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1412 - val_mean_squared_error: 0.1412\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1264 - val_mean_squared_error: 0.1264\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1170 - val_mean_squared_error: 0.1170\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1506 - val_mean_squared_error: 0.1506\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1283 - val_mean_squared_error: 0.1283\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1350 - val_mean_squared_error: 0.1350\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1358 - val_mean_squared_error: 0.1358\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1467 - val_mean_squared_error: 0.1467\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1171 - val_mean_squared_error: 0.1171\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1638 - val_mean_squared_error: 0.1638\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1262 - val_mean_squared_error: 0.1262\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1502 - val_mean_squared_error: 0.1502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1482 - val_mean_squared_error: 0.1482\n",
      "It has been 2.0034098625183105 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 1ms/step - loss: 0.3573 - mean_squared_error: 0.3573 - val_loss: 0.1711 - val_mean_squared_error: 0.1711\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.1302 - mean_squared_error: 0.1302 - val_loss: 0.6498 - val_mean_squared_error: 0.6498\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.1114 - mean_squared_error: 0.1114 - val_loss: 0.2840 - val_mean_squared_error: 0.2840\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0689 - mean_squared_error: 0.0689 - val_loss: 0.1282 - val_mean_squared_error: 0.1282\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0603 - mean_squared_error: 0.0603 - val_loss: 0.1309 - val_mean_squared_error: 0.1309\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0508 - mean_squared_error: 0.0508 - val_loss: 0.1633 - val_mean_squared_error: 0.1633\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0453 - mean_squared_error: 0.0453 - val_loss: 0.1411 - val_mean_squared_error: 0.1411\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.1375 - val_mean_squared_error: 0.1375\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.1278 - val_mean_squared_error: 0.1278\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.1422 - val_mean_squared_error: 0.1422\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0306 - mean_squared_error: 0.0306 - val_loss: 0.1309 - val_mean_squared_error: 0.1309\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0285 - mean_squared_error: 0.0285 - val_loss: 0.1323 - val_mean_squared_error: 0.1323\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.1317 - val_mean_squared_error: 0.1317\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.1281 - val_mean_squared_error: 0.1281\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.1307 - val_mean_squared_error: 0.1307\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.1215 - val_mean_squared_error: 0.1215\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.1220 - val_mean_squared_error: 0.1220\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.1201 - val_mean_squared_error: 0.1201\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.1182 - val_mean_squared_error: 0.1182\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.1145 - val_mean_squared_error: 0.1145\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.1135 - val_mean_squared_error: 0.1135\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.1147 - val_mean_squared_error: 0.1147\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.1074 - val_mean_squared_error: 0.1074\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.1102 - val_mean_squared_error: 0.1102\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.1051 - val_mean_squared_error: 0.1051\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.1039 - val_mean_squared_error: 0.1039\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.1018 - val_mean_squared_error: 0.1018\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0990 - val_mean_squared_error: 0.0990\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.1006 - val_mean_squared_error: 0.1006\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0963 - val_mean_squared_error: 0.0963\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0952 - val_mean_squared_error: 0.0952\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0933 - val_mean_squared_error: 0.0933\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0924 - val_mean_squared_error: 0.0924\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0907 - val_mean_squared_error: 0.0907\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0886 - val_mean_squared_error: 0.0886\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0875 - val_mean_squared_error: 0.0875\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0846 - val_mean_squared_error: 0.0846\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0856 - val_mean_squared_error: 0.0856\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0829 - val_mean_squared_error: 0.0829\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0842 - val_mean_squared_error: 0.0842\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0817 - val_mean_squared_error: 0.0817\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0839 - val_mean_squared_error: 0.0839\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0808 - val_mean_squared_error: 0.0808\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0847 - val_mean_squared_error: 0.0847\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0795 - val_mean_squared_error: 0.0795\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 33us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0815 - val_mean_squared_error: 0.0815\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0805 - val_mean_squared_error: 0.0805\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0797 - val_mean_squared_error: 0.0797\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0783 - val_mean_squared_error: 0.0783\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0825 - val_mean_squared_error: 0.0825\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0816 - val_mean_squared_error: 0.0816\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0791 - val_mean_squared_error: 0.0791\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0848 - val_mean_squared_error: 0.0848\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0818 - val_mean_squared_error: 0.0818\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0829 - val_mean_squared_error: 0.0829\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0814 - val_mean_squared_error: 0.0814\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0806 - val_mean_squared_error: 0.0806\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0826 - val_mean_squared_error: 0.0826\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0813 - val_mean_squared_error: 0.0813\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0912 - val_mean_squared_error: 0.0912\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0799 - val_mean_squared_error: 0.0799\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0899 - val_mean_squared_error: 0.0899\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0880 - val_mean_squared_error: 0.0880\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0948 - val_mean_squared_error: 0.0948\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0953 - val_mean_squared_error: 0.0953\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0858 - val_mean_squared_error: 0.0858\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0996 - val_mean_squared_error: 0.0996\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 28us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0909 - val_mean_squared_error: 0.0909\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1018 - val_mean_squared_error: 0.1018\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0979 - val_mean_squared_error: 0.0979\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0901 - val_mean_squared_error: 0.0901\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1013 - val_mean_squared_error: 0.1013\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0949 - val_mean_squared_error: 0.0949\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1135 - val_mean_squared_error: 0.1135\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0911 - val_mean_squared_error: 0.0911\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1054 - val_mean_squared_error: 0.1054\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1041 - val_mean_squared_error: 0.1041\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1086 - val_mean_squared_error: 0.1086\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1081 - val_mean_squared_error: 0.1081\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1100 - val_mean_squared_error: 0.1100\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1213 - val_mean_squared_error: 0.1213\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0972 - val_mean_squared_error: 0.0972\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - ETA: 0s - loss: 0.0075 - mean_squared_error: 0.00 - 0s 34us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1207 - val_mean_squared_error: 0.1207\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1309 - val_mean_squared_error: 0.1309\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1125 - val_mean_squared_error: 0.1125\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1205 - val_mean_squared_error: 0.1205\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1104 - val_mean_squared_error: 0.1104\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1381 - val_mean_squared_error: 0.1381\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1199 - val_mean_squared_error: 0.1199\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1297 - val_mean_squared_error: 0.1297\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 32us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1364 - val_mean_squared_error: 0.1364\n",
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1176 - val_mean_squared_error: 0.1176\n",
      "It has been 2.0840649604797363 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 1ms/step - loss: 0.2500 - mean_squared_error: 0.2500 - val_loss: 0.8169 - val_mean_squared_error: 0.8169\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.1373 - mean_squared_error: 0.1373 - val_loss: 0.6902 - val_mean_squared_error: 0.6902\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0827 - mean_squared_error: 0.0827 - val_loss: 0.2860 - val_mean_squared_error: 0.2860\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0580 - mean_squared_error: 0.0580 - val_loss: 0.2170 - val_mean_squared_error: 0.2170\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0420 - mean_squared_error: 0.0420 - val_loss: 0.2533 - val_mean_squared_error: 0.2533\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.2046 - val_mean_squared_error: 0.2046\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.1946 - val_mean_squared_error: 0.1946\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.1941 - val_mean_squared_error: 0.1941\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0261 - mean_squared_error: 0.0261 - val_loss: 0.1892 - val_mean_squared_error: 0.1892\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.1622 - val_mean_squared_error: 0.1622\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.1904 - val_mean_squared_error: 0.1904\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.1716 - val_mean_squared_error: 0.1716\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.1681 - val_mean_squared_error: 0.1681\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.1730 - val_mean_squared_error: 0.1730\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.1531 - val_mean_squared_error: 0.1531\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.1645 - val_mean_squared_error: 0.1645\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.1526 - val_mean_squared_error: 0.1526\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.1478 - val_mean_squared_error: 0.1478\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.1441 - val_mean_squared_error: 0.1441\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.1455 - val_mean_squared_error: 0.1455\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.1379 - val_mean_squared_error: 0.1379\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.1284 - val_mean_squared_error: 0.1284\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.1380 - val_mean_squared_error: 0.1380\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.1214 - val_mean_squared_error: 0.1214\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.1244 - val_mean_squared_error: 0.1244\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.1212 - val_mean_squared_error: 0.1212\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.1189 - val_mean_squared_error: 0.1189\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.1114 - val_mean_squared_error: 0.1114\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.1123 - val_mean_squared_error: 0.1123\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.1075 - val_mean_squared_error: 0.1075\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.1051 - val_mean_squared_error: 0.1051\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0988 - val_mean_squared_error: 0.0988\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.1017 - val_mean_squared_error: 0.1017\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0965 - val_mean_squared_error: 0.0965\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0951 - val_mean_squared_error: 0.0951\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0940 - val_mean_squared_error: 0.0940\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0901 - val_mean_squared_error: 0.0901\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0907 - val_mean_squared_error: 0.0907\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0876 - val_mean_squared_error: 0.0876\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0877 - val_mean_squared_error: 0.0877\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0842 - val_mean_squared_error: 0.0842\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0853 - val_mean_squared_error: 0.0853\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0811 - val_mean_squared_error: 0.0811\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0829 - val_mean_squared_error: 0.0829\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0829 - val_mean_squared_error: 0.0829\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0836 - val_mean_squared_error: 0.0836\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0780 - val_mean_squared_error: 0.0780\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0771 - val_mean_squared_error: 0.0771\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0769 - val_mean_squared_error: 0.0769\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 33us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0746 - val_mean_squared_error: 0.0746\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0752 - val_mean_squared_error: 0.0752\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0727 - val_mean_squared_error: 0.0727\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0752 - val_mean_squared_error: 0.0752\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0714 - val_mean_squared_error: 0.0714\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0702 - val_mean_squared_error: 0.0702\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0750 - val_mean_squared_error: 0.0750\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0723 - val_mean_squared_error: 0.0723\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0686 - val_mean_squared_error: 0.0686\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0722 - val_mean_squared_error: 0.0722\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0665 - val_mean_squared_error: 0.0665\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0748 - val_mean_squared_error: 0.0748\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0692 - val_mean_squared_error: 0.0692\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0712 - val_mean_squared_error: 0.0712\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0694 - val_mean_squared_error: 0.0694\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0792 - val_mean_squared_error: 0.0792\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0639 - val_mean_squared_error: 0.0639\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0849 - val_mean_squared_error: 0.0849\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0711 - val_mean_squared_error: 0.0711\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0701 - val_mean_squared_error: 0.0701\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0759 - val_mean_squared_error: 0.0759\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0678 - val_mean_squared_error: 0.0678\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0775 - val_mean_squared_error: 0.0775\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0785 - val_mean_squared_error: 0.0785\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0692 - val_mean_squared_error: 0.0692\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0780 - val_mean_squared_error: 0.0780\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0784 - val_mean_squared_error: 0.0784\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0743 - val_mean_squared_error: 0.0743\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0759 - val_mean_squared_error: 0.0759\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0867 - val_mean_squared_error: 0.0867\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0715 - val_mean_squared_error: 0.0715\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0854 - val_mean_squared_error: 0.0854\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0783 - val_mean_squared_error: 0.0783\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0821 - val_mean_squared_error: 0.0821\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0850 - val_mean_squared_error: 0.0850\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0886 - val_mean_squared_error: 0.0886\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0907 - val_mean_squared_error: 0.0907\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0822 - val_mean_squared_error: 0.0822\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0895 - val_mean_squared_error: 0.0895\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0963 - val_mean_squared_error: 0.0963\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0764 - val_mean_squared_error: 0.0764\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1047 - val_mean_squared_error: 0.1047\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1166 - val_mean_squared_error: 0.1166\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0896 - val_mean_squared_error: 0.0896\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0820 - val_mean_squared_error: 0.0820\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1159 - val_mean_squared_error: 0.1159\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0982 - val_mean_squared_error: 0.0982\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0989 - val_mean_squared_error: 0.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "It has been 2.1153762340545654 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 1ms/step - loss: 0.0514 - mean_squared_error: 0.0514 - val_loss: 0.1854 - val_mean_squared_error: 0.1854\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.1520 - val_mean_squared_error: 0.1520\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0301 - mean_squared_error: 0.0301 - val_loss: 0.1277 - val_mean_squared_error: 0.1277\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0261 - mean_squared_error: 0.0261 - val_loss: 0.1413 - val_mean_squared_error: 0.1413\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.1337 - val_mean_squared_error: 0.1337\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.1119 - val_mean_squared_error: 0.1119\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.1138 - val_mean_squared_error: 0.1138\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0810 - val_mean_squared_error: 0.0810\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.1065 - val_mean_squared_error: 0.1065\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0790 - val_mean_squared_error: 0.0790\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0746 - val_mean_squared_error: 0.0746\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0667 - val_mean_squared_error: 0.0667\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0601 - val_mean_squared_error: 0.0601\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0704 - val_mean_squared_error: 0.0704\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0581 - val_mean_squared_error: 0.0581\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0580 - val_mean_squared_error: 0.0580\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0559 - val_mean_squared_error: 0.0559\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0527 - val_mean_squared_error: 0.0527\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0552 - val_mean_squared_error: 0.0552\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0520 - val_mean_squared_error: 0.0520\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0640 - val_mean_squared_error: 0.0640\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0473 - val_mean_squared_error: 0.0473\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0536 - val_mean_squared_error: 0.0536\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0581 - val_mean_squared_error: 0.0581\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0536 - val_mean_squared_error: 0.0536\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0646 - val_mean_squared_error: 0.0646\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0511 - val_mean_squared_error: 0.0511\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0662 - val_mean_squared_error: 0.0662\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0627 - val_mean_squared_error: 0.0627\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0525 - val_mean_squared_error: 0.0525\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0601 - val_mean_squared_error: 0.0601\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0830 - val_mean_squared_error: 0.0830\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0650 - val_mean_squared_error: 0.0650\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0792 - val_mean_squared_error: 0.0792\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0833 - val_mean_squared_error: 0.0833\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0617 - val_mean_squared_error: 0.0617\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0714 - val_mean_squared_error: 0.0714\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0747 - val_mean_squared_error: 0.0747\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0875 - val_mean_squared_error: 0.0875\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 36us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0925 - val_mean_squared_error: 0.0925\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0820 - val_mean_squared_error: 0.0820\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1210 - val_mean_squared_error: 0.1210\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0916 - val_mean_squared_error: 0.0916\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0790 - val_mean_squared_error: 0.0790\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0690 - val_mean_squared_error: 0.0690\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1135 - val_mean_squared_error: 0.1135\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1113 - val_mean_squared_error: 0.1113\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1035 - val_mean_squared_error: 0.1035\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0934 - val_mean_squared_error: 0.0934\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1073 - val_mean_squared_error: 0.1073\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0829 - val_mean_squared_error: 0.0829\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1229 - val_mean_squared_error: 0.1229\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1289 - val_mean_squared_error: 0.1289\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1106 - val_mean_squared_error: 0.1106\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1383 - val_mean_squared_error: 0.1383\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1113 - val_mean_squared_error: 0.1113\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1188 - val_mean_squared_error: 0.1188\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1049 - val_mean_squared_error: 0.1049\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1036 - val_mean_squared_error: 0.1036\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1810 - val_mean_squared_error: 0.1810\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1440 - val_mean_squared_error: 0.1440\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1151 - val_mean_squared_error: 0.1151\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0901 - val_mean_squared_error: 0.0901\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1231 - val_mean_squared_error: 0.1231\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1748 - val_mean_squared_error: 0.1748\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1547 - val_mean_squared_error: 0.1547\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1676 - val_mean_squared_error: 0.1676\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1327 - val_mean_squared_error: 0.1327\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1333 - val_mean_squared_error: 0.1333\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1434 - val_mean_squared_error: 0.1434\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1362 - val_mean_squared_error: 0.1362\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1249 - val_mean_squared_error: 0.1249\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1727 - val_mean_squared_error: 0.1727\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1628 - val_mean_squared_error: 0.1628\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1605 - val_mean_squared_error: 0.1605\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1660 - val_mean_squared_error: 0.1660\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1470 - val_mean_squared_error: 0.1470\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1719 - val_mean_squared_error: 0.1719\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1445 - val_mean_squared_error: 0.1445\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1458 - val_mean_squared_error: 0.1458\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1911 - val_mean_squared_error: 0.1911\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1662 - val_mean_squared_error: 0.1662\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1604 - val_mean_squared_error: 0.1604\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1709 - val_mean_squared_error: 0.1709\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1753 - val_mean_squared_error: 0.1753\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1824 - val_mean_squared_error: 0.1824\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.2017 - val_mean_squared_error: 0.2017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1718 - val_mean_squared_error: 0.1718\n",
      "It has been 2.1666688919067383 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 1ms/step - loss: 0.0640 - mean_squared_error: 0.0640 - val_loss: 0.2025 - val_mean_squared_error: 0.2025\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0428 - mean_squared_error: 0.0428 - val_loss: 0.0857 - val_mean_squared_error: 0.0857\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.1099 - val_mean_squared_error: 0.1099\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0277 - mean_squared_error: 0.0277 - val_loss: 0.0983 - val_mean_squared_error: 0.0983\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.1134 - val_mean_squared_error: 0.1134\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.1064 - val_mean_squared_error: 0.1064\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.1120 - val_mean_squared_error: 0.1120\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.1047 - val_mean_squared_error: 0.1047\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.1135 - val_mean_squared_error: 0.1135\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.1163 - val_mean_squared_error: 0.1163\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.1079 - val_mean_squared_error: 0.1079\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.1088 - val_mean_squared_error: 0.1088\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.1164 - val_mean_squared_error: 0.1164\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.1086 - val_mean_squared_error: 0.1086\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.1258 - val_mean_squared_error: 0.1258\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.1034 - val_mean_squared_error: 0.1034\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.1252 - val_mean_squared_error: 0.1252\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.1152 - val_mean_squared_error: 0.1152\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.1147 - val_mean_squared_error: 0.1147\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.1102 - val_mean_squared_error: 0.1102\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.1340 - val_mean_squared_error: 0.1340\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0912 - val_mean_squared_error: 0.0912\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.1233 - val_mean_squared_error: 0.1233\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0981 - val_mean_squared_error: 0.0981\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.1293 - val_mean_squared_error: 0.1293\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1154 - val_mean_squared_error: 0.1154\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.1128 - val_mean_squared_error: 0.1128\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1328 - val_mean_squared_error: 0.1328\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1147 - val_mean_squared_error: 0.1147\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1144 - val_mean_squared_error: 0.1144\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.1210 - val_mean_squared_error: 0.1210\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1108 - val_mean_squared_error: 0.1108\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1391 - val_mean_squared_error: 0.1391\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1163 - val_mean_squared_error: 0.1163\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1225 - val_mean_squared_error: 0.1225\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1158 - val_mean_squared_error: 0.1158\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1375 - val_mean_squared_error: 0.1375\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1127 - val_mean_squared_error: 0.1127\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1261 - val_mean_squared_error: 0.1261\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1156 - val_mean_squared_error: 0.1156\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1653 - val_mean_squared_error: 0.1653\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1276 - val_mean_squared_error: 0.1276\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1097 - val_mean_squared_error: 0.1097\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1459 - val_mean_squared_error: 0.1459\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1200 - val_mean_squared_error: 0.1200\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1342 - val_mean_squared_error: 0.1342\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1227 - val_mean_squared_error: 0.1227\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1346 - val_mean_squared_error: 0.1346\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 33us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1354 - val_mean_squared_error: 0.1354\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1426 - val_mean_squared_error: 0.1426\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1375 - val_mean_squared_error: 0.1375\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1411 - val_mean_squared_error: 0.1411\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1426 - val_mean_squared_error: 0.1426\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1523 - val_mean_squared_error: 0.1523\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1212 - val_mean_squared_error: 0.1212\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1641 - val_mean_squared_error: 0.1641\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1350 - val_mean_squared_error: 0.1350\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1709 - val_mean_squared_error: 0.1709\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1617 - val_mean_squared_error: 0.1617\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1351 - val_mean_squared_error: 0.1351\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1813 - val_mean_squared_error: 0.1813\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1643 - val_mean_squared_error: 0.1643\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1504 - val_mean_squared_error: 0.1504\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1801 - val_mean_squared_error: 0.1801\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1894 - val_mean_squared_error: 0.1894\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1311 - val_mean_squared_error: 0.1311\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1612 - val_mean_squared_error: 0.1612\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.2185 - val_mean_squared_error: 0.2185\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1529 - val_mean_squared_error: 0.1529\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1715 - val_mean_squared_error: 0.1715\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1909 - val_mean_squared_error: 0.1909\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1998 - val_mean_squared_error: 0.1998\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1882 - val_mean_squared_error: 0.1882\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1827 - val_mean_squared_error: 0.1827\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1827 - val_mean_squared_error: 0.1827\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1815 - val_mean_squared_error: 0.1815\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1957 - val_mean_squared_error: 0.1957\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1987 - val_mean_squared_error: 0.1987\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1913 - val_mean_squared_error: 0.1913\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1989 - val_mean_squared_error: 0.1989\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1756 - val_mean_squared_error: 0.1756\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1763 - val_mean_squared_error: 0.1763\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2613 - val_mean_squared_error: 0.2613\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2667 - val_mean_squared_error: 0.2667\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1756 - val_mean_squared_error: 0.1756\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1729 - val_mean_squared_error: 0.1729\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2254 - val_mean_squared_error: 0.2254\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2687 - val_mean_squared_error: 0.2687\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2080 - val_mean_squared_error: 0.2080\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1733 - val_mean_squared_error: 0.1733\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2319 - val_mean_squared_error: 0.2319\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2710 - val_mean_squared_error: 0.2710\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2050 - val_mean_squared_error: 0.2050\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.2096 - val_mean_squared_error: 0.2096\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.2434 - val_mean_squared_error: 0.2434\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2159 - val_mean_squared_error: 0.2159\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2132 - val_mean_squared_error: 0.2132\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2760 - val_mean_squared_error: 0.2760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.2633 - val_mean_squared_error: 0.2633\n",
      "It has been 2.2129452228546143 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 1ms/step - loss: 0.0617 - mean_squared_error: 0.0617 - val_loss: 0.2038 - val_mean_squared_error: 0.2038\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.1848 - val_mean_squared_error: 0.1848\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.1836 - val_mean_squared_error: 0.1836\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.1619 - val_mean_squared_error: 0.1619\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.1676 - val_mean_squared_error: 0.1676\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.1489 - val_mean_squared_error: 0.1489\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.1450 - val_mean_squared_error: 0.1450\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.1351 - val_mean_squared_error: 0.1351\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0215 - mean_squared_error: 0.0215 - val_loss: 0.1400 - val_mean_squared_error: 0.1400\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.1233 - val_mean_squared_error: 0.1233\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.1279 - val_mean_squared_error: 0.1279\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.1107 - val_mean_squared_error: 0.1107\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.1160 - val_mean_squared_error: 0.1160\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.1157 - val_mean_squared_error: 0.1157\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0974 - val_mean_squared_error: 0.0974\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0978 - val_mean_squared_error: 0.0978\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0959 - val_mean_squared_error: 0.0959\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0915 - val_mean_squared_error: 0.0915\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0873 - val_mean_squared_error: 0.0873\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0871 - val_mean_squared_error: 0.0871\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0813 - val_mean_squared_error: 0.0813\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0767 - val_mean_squared_error: 0.0767\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0749 - val_mean_squared_error: 0.0749\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0811 - val_mean_squared_error: 0.0811\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0723 - val_mean_squared_error: 0.0723\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0719 - val_mean_squared_error: 0.0719\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0666 - val_mean_squared_error: 0.0666\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0651 - val_mean_squared_error: 0.0651\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0638 - val_mean_squared_error: 0.0638\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0626 - val_mean_squared_error: 0.0626\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0675 - val_mean_squared_error: 0.0675\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0611 - val_mean_squared_error: 0.0611\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0594 - val_mean_squared_error: 0.0594\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0569 - val_mean_squared_error: 0.0569\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0568 - val_mean_squared_error: 0.0568\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0554 - val_mean_squared_error: 0.0554\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0555 - val_mean_squared_error: 0.0555\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0560 - val_mean_squared_error: 0.0560\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0549 - val_mean_squared_error: 0.0549\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0599 - val_mean_squared_error: 0.0599\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0523 - val_mean_squared_error: 0.0523\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0519 - val_mean_squared_error: 0.0519\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0572 - val_mean_squared_error: 0.0572\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0553 - val_mean_squared_error: 0.0553\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0642 - val_mean_squared_error: 0.0642\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 32us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0619 - val_mean_squared_error: 0.0619\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0530 - val_mean_squared_error: 0.0530\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0498 - val_mean_squared_error: 0.0498\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0544 - val_mean_squared_error: 0.0544\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0601 - val_mean_squared_error: 0.0601\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0566 - val_mean_squared_error: 0.0566\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0521 - val_mean_squared_error: 0.0521\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0561 - val_mean_squared_error: 0.0561\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0629 - val_mean_squared_error: 0.0629\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0632 - val_mean_squared_error: 0.0632\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0552 - val_mean_squared_error: 0.0552\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0539 - val_mean_squared_error: 0.0539\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0668 - val_mean_squared_error: 0.0668\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0598 - val_mean_squared_error: 0.0598\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0597 - val_mean_squared_error: 0.0597\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0653 - val_mean_squared_error: 0.0653\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0750 - val_mean_squared_error: 0.0750\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0742 - val_mean_squared_error: 0.0742\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0586 - val_mean_squared_error: 0.0586\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0668 - val_mean_squared_error: 0.0668\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0644 - val_mean_squared_error: 0.0644\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0738 - val_mean_squared_error: 0.0738\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0706 - val_mean_squared_error: 0.0706\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0823 - val_mean_squared_error: 0.0823\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0692 - val_mean_squared_error: 0.0692\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0777 - val_mean_squared_error: 0.0777\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0777 - val_mean_squared_error: 0.0777\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0734 - val_mean_squared_error: 0.0734\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0716 - val_mean_squared_error: 0.0716\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0833 - val_mean_squared_error: 0.0833\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0928 - val_mean_squared_error: 0.0928\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0784 - val_mean_squared_error: 0.0784\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0643 - val_mean_squared_error: 0.0643\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0640 - val_mean_squared_error: 0.0640\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0930 - val_mean_squared_error: 0.0930\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0812 - val_mean_squared_error: 0.0812\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0816 - val_mean_squared_error: 0.0816\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0849 - val_mean_squared_error: 0.0849\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0786 - val_mean_squared_error: 0.0786\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0812 - val_mean_squared_error: 0.0812\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1267 - val_mean_squared_error: 0.1267\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0887 - val_mean_squared_error: 0.0887\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0830 - val_mean_squared_error: 0.0830\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0981 - val_mean_squared_error: 0.0981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0888 - val_mean_squared_error: 0.0888\n",
      "It has been 2.2699878215789795 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 2ms/step - loss: 0.0434 - mean_squared_error: 0.0434 - val_loss: 0.1567 - val_mean_squared_error: 0.1567\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.1346 - val_mean_squared_error: 0.1346\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0303 - mean_squared_error: 0.0303 - val_loss: 0.1565 - val_mean_squared_error: 0.1565\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.1109 - val_mean_squared_error: 0.1109\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0938 - val_mean_squared_error: 0.0938\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.1121 - val_mean_squared_error: 0.1121\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0972 - val_mean_squared_error: 0.0972\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0848 - val_mean_squared_error: 0.0848\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0926 - val_mean_squared_error: 0.0926\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0835 - val_mean_squared_error: 0.0835\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0969 - val_mean_squared_error: 0.0969\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.1124 - val_mean_squared_error: 0.1124\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0753 - val_mean_squared_error: 0.0753\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.1135 - val_mean_squared_error: 0.1135\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0999 - val_mean_squared_error: 0.0999\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0969 - val_mean_squared_error: 0.0969\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.1104 - val_mean_squared_error: 0.1104\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0843 - val_mean_squared_error: 0.0843\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0998 - val_mean_squared_error: 0.0998\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0992 - val_mean_squared_error: 0.0992\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1198 - val_mean_squared_error: 0.1198\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.1039 - val_mean_squared_error: 0.1039\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.1103 - val_mean_squared_error: 0.1103\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1112 - val_mean_squared_error: 0.1112\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1376 - val_mean_squared_error: 0.1376\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1394 - val_mean_squared_error: 0.1394\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1279 - val_mean_squared_error: 0.1279\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.1381 - val_mean_squared_error: 0.1381\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1270 - val_mean_squared_error: 0.1270\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1491 - val_mean_squared_error: 0.1491\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1323 - val_mean_squared_error: 0.1323\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1317 - val_mean_squared_error: 0.1317\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1602 - val_mean_squared_error: 0.1602\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1469 - val_mean_squared_error: 0.1469\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1191 - val_mean_squared_error: 0.1191\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1799 - val_mean_squared_error: 0.1799\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.2222 - val_mean_squared_error: 0.2222\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1683 - val_mean_squared_error: 0.1683\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1329 - val_mean_squared_error: 0.1329\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1566 - val_mean_squared_error: 0.1566\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.2118 - val_mean_squared_error: 0.2118\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1914 - val_mean_squared_error: 0.1914\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1784 - val_mean_squared_error: 0.1784\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1870 - val_mean_squared_error: 0.1870\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1880 - val_mean_squared_error: 0.1880\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1655 - val_mean_squared_error: 0.1655\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2203 - val_mean_squared_error: 0.2203\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.2019 - val_mean_squared_error: 0.2019\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 37us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1992 - val_mean_squared_error: 0.1992\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2508 - val_mean_squared_error: 0.2508\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1637 - val_mean_squared_error: 0.1637\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2199 - val_mean_squared_error: 0.2199\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.2135 - val_mean_squared_error: 0.2135\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2248 - val_mean_squared_error: 0.2248\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2271 - val_mean_squared_error: 0.2271\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2243 - val_mean_squared_error: 0.2243\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2169 - val_mean_squared_error: 0.2169\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2756 - val_mean_squared_error: 0.2756\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2545 - val_mean_squared_error: 0.2545\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.2310 - val_mean_squared_error: 0.2310\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2596 - val_mean_squared_error: 0.2596\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2376 - val_mean_squared_error: 0.2376\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2848 - val_mean_squared_error: 0.2848\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2526 - val_mean_squared_error: 0.2526\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.3053 - val_mean_squared_error: 0.3053\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2683 - val_mean_squared_error: 0.2683\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.2655 - val_mean_squared_error: 0.2655\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2432 - val_mean_squared_error: 0.2432\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2638 - val_mean_squared_error: 0.2638\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.3060 - val_mean_squared_error: 0.3060\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2840 - val_mean_squared_error: 0.2840\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2888 - val_mean_squared_error: 0.2888\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2982 - val_mean_squared_error: 0.2982\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.3203 - val_mean_squared_error: 0.3203\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3132 - val_mean_squared_error: 0.3132\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3404 - val_mean_squared_error: 0.3404\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2715 - val_mean_squared_error: 0.2715\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.3073 - val_mean_squared_error: 0.3073\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.3357 - val_mean_squared_error: 0.3357\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3433 - val_mean_squared_error: 0.3433\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.3668 - val_mean_squared_error: 0.3668\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.3714 - val_mean_squared_error: 0.3714\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.2888 - val_mean_squared_error: 0.2888\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2899 - val_mean_squared_error: 0.2899\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3392 - val_mean_squared_error: 0.3392\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.3311 - val_mean_squared_error: 0.3311\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.3404 - val_mean_squared_error: 0.3404\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.3446 - val_mean_squared_error: 0.3446\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.3540 - val_mean_squared_error: 0.3540\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.3448 - val_mean_squared_error: 0.3448\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.3719 - val_mean_squared_error: 0.3719\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.3293 - val_mean_squared_error: 0.3293\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.3647 - val_mean_squared_error: 0.3647\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.4025 - val_mean_squared_error: 0.4025\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.3783 - val_mean_squared_error: 0.3783\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.3733 - val_mean_squared_error: 0.3733\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.3432 - val_mean_squared_error: 0.3432\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.3298 - val_mean_squared_error: 0.3298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.3576 - val_mean_squared_error: 0.3576\n",
      "It has been 2.300320625305176 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 2ms/step - loss: 0.1661 - mean_squared_error: 0.1661 - val_loss: 0.2607 - val_mean_squared_error: 0.2607\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0784 - mean_squared_error: 0.0784 - val_loss: 0.3484 - val_mean_squared_error: 0.3484\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0541 - mean_squared_error: 0.0541 - val_loss: 0.0999 - val_mean_squared_error: 0.0999\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0451 - mean_squared_error: 0.0451 - val_loss: 0.0886 - val_mean_squared_error: 0.0886\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.1179 - val_mean_squared_error: 0.1179\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.1001 - val_mean_squared_error: 0.1001\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.0899 - val_mean_squared_error: 0.0899\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0283 - mean_squared_error: 0.0283 - val_loss: 0.0940 - val_mean_squared_error: 0.0940\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.0919 - val_mean_squared_error: 0.0919\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0899 - val_mean_squared_error: 0.0899\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.0886 - val_mean_squared_error: 0.0886\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0870 - val_mean_squared_error: 0.0870\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0862 - val_mean_squared_error: 0.0862\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0854 - val_mean_squared_error: 0.0854\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0859 - val_mean_squared_error: 0.0859\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0864 - val_mean_squared_error: 0.0864\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.0840 - val_mean_squared_error: 0.0840\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0831 - val_mean_squared_error: 0.0831\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0884 - val_mean_squared_error: 0.0884\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0820 - val_mean_squared_error: 0.0820\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0842 - val_mean_squared_error: 0.0842\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0814 - val_mean_squared_error: 0.0814\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0837 - val_mean_squared_error: 0.0837\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0825 - val_mean_squared_error: 0.0825\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0849 - val_mean_squared_error: 0.0849\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0835 - val_mean_squared_error: 0.0835\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0821 - val_mean_squared_error: 0.0821\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0864 - val_mean_squared_error: 0.0864\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0807 - val_mean_squared_error: 0.0807\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0780 - val_mean_squared_error: 0.0780\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0933 - val_mean_squared_error: 0.0933\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0853 - val_mean_squared_error: 0.0853\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0823 - val_mean_squared_error: 0.0823\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0936 - val_mean_squared_error: 0.0936\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0886 - val_mean_squared_error: 0.0886\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0880 - val_mean_squared_error: 0.0880\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0874 - val_mean_squared_error: 0.0874\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0874 - val_mean_squared_error: 0.0874\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0904 - val_mean_squared_error: 0.0904\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0896 - val_mean_squared_error: 0.0896\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0926 - val_mean_squared_error: 0.0926\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0931 - val_mean_squared_error: 0.0931\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0965 - val_mean_squared_error: 0.0965\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0907 - val_mean_squared_error: 0.0907\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0921 - val_mean_squared_error: 0.0921\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0876 - val_mean_squared_error: 0.0876\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 40us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1083 - val_mean_squared_error: 0.1083\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0904 - val_mean_squared_error: 0.0904\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1058 - val_mean_squared_error: 0.1058\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0981 - val_mean_squared_error: 0.0981\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1039 - val_mean_squared_error: 0.1039\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0992 - val_mean_squared_error: 0.0992\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1033 - val_mean_squared_error: 0.1033\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0974 - val_mean_squared_error: 0.0974\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1171 - val_mean_squared_error: 0.1171\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.1068 - val_mean_squared_error: 0.1068\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1041 - val_mean_squared_error: 0.1041\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1238 - val_mean_squared_error: 0.1238\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0985 - val_mean_squared_error: 0.0985\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1333 - val_mean_squared_error: 0.1333\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0898 - val_mean_squared_error: 0.0898\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1434 - val_mean_squared_error: 0.1434\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0967 - val_mean_squared_error: 0.0967\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1368 - val_mean_squared_error: 0.1368\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1120 - val_mean_squared_error: 0.1120\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1180 - val_mean_squared_error: 0.1180\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1387 - val_mean_squared_error: 0.1387\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1216 - val_mean_squared_error: 0.1216\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1222 - val_mean_squared_error: 0.1222\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1283 - val_mean_squared_error: 0.1283\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1208 - val_mean_squared_error: 0.1208\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1351 - val_mean_squared_error: 0.1351\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1287 - val_mean_squared_error: 0.1287\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1418 - val_mean_squared_error: 0.1418\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1328 - val_mean_squared_error: 0.1328\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1428 - val_mean_squared_error: 0.1428\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1640 - val_mean_squared_error: 0.1640\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1239 - val_mean_squared_error: 0.1239\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1441 - val_mean_squared_error: 0.1441\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1511 - val_mean_squared_error: 0.1511\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1279 - val_mean_squared_error: 0.1279\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1662 - val_mean_squared_error: 0.1662\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1477 - val_mean_squared_error: 0.1477\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1582 - val_mean_squared_error: 0.1582\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1404 - val_mean_squared_error: 0.1404\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1701 - val_mean_squared_error: 0.1701\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1585 - val_mean_squared_error: 0.1585\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1664 - val_mean_squared_error: 0.1664\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1741 - val_mean_squared_error: 0.1741\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1674 - val_mean_squared_error: 0.1674\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1639 - val_mean_squared_error: 0.1639\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1699 - val_mean_squared_error: 0.1699\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1608 - val_mean_squared_error: 0.1608\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.2058 - val_mean_squared_error: 0.2058\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1637 - val_mean_squared_error: 0.1637\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1837 - val_mean_squared_error: 0.1837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1893 - val_mean_squared_error: 0.1893\n",
      "It has been 2.3952178955078125 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 2ms/step - loss: 0.0845 - mean_squared_error: 0.0845 - val_loss: 0.2430 - val_mean_squared_error: 0.2430\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0520 - mean_squared_error: 0.0520 - val_loss: 0.0957 - val_mean_squared_error: 0.0957\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0297 - mean_squared_error: 0.0297 - val_loss: 0.0809 - val_mean_squared_error: 0.0809\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.0831 - val_mean_squared_error: 0.0831\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.0833 - val_mean_squared_error: 0.0833\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0216 - mean_squared_error: 0.0216 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0831 - val_mean_squared_error: 0.0831\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0822 - val_mean_squared_error: 0.0822\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0814 - val_mean_squared_error: 0.0814\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0796 - val_mean_squared_error: 0.0796\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0789 - val_mean_squared_error: 0.0789\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0773 - val_mean_squared_error: 0.0773\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0765 - val_mean_squared_error: 0.0765\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0750 - val_mean_squared_error: 0.0750\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0746 - val_mean_squared_error: 0.0746\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0740 - val_mean_squared_error: 0.0740\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0737 - val_mean_squared_error: 0.0737\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0729 - val_mean_squared_error: 0.0729\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0731 - val_mean_squared_error: 0.0731\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0705 - val_mean_squared_error: 0.0705\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0713 - val_mean_squared_error: 0.0713\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0697 - val_mean_squared_error: 0.0697\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0701 - val_mean_squared_error: 0.0701\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0677 - val_mean_squared_error: 0.0677\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0688 - val_mean_squared_error: 0.0688\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0689 - val_mean_squared_error: 0.0689\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0702 - val_mean_squared_error: 0.0702\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0675 - val_mean_squared_error: 0.0675\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0736 - val_mean_squared_error: 0.0736\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0643 - val_mean_squared_error: 0.0643\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0802 - val_mean_squared_error: 0.0802\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0687 - val_mean_squared_error: 0.0687\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0777 - val_mean_squared_error: 0.0777\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0688 - val_mean_squared_error: 0.0688\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0858 - val_mean_squared_error: 0.0858\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0723 - val_mean_squared_error: 0.0723\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0711 - val_mean_squared_error: 0.0711\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0877 - val_mean_squared_error: 0.0877\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0618 - val_mean_squared_error: 0.0618\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0866 - val_mean_squared_error: 0.0866\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0742 - val_mean_squared_error: 0.0742\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0919 - val_mean_squared_error: 0.0919\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0726 - val_mean_squared_error: 0.0726\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0777 - val_mean_squared_error: 0.0777\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1009 - val_mean_squared_error: 0.1009\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0679 - val_mean_squared_error: 0.0679\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1199 - val_mean_squared_error: 0.1199\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 41us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1068 - val_mean_squared_error: 0.1068\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0887 - val_mean_squared_error: 0.0887\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0839 - val_mean_squared_error: 0.0839\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0889 - val_mean_squared_error: 0.0889\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0874 - val_mean_squared_error: 0.0874\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1028 - val_mean_squared_error: 0.1028\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0902 - val_mean_squared_error: 0.0902\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0916 - val_mean_squared_error: 0.0916\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1113 - val_mean_squared_error: 0.1113\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1072 - val_mean_squared_error: 0.1072\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1199 - val_mean_squared_error: 0.1199\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0991 - val_mean_squared_error: 0.0991\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0901 - val_mean_squared_error: 0.0901\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1160 - val_mean_squared_error: 0.1160\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1241 - val_mean_squared_error: 0.1241\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1005 - val_mean_squared_error: 0.1005\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1205 - val_mean_squared_error: 0.1205\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1149 - val_mean_squared_error: 0.1149\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1106 - val_mean_squared_error: 0.1106\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1418 - val_mean_squared_error: 0.1418\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1141 - val_mean_squared_error: 0.1141\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1253 - val_mean_squared_error: 0.1253\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1273 - val_mean_squared_error: 0.1273\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1140 - val_mean_squared_error: 0.1140\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1413 - val_mean_squared_error: 0.1413\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1345 - val_mean_squared_error: 0.1345\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1217 - val_mean_squared_error: 0.1217\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1453 - val_mean_squared_error: 0.1453\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1410 - val_mean_squared_error: 0.1410\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1303 - val_mean_squared_error: 0.1303\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1371 - val_mean_squared_error: 0.1371\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1167 - val_mean_squared_error: 0.1167\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1457 - val_mean_squared_error: 0.1457\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1283 - val_mean_squared_error: 0.1283\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1260 - val_mean_squared_error: 0.1260\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1514 - val_mean_squared_error: 0.1514\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1380 - val_mean_squared_error: 0.1380\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1493 - val_mean_squared_error: 0.1493\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1623 - val_mean_squared_error: 0.1623\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1273 - val_mean_squared_error: 0.1273\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1502 - val_mean_squared_error: 0.1502\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1556 - val_mean_squared_error: 0.1556\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1370 - val_mean_squared_error: 0.1370\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1567 - val_mean_squared_error: 0.1567\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1564 - val_mean_squared_error: 0.1564\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1527 - val_mean_squared_error: 0.1527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1614 - val_mean_squared_error: 0.1614\n",
      "It has been 2.4533989429473877 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 2ms/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.1499 - val_mean_squared_error: 0.1499\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.1416 - val_mean_squared_error: 0.1416\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 30us/step - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.1221 - val_mean_squared_error: 0.1221\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.1611 - val_mean_squared_error: 0.1611\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.1280 - val_mean_squared_error: 0.1280\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.1350 - val_mean_squared_error: 0.1350\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.1683 - val_mean_squared_error: 0.1683\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.1676 - val_mean_squared_error: 0.1676\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.1006 - val_mean_squared_error: 0.1006\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.1917 - val_mean_squared_error: 0.1917\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1680 - val_mean_squared_error: 0.1680\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.1389 - val_mean_squared_error: 0.1389\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.1332 - val_mean_squared_error: 0.1332\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.1836 - val_mean_squared_error: 0.1836\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.1378 - val_mean_squared_error: 0.1378\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.1896 - val_mean_squared_error: 0.1896\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1809 - val_mean_squared_error: 0.1809\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.1562 - val_mean_squared_error: 0.1562\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1829 - val_mean_squared_error: 0.1829\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1857 - val_mean_squared_error: 0.1857\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1823 - val_mean_squared_error: 0.1823\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.2016 - val_mean_squared_error: 0.2016\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.1922 - val_mean_squared_error: 0.1922\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.1443 - val_mean_squared_error: 0.1443\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.2828 - val_mean_squared_error: 0.2828\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.1826 - val_mean_squared_error: 0.1826\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.1559 - val_mean_squared_error: 0.1559\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.2437 - val_mean_squared_error: 0.2437\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1836 - val_mean_squared_error: 0.1836\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1765 - val_mean_squared_error: 0.1765\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.2241 - val_mean_squared_error: 0.2241\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.2136 - val_mean_squared_error: 0.2136\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.2135 - val_mean_squared_error: 0.2135\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.2138 - val_mean_squared_error: 0.2138\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.2146 - val_mean_squared_error: 0.2146\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.2116 - val_mean_squared_error: 0.2116\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1940 - val_mean_squared_error: 0.1940\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.2530 - val_mean_squared_error: 0.2530\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.2066 - val_mean_squared_error: 0.2066\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.2350 - val_mean_squared_error: 0.2350\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.2082 - val_mean_squared_error: 0.2082\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.2838 - val_mean_squared_error: 0.2838\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.2174 - val_mean_squared_error: 0.2174\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.2296 - val_mean_squared_error: 0.2296\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.2313 - val_mean_squared_error: 0.2313\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.2197 - val_mean_squared_error: 0.2197\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.2549 - val_mean_squared_error: 0.2549\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.3016 - val_mean_squared_error: 0.3016\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.2103 - val_mean_squared_error: 0.2103\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 43us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2777 - val_mean_squared_error: 0.2777\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2834 - val_mean_squared_error: 0.2834\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2654 - val_mean_squared_error: 0.2654\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.2672 - val_mean_squared_error: 0.2672\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2139 - val_mean_squared_error: 0.2139\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2840 - val_mean_squared_error: 0.2840\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.3262 - val_mean_squared_error: 0.3262\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2982 - val_mean_squared_error: 0.2982\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2356 - val_mean_squared_error: 0.2356\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2788 - val_mean_squared_error: 0.2788\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2976 - val_mean_squared_error: 0.2976\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.3072 - val_mean_squared_error: 0.3072\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2427 - val_mean_squared_error: 0.2427\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2542 - val_mean_squared_error: 0.2542\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.3047 - val_mean_squared_error: 0.3047\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2330 - val_mean_squared_error: 0.2330\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2409 - val_mean_squared_error: 0.2409\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.3174 - val_mean_squared_error: 0.3174\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.2860 - val_mean_squared_error: 0.2860\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.3107 - val_mean_squared_error: 0.3107\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2804 - val_mean_squared_error: 0.2804\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2915 - val_mean_squared_error: 0.2915\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.3032 - val_mean_squared_error: 0.3032\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.3063 - val_mean_squared_error: 0.3063\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.3225 - val_mean_squared_error: 0.3225\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.3007 - val_mean_squared_error: 0.3007\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.3168 - val_mean_squared_error: 0.3168\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.3251 - val_mean_squared_error: 0.3251\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2873 - val_mean_squared_error: 0.2873\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2950 - val_mean_squared_error: 0.2950\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2912 - val_mean_squared_error: 0.2912\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3185 - val_mean_squared_error: 0.3185\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.3116 - val_mean_squared_error: 0.3116\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2826 - val_mean_squared_error: 0.2826\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2986 - val_mean_squared_error: 0.2986\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2912 - val_mean_squared_error: 0.2912\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.3011 - val_mean_squared_error: 0.3011\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.3212 - val_mean_squared_error: 0.3212\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2898 - val_mean_squared_error: 0.2898\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2909 - val_mean_squared_error: 0.2909\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.3565 - val_mean_squared_error: 0.3565\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.3592 - val_mean_squared_error: 0.3592\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.3228 - val_mean_squared_error: 0.3228\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2439 - val_mean_squared_error: 0.2439\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2975 - val_mean_squared_error: 0.2975\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3366 - val_mean_squared_error: 0.3366\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3741 - val_mean_squared_error: 0.3741\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.3706 - val_mean_squared_error: 0.3706\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3180 - val_mean_squared_error: 0.3180\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.3073 - val_mean_squared_error: 0.3073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.3085 - val_mean_squared_error: 0.3085\n",
      "It has been 2.501002788543701 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 0s 2ms/step - loss: 0.1211 - mean_squared_error: 0.1211 - val_loss: 0.0644 - val_mean_squared_error: 0.0644\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0590 - mean_squared_error: 0.0590 - val_loss: 0.2791 - val_mean_squared_error: 0.2791\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 29us/step - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.1944 - val_mean_squared_error: 0.1944\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0262 - mean_squared_error: 0.0262 - val_loss: 0.2732 - val_mean_squared_error: 0.2732\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 31us/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.1908 - val_mean_squared_error: 0.1908\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.1807 - val_mean_squared_error: 0.1807\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.1467 - val_mean_squared_error: 0.1467\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.1466 - val_mean_squared_error: 0.1466\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.1604 - val_mean_squared_error: 0.1604\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.1548 - val_mean_squared_error: 0.1548\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1597 - val_mean_squared_error: 0.1597\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.1499 - val_mean_squared_error: 0.1499\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.1584 - val_mean_squared_error: 0.1584\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.1306 - val_mean_squared_error: 0.1306\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.2197 - val_mean_squared_error: 0.2197\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.1369 - val_mean_squared_error: 0.1369\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.1747 - val_mean_squared_error: 0.1747\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.1609 - val_mean_squared_error: 0.1609\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1652 - val_mean_squared_error: 0.1652\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.1824 - val_mean_squared_error: 0.1824\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1493 - val_mean_squared_error: 0.1493\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.1587 - val_mean_squared_error: 0.1587\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.2091 - val_mean_squared_error: 0.2091\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1502 - val_mean_squared_error: 0.1502\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1787 - val_mean_squared_error: 0.1787\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1838 - val_mean_squared_error: 0.1838\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1654 - val_mean_squared_error: 0.1654\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1532 - val_mean_squared_error: 0.1532\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.2461 - val_mean_squared_error: 0.2461\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1620 - val_mean_squared_error: 0.1620\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1755 - val_mean_squared_error: 0.1755\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.2333 - val_mean_squared_error: 0.2333\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1783 - val_mean_squared_error: 0.1783\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.2016 - val_mean_squared_error: 0.2016\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.2277 - val_mean_squared_error: 0.2277\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1794 - val_mean_squared_error: 0.1794\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.2432 - val_mean_squared_error: 0.2432\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.2325 - val_mean_squared_error: 0.2325\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1938 - val_mean_squared_error: 0.1938\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.2064 - val_mean_squared_error: 0.2064\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.2422 - val_mean_squared_error: 0.2422\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.2025 - val_mean_squared_error: 0.2025\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.2647 - val_mean_squared_error: 0.2647\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.2736 - val_mean_squared_error: 0.2736\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1663 - val_mean_squared_error: 0.1663\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.2456 - val_mean_squared_error: 0.2456\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2475 - val_mean_squared_error: 0.2475\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.2932 - val_mean_squared_error: 0.2932\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2333 - val_mean_squared_error: 0.2333\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 39us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.2613 - val_mean_squared_error: 0.2613\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2470 - val_mean_squared_error: 0.2470\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.2353 - val_mean_squared_error: 0.2353\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2394 - val_mean_squared_error: 0.2394\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2487 - val_mean_squared_error: 0.2487\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2726 - val_mean_squared_error: 0.2726\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2977 - val_mean_squared_error: 0.2977\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.2758 - val_mean_squared_error: 0.2758\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.2393 - val_mean_squared_error: 0.2393\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.2558 - val_mean_squared_error: 0.2558\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2513 - val_mean_squared_error: 0.2513\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.2868 - val_mean_squared_error: 0.2868\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.3324 - val_mean_squared_error: 0.3324\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2849 - val_mean_squared_error: 0.2849\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.2359 - val_mean_squared_error: 0.2359\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.3209 - val_mean_squared_error: 0.3209\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.3202 - val_mean_squared_error: 0.3202\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.2439 - val_mean_squared_error: 0.2439\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2848 - val_mean_squared_error: 0.2848\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.3181 - val_mean_squared_error: 0.3181\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.3425 - val_mean_squared_error: 0.3425\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.3242 - val_mean_squared_error: 0.3242\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2865 - val_mean_squared_error: 0.2865\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.3350 - val_mean_squared_error: 0.3350\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3244 - val_mean_squared_error: 0.3244\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3372 - val_mean_squared_error: 0.3372\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.3345 - val_mean_squared_error: 0.3345\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.3303 - val_mean_squared_error: 0.3303\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.3382 - val_mean_squared_error: 0.3382\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.3369 - val_mean_squared_error: 0.3369\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3539 - val_mean_squared_error: 0.3539\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3191 - val_mean_squared_error: 0.3191\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3230 - val_mean_squared_error: 0.3230\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.3326 - val_mean_squared_error: 0.3326\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.3922 - val_mean_squared_error: 0.3922\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.3602 - val_mean_squared_error: 0.3602\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2937 - val_mean_squared_error: 0.2937\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3262 - val_mean_squared_error: 0.3262\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.3753 - val_mean_squared_error: 0.3753\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.3216 - val_mean_squared_error: 0.3216\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.3040 - val_mean_squared_error: 0.3040\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3502 - val_mean_squared_error: 0.3502\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3747 - val_mean_squared_error: 0.3747\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.3644 - val_mean_squared_error: 0.3644\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.4083 - val_mean_squared_error: 0.4083\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.3812 - val_mean_squared_error: 0.3812\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.3629 - val_mean_squared_error: 0.3629\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.3817 - val_mean_squared_error: 0.3817\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.3719 - val_mean_squared_error: 0.3719\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.3769 - val_mean_squared_error: 0.3769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.4122 - val_mean_squared_error: 0.4122\n",
      "It has been 2.5167648792266846 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.0838 - mean_squared_error: 0.0838 - val_loss: 0.5060 - val_mean_squared_error: 0.5060\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0499 - mean_squared_error: 0.0499 - val_loss: 0.1631 - val_mean_squared_error: 0.1631\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0922 - val_mean_squared_error: 0.0922\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.1598 - val_mean_squared_error: 0.1598\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.1094 - val_mean_squared_error: 0.1094\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.1160 - val_mean_squared_error: 0.1160\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.1134 - val_mean_squared_error: 0.1134\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.1091 - val_mean_squared_error: 0.1091\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.1054 - val_mean_squared_error: 0.1054\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0925 - val_mean_squared_error: 0.0925\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.1047 - val_mean_squared_error: 0.1047\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0926 - val_mean_squared_error: 0.0926\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0926 - val_mean_squared_error: 0.0926\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0871 - val_mean_squared_error: 0.0871\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0852 - val_mean_squared_error: 0.0852\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0823 - val_mean_squared_error: 0.0823\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0798 - val_mean_squared_error: 0.0798\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0766 - val_mean_squared_error: 0.0766\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0723 - val_mean_squared_error: 0.0723\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0770 - val_mean_squared_error: 0.0770\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0688 - val_mean_squared_error: 0.0688\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0636 - val_mean_squared_error: 0.0636\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0617 - val_mean_squared_error: 0.0617\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0637 - val_mean_squared_error: 0.0637\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0588 - val_mean_squared_error: 0.0588\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0578 - val_mean_squared_error: 0.0578\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0564 - val_mean_squared_error: 0.0564\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0557 - val_mean_squared_error: 0.0557\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0537 - val_mean_squared_error: 0.0537\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0538 - val_mean_squared_error: 0.0538\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0548 - val_mean_squared_error: 0.0548\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0548 - val_mean_squared_error: 0.0548\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0569 - val_mean_squared_error: 0.0569\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0504 - val_mean_squared_error: 0.0504\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0543 - val_mean_squared_error: 0.0543\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0539 - val_mean_squared_error: 0.0539\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0537 - val_mean_squared_error: 0.0537\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0570 - val_mean_squared_error: 0.0570\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0539 - val_mean_squared_error: 0.0539\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0506 - val_mean_squared_error: 0.0506\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0525 - val_mean_squared_error: 0.0525\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0617 - val_mean_squared_error: 0.0617\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 42us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0535 - val_mean_squared_error: 0.0535\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0670 - val_mean_squared_error: 0.0670\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0593 - val_mean_squared_error: 0.0593\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0685 - val_mean_squared_error: 0.0685\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0606 - val_mean_squared_error: 0.0606\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0545 - val_mean_squared_error: 0.0545\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0697 - val_mean_squared_error: 0.0697\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0728 - val_mean_squared_error: 0.0728\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0589 - val_mean_squared_error: 0.0589\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0660 - val_mean_squared_error: 0.0660\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0793 - val_mean_squared_error: 0.0793\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0589 - val_mean_squared_error: 0.0589\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0792 - val_mean_squared_error: 0.0792\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0777 - val_mean_squared_error: 0.0777\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0800 - val_mean_squared_error: 0.0800\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0777 - val_mean_squared_error: 0.0777\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0767 - val_mean_squared_error: 0.0767\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0898 - val_mean_squared_error: 0.0898\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0835 - val_mean_squared_error: 0.0835\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0781 - val_mean_squared_error: 0.0781\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0947 - val_mean_squared_error: 0.0947\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0881 - val_mean_squared_error: 0.0881\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0697 - val_mean_squared_error: 0.0697\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0842 - val_mean_squared_error: 0.0842\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1157 - val_mean_squared_error: 0.1157\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0793 - val_mean_squared_error: 0.0793\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0814 - val_mean_squared_error: 0.0814\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0871 - val_mean_squared_error: 0.0871\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0972 - val_mean_squared_error: 0.0972\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0985 - val_mean_squared_error: 0.0985\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0997 - val_mean_squared_error: 0.0997\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0998 - val_mean_squared_error: 0.0998\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1175 - val_mean_squared_error: 0.1175\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0992 - val_mean_squared_error: 0.0992\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1165 - val_mean_squared_error: 0.1165\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1088 - val_mean_squared_error: 0.1088\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1055 - val_mean_squared_error: 0.1055\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0986 - val_mean_squared_error: 0.0986\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1257 - val_mean_squared_error: 0.1257\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1138 - val_mean_squared_error: 0.1138\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1095 - val_mean_squared_error: 0.1095\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1206 - val_mean_squared_error: 0.1206\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1017 - val_mean_squared_error: 0.1017\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1393 - val_mean_squared_error: 0.1393\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1103 - val_mean_squared_error: 0.1103\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1004 - val_mean_squared_error: 0.1004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1102 - val_mean_squared_error: 0.1102\n",
      "It has been 2.579495906829834 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.0287 - mean_squared_error: 0.0287 - val_loss: 0.0717 - val_mean_squared_error: 0.0717\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0684 - val_mean_squared_error: 0.0684\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0635 - val_mean_squared_error: 0.0635\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0747 - val_mean_squared_error: 0.0747\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0671 - val_mean_squared_error: 0.0671\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0674 - val_mean_squared_error: 0.0674\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0696 - val_mean_squared_error: 0.0696\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0721 - val_mean_squared_error: 0.0721\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0738 - val_mean_squared_error: 0.0738\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.1042 - val_mean_squared_error: 0.1042\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0776 - val_mean_squared_error: 0.0776\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0904 - val_mean_squared_error: 0.0904\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0821 - val_mean_squared_error: 0.0821\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0706 - val_mean_squared_error: 0.0706\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0925 - val_mean_squared_error: 0.0925\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1013 - val_mean_squared_error: 0.1013\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0902 - val_mean_squared_error: 0.0902\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0920 - val_mean_squared_error: 0.0920\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0938 - val_mean_squared_error: 0.0938\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1102 - val_mean_squared_error: 0.1102\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0960 - val_mean_squared_error: 0.0960\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0910 - val_mean_squared_error: 0.0910\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0938 - val_mean_squared_error: 0.0938\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1053 - val_mean_squared_error: 0.1053\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1310 - val_mean_squared_error: 0.1310\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0987 - val_mean_squared_error: 0.0987\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1143 - val_mean_squared_error: 0.1143\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1176 - val_mean_squared_error: 0.1176\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1007 - val_mean_squared_error: 0.1007\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1396 - val_mean_squared_error: 0.1396\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1380 - val_mean_squared_error: 0.1380\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1130 - val_mean_squared_error: 0.1130\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1341 - val_mean_squared_error: 0.1341\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1333 - val_mean_squared_error: 0.1333\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1568 - val_mean_squared_error: 0.1568\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1456 - val_mean_squared_error: 0.1456\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1569 - val_mean_squared_error: 0.1569\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1145 - val_mean_squared_error: 0.1145\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1532 - val_mean_squared_error: 0.1532\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1428 - val_mean_squared_error: 0.1428\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1296 - val_mean_squared_error: 0.1296\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1640 - val_mean_squared_error: 0.1640\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1686 - val_mean_squared_error: 0.1686\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1590 - val_mean_squared_error: 0.1590\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1443 - val_mean_squared_error: 0.1443\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1306 - val_mean_squared_error: 0.1306\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 37us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1562 - val_mean_squared_error: 0.1562\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1795 - val_mean_squared_error: 0.1795\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1681 - val_mean_squared_error: 0.1681\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1394 - val_mean_squared_error: 0.1394\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1692 - val_mean_squared_error: 0.1692\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1911 - val_mean_squared_error: 0.1911\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1695 - val_mean_squared_error: 0.1695\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1878 - val_mean_squared_error: 0.1878\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1806 - val_mean_squared_error: 0.1806\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1885 - val_mean_squared_error: 0.1885\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2061 - val_mean_squared_error: 0.2061\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1838 - val_mean_squared_error: 0.1838\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1925 - val_mean_squared_error: 0.1925\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2106 - val_mean_squared_error: 0.2106\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2174 - val_mean_squared_error: 0.2174\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1780 - val_mean_squared_error: 0.1780\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1843 - val_mean_squared_error: 0.1843\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1628 - val_mean_squared_error: 0.1628\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.2262 - val_mean_squared_error: 0.2262\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2286 - val_mean_squared_error: 0.2286\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2496 - val_mean_squared_error: 0.2496\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.2143 - val_mean_squared_error: 0.2143\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2248 - val_mean_squared_error: 0.2248\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.2007 - val_mean_squared_error: 0.2007\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2073 - val_mean_squared_error: 0.2073\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.2305 - val_mean_squared_error: 0.2305\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.2194 - val_mean_squared_error: 0.2194\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.2083 - val_mean_squared_error: 0.2083\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.2273 - val_mean_squared_error: 0.2273\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1957 - val_mean_squared_error: 0.1957\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1901 - val_mean_squared_error: 0.1901\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.2056 - val_mean_squared_error: 0.2056\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.2433 - val_mean_squared_error: 0.2433\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2300 - val_mean_squared_error: 0.2300\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.2817 - val_mean_squared_error: 0.2817\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2819 - val_mean_squared_error: 0.2819\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2626 - val_mean_squared_error: 0.2626\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2503 - val_mean_squared_error: 0.2503\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.2430 - val_mean_squared_error: 0.2430\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.2413 - val_mean_squared_error: 0.2413\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.2286 - val_mean_squared_error: 0.2286\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.2116 - val_mean_squared_error: 0.2116\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.2183 - val_mean_squared_error: 0.2183\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.2284 - val_mean_squared_error: 0.2284\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.2357 - val_mean_squared_error: 0.2357\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.2610 - val_mean_squared_error: 0.2610\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.2456 - val_mean_squared_error: 0.2456\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.2304 - val_mean_squared_error: 0.2304\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.2251 - val_mean_squared_error: 0.2251\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.2596 - val_mean_squared_error: 0.2596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.2910 - val_mean_squared_error: 0.2910\n",
      "It has been 2.652062177658081 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.3053 - mean_squared_error: 0.3053 - val_loss: 0.0805 - val_mean_squared_error: 0.0805\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0572 - mean_squared_error: 0.0572 - val_loss: 0.2101 - val_mean_squared_error: 0.2101\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0711 - mean_squared_error: 0.0711 - val_loss: 0.0851 - val_mean_squared_error: 0.0851\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0643 - val_mean_squared_error: 0.0643\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0672 - val_mean_squared_error: 0.0672\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0277 - mean_squared_error: 0.0277 - val_loss: 0.0595 - val_mean_squared_error: 0.0595\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0549 - val_mean_squared_error: 0.0549\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0600 - val_mean_squared_error: 0.0600\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0641 - val_mean_squared_error: 0.0641\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0659 - val_mean_squared_error: 0.0659\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0653 - val_mean_squared_error: 0.0653\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0682 - val_mean_squared_error: 0.0682\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0719 - val_mean_squared_error: 0.0719\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0725 - val_mean_squared_error: 0.0725\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0770 - val_mean_squared_error: 0.0770\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0735 - val_mean_squared_error: 0.0735\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0799 - val_mean_squared_error: 0.0799\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0767 - val_mean_squared_error: 0.0767\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0826 - val_mean_squared_error: 0.0826\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0799 - val_mean_squared_error: 0.0799\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0818 - val_mean_squared_error: 0.0818\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0820 - val_mean_squared_error: 0.0820\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0909 - val_mean_squared_error: 0.0909\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0768 - val_mean_squared_error: 0.0768\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0908 - val_mean_squared_error: 0.0908\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0854 - val_mean_squared_error: 0.0854\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0938 - val_mean_squared_error: 0.0938\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0883 - val_mean_squared_error: 0.0883\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0953 - val_mean_squared_error: 0.0953\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0918 - val_mean_squared_error: 0.0918\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0846 - val_mean_squared_error: 0.0846\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1063 - val_mean_squared_error: 0.1063\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0929 - val_mean_squared_error: 0.0929\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.1050 - val_mean_squared_error: 0.1050\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1055 - val_mean_squared_error: 0.1055\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0944 - val_mean_squared_error: 0.0944\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1084 - val_mean_squared_error: 0.1084\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1038 - val_mean_squared_error: 0.1038\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.1046 - val_mean_squared_error: 0.1046\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1086 - val_mean_squared_error: 0.1086\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1094 - val_mean_squared_error: 0.1094\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.1127 - val_mean_squared_error: 0.1127\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 40us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1112 - val_mean_squared_error: 0.1112\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1176 - val_mean_squared_error: 0.1176\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1126 - val_mean_squared_error: 0.1126\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.1186 - val_mean_squared_error: 0.1186\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1143 - val_mean_squared_error: 0.1143\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1190 - val_mean_squared_error: 0.1190\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1208 - val_mean_squared_error: 0.1208\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.1192 - val_mean_squared_error: 0.1192\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1240 - val_mean_squared_error: 0.1240\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1252 - val_mean_squared_error: 0.1252\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1225 - val_mean_squared_error: 0.1225\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1204 - val_mean_squared_error: 0.1204\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1313 - val_mean_squared_error: 0.1313\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1271 - val_mean_squared_error: 0.1271\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1411 - val_mean_squared_error: 0.1411\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1229 - val_mean_squared_error: 0.1229\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1421 - val_mean_squared_error: 0.1421\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1373 - val_mean_squared_error: 0.1373\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1385 - val_mean_squared_error: 0.1385\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1418 - val_mean_squared_error: 0.1418\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1418 - val_mean_squared_error: 0.1418\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1317 - val_mean_squared_error: 0.1317\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1592 - val_mean_squared_error: 0.1592\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1398 - val_mean_squared_error: 0.1398\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1494 - val_mean_squared_error: 0.1494\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1398 - val_mean_squared_error: 0.1398\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1479 - val_mean_squared_error: 0.1479\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1495 - val_mean_squared_error: 0.1495\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - ETA: 0s - loss: 0.0090 - mean_squared_error: 0.00 - 0s 41us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1536 - val_mean_squared_error: 0.1536\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1496 - val_mean_squared_error: 0.1496\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1535 - val_mean_squared_error: 0.1535\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1633 - val_mean_squared_error: 0.1633\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1581 - val_mean_squared_error: 0.1581\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1591 - val_mean_squared_error: 0.1591\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1482 - val_mean_squared_error: 0.1482\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1733 - val_mean_squared_error: 0.1733\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1500 - val_mean_squared_error: 0.1500\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1734 - val_mean_squared_error: 0.1734\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1567 - val_mean_squared_error: 0.1567\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1656 - val_mean_squared_error: 0.1656\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1504 - val_mean_squared_error: 0.1504\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1852 - val_mean_squared_error: 0.1852\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1475 - val_mean_squared_error: 0.1475\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1774 - val_mean_squared_error: 0.1774\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1836 - val_mean_squared_error: 0.1836\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1613 - val_mean_squared_error: 0.1613\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2010 - val_mean_squared_error: 0.2010\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1593 - val_mean_squared_error: 0.1593\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1945 - val_mean_squared_error: 0.1945\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 40us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1742 - val_mean_squared_error: 0.1742\n",
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1834 - val_mean_squared_error: 0.1834\n",
      "It has been 2.674104690551758 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.5909 - mean_squared_error: 0.5909 - val_loss: 0.3866 - val_mean_squared_error: 0.3866\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0916 - mean_squared_error: 0.0916 - val_loss: 0.4230 - val_mean_squared_error: 0.4230\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0817 - mean_squared_error: 0.0817 - val_loss: 0.5959 - val_mean_squared_error: 0.5959\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0745 - mean_squared_error: 0.0745 - val_loss: 0.3186 - val_mean_squared_error: 0.3186\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0458 - mean_squared_error: 0.0458 - val_loss: 0.2126 - val_mean_squared_error: 0.2126\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0459 - mean_squared_error: 0.0459 - val_loss: 0.2074 - val_mean_squared_error: 0.2074\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0409 - mean_squared_error: 0.0409 - val_loss: 0.2235 - val_mean_squared_error: 0.2235\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.2238 - val_mean_squared_error: 0.2238\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.2134 - val_mean_squared_error: 0.2134\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.2044 - val_mean_squared_error: 0.2044\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.2037 - val_mean_squared_error: 0.2037\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.2056 - val_mean_squared_error: 0.2056\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0296 - mean_squared_error: 0.0296 - val_loss: 0.2025 - val_mean_squared_error: 0.2025\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.1991 - val_mean_squared_error: 0.1991\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0276 - mean_squared_error: 0.0276 - val_loss: 0.1964 - val_mean_squared_error: 0.1964\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0265 - mean_squared_error: 0.0265 - val_loss: 0.1987 - val_mean_squared_error: 0.1987\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.1959 - val_mean_squared_error: 0.1959\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.1938 - val_mean_squared_error: 0.1938\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.1929 - val_mean_squared_error: 0.1929\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.1920 - val_mean_squared_error: 0.1920\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.1898 - val_mean_squared_error: 0.1898\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.1891 - val_mean_squared_error: 0.1891\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.1870 - val_mean_squared_error: 0.1870\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.1859 - val_mean_squared_error: 0.1859\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.1844 - val_mean_squared_error: 0.1844\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.1826 - val_mean_squared_error: 0.1826\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.1814 - val_mean_squared_error: 0.1814\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.1793 - val_mean_squared_error: 0.1793\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.1778 - val_mean_squared_error: 0.1778\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.1773 - val_mean_squared_error: 0.1773\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.1740 - val_mean_squared_error: 0.1740\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.1729 - val_mean_squared_error: 0.1729\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.1703 - val_mean_squared_error: 0.1703\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.1700 - val_mean_squared_error: 0.1700\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.1693 - val_mean_squared_error: 0.1693\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.1670 - val_mean_squared_error: 0.1670\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.1625 - val_mean_squared_error: 0.1625\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.1640 - val_mean_squared_error: 0.1640\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.1608 - val_mean_squared_error: 0.1608\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.1599 - val_mean_squared_error: 0.1599\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1576 - val_mean_squared_error: 0.1576\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.1572 - val_mean_squared_error: 0.1572\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.1583 - val_mean_squared_error: 0.1583\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.1509 - val_mean_squared_error: 0.1509\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.1561 - val_mean_squared_error: 0.1561\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.1492 - val_mean_squared_error: 0.1492\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.1516 - val_mean_squared_error: 0.1516\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.1475 - val_mean_squared_error: 0.1475\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.1477 - val_mean_squared_error: 0.1477\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 40us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.1477 - val_mean_squared_error: 0.1477\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.1437 - val_mean_squared_error: 0.1437\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.1503 - val_mean_squared_error: 0.1503\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.1351 - val_mean_squared_error: 0.1351\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.1519 - val_mean_squared_error: 0.1519\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.1364 - val_mean_squared_error: 0.1364\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.1444 - val_mean_squared_error: 0.1444\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.1390 - val_mean_squared_error: 0.1390\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.1397 - val_mean_squared_error: 0.1397\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.1390 - val_mean_squared_error: 0.1390\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1381 - val_mean_squared_error: 0.1381\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1408 - val_mean_squared_error: 0.1408\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.1357 - val_mean_squared_error: 0.1357\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.1370 - val_mean_squared_error: 0.1370\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1412 - val_mean_squared_error: 0.1412\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.1312 - val_mean_squared_error: 0.1312\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1453 - val_mean_squared_error: 0.1453\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1289 - val_mean_squared_error: 0.1289\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.1292 - val_mean_squared_error: 0.1292\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.1378 - val_mean_squared_error: 0.1378\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1369 - val_mean_squared_error: 0.1369\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1344 - val_mean_squared_error: 0.1344\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1327 - val_mean_squared_error: 0.1327\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.1310 - val_mean_squared_error: 0.1310\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1345 - val_mean_squared_error: 0.1345\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1332 - val_mean_squared_error: 0.1332\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1384 - val_mean_squared_error: 0.1384\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.1369 - val_mean_squared_error: 0.1369\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1297 - val_mean_squared_error: 0.1297\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1437 - val_mean_squared_error: 0.1437\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1285 - val_mean_squared_error: 0.1285\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1399 - val_mean_squared_error: 0.1399\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1317 - val_mean_squared_error: 0.1317\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.1396 - val_mean_squared_error: 0.1396\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1361 - val_mean_squared_error: 0.1361\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1337 - val_mean_squared_error: 0.1337\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1389 - val_mean_squared_error: 0.1389\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1362 - val_mean_squared_error: 0.1362\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1403 - val_mean_squared_error: 0.1403\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1360 - val_mean_squared_error: 0.1360\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1353 - val_mean_squared_error: 0.1353\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1418 - val_mean_squared_error: 0.1418\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1407 - val_mean_squared_error: 0.1407\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1398 - val_mean_squared_error: 0.1398\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1415 - val_mean_squared_error: 0.1415\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1444 - val_mean_squared_error: 0.1444\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1451 - val_mean_squared_error: 0.1451\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1459 - val_mean_squared_error: 0.1459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1453 - val_mean_squared_error: 0.1453\n",
      "It has been 2.7416887283325195 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.0670 - mean_squared_error: 0.0670 - val_loss: 0.1104 - val_mean_squared_error: 0.1104\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0450 - mean_squared_error: 0.0450 - val_loss: 0.1616 - val_mean_squared_error: 0.1616\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0411 - mean_squared_error: 0.0411 - val_loss: 0.1478 - val_mean_squared_error: 0.1478\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 32us/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.1566 - val_mean_squared_error: 0.1566\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.1428 - val_mean_squared_error: 0.1428\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.1791 - val_mean_squared_error: 0.1791\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.1604 - val_mean_squared_error: 0.1604\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.1840 - val_mean_squared_error: 0.1840\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.1593 - val_mean_squared_error: 0.1593\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.1993 - val_mean_squared_error: 0.1993\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.1917 - val_mean_squared_error: 0.1917\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.1941 - val_mean_squared_error: 0.1941\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.2032 - val_mean_squared_error: 0.2032\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.2168 - val_mean_squared_error: 0.2168\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.1771 - val_mean_squared_error: 0.1771\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.2667 - val_mean_squared_error: 0.2667\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.1694 - val_mean_squared_error: 0.1694\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.2309 - val_mean_squared_error: 0.2309\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.2913 - val_mean_squared_error: 0.2913\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.2417 - val_mean_squared_error: 0.2417\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.2329 - val_mean_squared_error: 0.2329\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.2474 - val_mean_squared_error: 0.2474\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.2408 - val_mean_squared_error: 0.2408\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.2543 - val_mean_squared_error: 0.2543\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.2437 - val_mean_squared_error: 0.2437\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.2657 - val_mean_squared_error: 0.2657\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.2124 - val_mean_squared_error: 0.2124\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.2760 - val_mean_squared_error: 0.2760\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.2457 - val_mean_squared_error: 0.2457\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.2814 - val_mean_squared_error: 0.2814\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.2653 - val_mean_squared_error: 0.2653\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.2817 - val_mean_squared_error: 0.2817\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.2774 - val_mean_squared_error: 0.2774\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.3218 - val_mean_squared_error: 0.3218\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.2633 - val_mean_squared_error: 0.2633\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.2353 - val_mean_squared_error: 0.2353\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.3012 - val_mean_squared_error: 0.3012\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.3218 - val_mean_squared_error: 0.3218\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.2336 - val_mean_squared_error: 0.2336\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.3181 - val_mean_squared_error: 0.3181\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.3127 - val_mean_squared_error: 0.3127\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.2962 - val_mean_squared_error: 0.2962\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.2838 - val_mean_squared_error: 0.2838\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.2965 - val_mean_squared_error: 0.2965\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.3101 - val_mean_squared_error: 0.3101\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.2970 - val_mean_squared_error: 0.2970\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.3149 - val_mean_squared_error: 0.3149\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.2992 - val_mean_squared_error: 0.2992\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2922 - val_mean_squared_error: 0.2922\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 40us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.3710 - val_mean_squared_error: 0.3710\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.2862 - val_mean_squared_error: 0.2862\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.3558 - val_mean_squared_error: 0.3558\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.3065 - val_mean_squared_error: 0.3065\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.3035 - val_mean_squared_error: 0.3035\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.3292 - val_mean_squared_error: 0.3292\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.3514 - val_mean_squared_error: 0.3514\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.3512 - val_mean_squared_error: 0.3512\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.3306 - val_mean_squared_error: 0.3306\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.3512 - val_mean_squared_error: 0.3512\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.3393 - val_mean_squared_error: 0.3393\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2870 - val_mean_squared_error: 0.2870\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.3298 - val_mean_squared_error: 0.3298\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.3861 - val_mean_squared_error: 0.3861\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.3478 - val_mean_squared_error: 0.3478\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.3387 - val_mean_squared_error: 0.3387\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.3815 - val_mean_squared_error: 0.3815\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.3429 - val_mean_squared_error: 0.3429\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.3676 - val_mean_squared_error: 0.3676\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.3937 - val_mean_squared_error: 0.3937\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.3582 - val_mean_squared_error: 0.3582\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.3717 - val_mean_squared_error: 0.3717\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.3836 - val_mean_squared_error: 0.3836\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.3419 - val_mean_squared_error: 0.3419\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.3615 - val_mean_squared_error: 0.3615\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.3832 - val_mean_squared_error: 0.3832\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3728 - val_mean_squared_error: 0.3728\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3886 - val_mean_squared_error: 0.3886\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3593 - val_mean_squared_error: 0.3593\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.4085 - val_mean_squared_error: 0.4085\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3598 - val_mean_squared_error: 0.3598\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.3457 - val_mean_squared_error: 0.3457\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.3532 - val_mean_squared_error: 0.3532\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.3905 - val_mean_squared_error: 0.3905\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.4258 - val_mean_squared_error: 0.4258\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.4134 - val_mean_squared_error: 0.4134\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3400 - val_mean_squared_error: 0.3400\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.3210 - val_mean_squared_error: 0.3210\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.4034 - val_mean_squared_error: 0.4034\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.4668 - val_mean_squared_error: 0.4668\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.4067 - val_mean_squared_error: 0.4067\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.3358 - val_mean_squared_error: 0.3358\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.4079 - val_mean_squared_error: 0.4079\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.3786 - val_mean_squared_error: 0.3786\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.3798 - val_mean_squared_error: 0.3798\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.4124 - val_mean_squared_error: 0.4124\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.4636 - val_mean_squared_error: 0.4636\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.3995 - val_mean_squared_error: 0.3995\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.3954 - val_mean_squared_error: 0.3954\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.3848 - val_mean_squared_error: 0.3848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.3924 - val_mean_squared_error: 0.3924\n",
      "It has been 2.805241823196411 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.4678 - mean_squared_error: 0.4678 - val_loss: 0.1816 - val_mean_squared_error: 0.1816\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0831 - mean_squared_error: 0.0831 - val_loss: 0.4391 - val_mean_squared_error: 0.4391\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0845 - mean_squared_error: 0.0845 - val_loss: 0.5139 - val_mean_squared_error: 0.5139\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0532 - mean_squared_error: 0.0532 - val_loss: 0.2154 - val_mean_squared_error: 0.2154\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0390 - mean_squared_error: 0.0390 - val_loss: 0.1410 - val_mean_squared_error: 0.1410\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.1764 - val_mean_squared_error: 0.1764\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0293 - mean_squared_error: 0.0293 - val_loss: 0.1969 - val_mean_squared_error: 0.1969\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0277 - mean_squared_error: 0.0277 - val_loss: 0.1667 - val_mean_squared_error: 0.1667\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.1590 - val_mean_squared_error: 0.1590\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.1595 - val_mean_squared_error: 0.1595\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.1537 - val_mean_squared_error: 0.1537\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.1545 - val_mean_squared_error: 0.1545\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.1519 - val_mean_squared_error: 0.1519\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.1549 - val_mean_squared_error: 0.1549\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.1475 - val_mean_squared_error: 0.1475\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.1492 - val_mean_squared_error: 0.1492\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.1422 - val_mean_squared_error: 0.1422\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.1475 - val_mean_squared_error: 0.1475\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.1410 - val_mean_squared_error: 0.1410\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.1449 - val_mean_squared_error: 0.1449\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.1365 - val_mean_squared_error: 0.1365\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.1355 - val_mean_squared_error: 0.1355\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.1393 - val_mean_squared_error: 0.1393\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.1331 - val_mean_squared_error: 0.1331\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.1315 - val_mean_squared_error: 0.1315\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.1267 - val_mean_squared_error: 0.1267\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.1331 - val_mean_squared_error: 0.1331\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1251 - val_mean_squared_error: 0.1251\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.1223 - val_mean_squared_error: 0.1223\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.1271 - val_mean_squared_error: 0.1271\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.1204 - val_mean_squared_error: 0.1204\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.1217 - val_mean_squared_error: 0.1217\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.1170 - val_mean_squared_error: 0.1170\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.1165 - val_mean_squared_error: 0.1165\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.1141 - val_mean_squared_error: 0.1141\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.1127 - val_mean_squared_error: 0.1127\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.1124 - val_mean_squared_error: 0.1124\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.1070 - val_mean_squared_error: 0.1070\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.1100 - val_mean_squared_error: 0.1100\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.1038 - val_mean_squared_error: 0.1038\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1040 - val_mean_squared_error: 0.1040\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.1006 - val_mean_squared_error: 0.1006\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1014 - val_mean_squared_error: 0.1014\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0992 - val_mean_squared_error: 0.0992\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0938 - val_mean_squared_error: 0.0938\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0978 - val_mean_squared_error: 0.0978\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 41us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0957 - val_mean_squared_error: 0.0957\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0910 - val_mean_squared_error: 0.0910\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0945 - val_mean_squared_error: 0.0945\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0908 - val_mean_squared_error: 0.0908\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0880 - val_mean_squared_error: 0.0880\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0865 - val_mean_squared_error: 0.0865\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0861 - val_mean_squared_error: 0.0861\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0846 - val_mean_squared_error: 0.0846\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0828 - val_mean_squared_error: 0.0828\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0820 - val_mean_squared_error: 0.0820\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0815 - val_mean_squared_error: 0.0815\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0812 - val_mean_squared_error: 0.0812\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0796 - val_mean_squared_error: 0.0796\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0780 - val_mean_squared_error: 0.0780\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0774 - val_mean_squared_error: 0.0774\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0763 - val_mean_squared_error: 0.0763\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0768 - val_mean_squared_error: 0.0768\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0751 - val_mean_squared_error: 0.0751\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0749 - val_mean_squared_error: 0.0749\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0750 - val_mean_squared_error: 0.0750\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0735 - val_mean_squared_error: 0.0735\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0737 - val_mean_squared_error: 0.0737\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0726 - val_mean_squared_error: 0.0726\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0726 - val_mean_squared_error: 0.0726\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0720 - val_mean_squared_error: 0.0720\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0721 - val_mean_squared_error: 0.0721\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0708 - val_mean_squared_error: 0.0708\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0705 - val_mean_squared_error: 0.0705\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0706 - val_mean_squared_error: 0.0706\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0693 - val_mean_squared_error: 0.0693\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0691 - val_mean_squared_error: 0.0691\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0698 - val_mean_squared_error: 0.0698\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0685 - val_mean_squared_error: 0.0685\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0690 - val_mean_squared_error: 0.0690\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0682 - val_mean_squared_error: 0.0682\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0695 - val_mean_squared_error: 0.0695\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0673 - val_mean_squared_error: 0.0673\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0681 - val_mean_squared_error: 0.0681\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0677 - val_mean_squared_error: 0.0677\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0679 - val_mean_squared_error: 0.0679\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0667 - val_mean_squared_error: 0.0667\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0677 - val_mean_squared_error: 0.0677\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0666 - val_mean_squared_error: 0.0666\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0673 - val_mean_squared_error: 0.0673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0664 - val_mean_squared_error: 0.0664\n",
      "It has been 2.845736026763916 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.3564 - mean_squared_error: 0.3564 - val_loss: 0.1448 - val_mean_squared_error: 0.1448\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0893 - mean_squared_error: 0.0893 - val_loss: 0.2748 - val_mean_squared_error: 0.2748\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0962 - mean_squared_error: 0.0962 - val_loss: 0.1719 - val_mean_squared_error: 0.1719\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0607 - mean_squared_error: 0.0607 - val_loss: 0.0787 - val_mean_squared_error: 0.0787\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0576 - mean_squared_error: 0.0576 - val_loss: 0.0835 - val_mean_squared_error: 0.0835\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0475 - mean_squared_error: 0.0475 - val_loss: 0.0673 - val_mean_squared_error: 0.0673\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0424 - mean_squared_error: 0.0424 - val_loss: 0.0639 - val_mean_squared_error: 0.0639\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0618 - val_mean_squared_error: 0.0618\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0619 - val_mean_squared_error: 0.0619\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0602 - val_mean_squared_error: 0.0602\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0291 - mean_squared_error: 0.0291 - val_loss: 0.0591 - val_mean_squared_error: 0.0591\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.0614 - val_mean_squared_error: 0.0614\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0645 - val_mean_squared_error: 0.0645\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0581 - val_mean_squared_error: 0.0581\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0647 - val_mean_squared_error: 0.0647\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0687 - val_mean_squared_error: 0.0687\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0626 - val_mean_squared_error: 0.0626\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0693 - val_mean_squared_error: 0.0693\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0668 - val_mean_squared_error: 0.0668\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0783 - val_mean_squared_error: 0.0783\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0654 - val_mean_squared_error: 0.0654\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0697 - val_mean_squared_error: 0.0697\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0796 - val_mean_squared_error: 0.0796\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0751 - val_mean_squared_error: 0.0751\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0803 - val_mean_squared_error: 0.0803\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0815 - val_mean_squared_error: 0.0815\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0811 - val_mean_squared_error: 0.0811\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0976 - val_mean_squared_error: 0.0976\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0914 - val_mean_squared_error: 0.0914\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0900 - val_mean_squared_error: 0.0900\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.1059 - val_mean_squared_error: 0.1059\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.1029 - val_mean_squared_error: 0.1029\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.1071 - val_mean_squared_error: 0.1071\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1118 - val_mean_squared_error: 0.1118\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1053 - val_mean_squared_error: 0.1053\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1118 - val_mean_squared_error: 0.1118\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1107 - val_mean_squared_error: 0.1107\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.1199 - val_mean_squared_error: 0.1199\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.1105 - val_mean_squared_error: 0.1105\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.1211 - val_mean_squared_error: 0.1211\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.1212 - val_mean_squared_error: 0.1212\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.1207 - val_mean_squared_error: 0.1207\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1174 - val_mean_squared_error: 0.1174\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1261 - val_mean_squared_error: 0.1261\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 39us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.1304 - val_mean_squared_error: 0.1304\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1301 - val_mean_squared_error: 0.1301\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1316 - val_mean_squared_error: 0.1316\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1459 - val_mean_squared_error: 0.1459\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.1257 - val_mean_squared_error: 0.1257\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1407 - val_mean_squared_error: 0.1407\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1430 - val_mean_squared_error: 0.1430\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1423 - val_mean_squared_error: 0.1423\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1418 - val_mean_squared_error: 0.1418\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1556 - val_mean_squared_error: 0.1556\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1415 - val_mean_squared_error: 0.1415\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1537 - val_mean_squared_error: 0.1537\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1585 - val_mean_squared_error: 0.1585\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1524 - val_mean_squared_error: 0.1524\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1548 - val_mean_squared_error: 0.1548\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1527 - val_mean_squared_error: 0.1527\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1593 - val_mean_squared_error: 0.1593\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1591 - val_mean_squared_error: 0.1591\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1642 - val_mean_squared_error: 0.1642\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1628 - val_mean_squared_error: 0.1628\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1617 - val_mean_squared_error: 0.1617\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1721 - val_mean_squared_error: 0.1721\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1673 - val_mean_squared_error: 0.1673\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1656 - val_mean_squared_error: 0.1656\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1679 - val_mean_squared_error: 0.1679\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1882 - val_mean_squared_error: 0.1882\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1799 - val_mean_squared_error: 0.1799\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1809 - val_mean_squared_error: 0.1809\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1792 - val_mean_squared_error: 0.1792\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1840 - val_mean_squared_error: 0.1840\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1888 - val_mean_squared_error: 0.1888\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1880 - val_mean_squared_error: 0.1880\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1823 - val_mean_squared_error: 0.1823\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1981 - val_mean_squared_error: 0.1981\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1809 - val_mean_squared_error: 0.1809\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.2061 - val_mean_squared_error: 0.2061\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1943 - val_mean_squared_error: 0.1943\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2050 - val_mean_squared_error: 0.2050\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2112 - val_mean_squared_error: 0.2112\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1809 - val_mean_squared_error: 0.1809\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2236 - val_mean_squared_error: 0.2236\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1980 - val_mean_squared_error: 0.1980\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2258 - val_mean_squared_error: 0.2258\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1873 - val_mean_squared_error: 0.1873\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2363 - val_mean_squared_error: 0.2363\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1990 - val_mean_squared_error: 0.1990\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2302 - val_mean_squared_error: 0.2302\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2100 - val_mean_squared_error: 0.2100\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.2079 - val_mean_squared_error: 0.2079\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.2222 - val_mean_squared_error: 0.2222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2150 - val_mean_squared_error: 0.2150\n",
      "It has been 2.898299217224121 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 2ms/step - loss: 0.0766 - mean_squared_error: 0.0766 - val_loss: 0.3750 - val_mean_squared_error: 0.3750\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.1848 - val_mean_squared_error: 0.1848\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 33us/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0924 - val_mean_squared_error: 0.0924\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.1550 - val_mean_squared_error: 0.1550\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.1250 - val_mean_squared_error: 0.1250\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.1125 - val_mean_squared_error: 0.1125\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.1266 - val_mean_squared_error: 0.1266\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.1108 - val_mean_squared_error: 0.1108\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.1204 - val_mean_squared_error: 0.1204\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.1121 - val_mean_squared_error: 0.1121\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.1093 - val_mean_squared_error: 0.1093\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1104 - val_mean_squared_error: 0.1104\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1076 - val_mean_squared_error: 0.1076\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.1033 - val_mean_squared_error: 0.1033\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0998 - val_mean_squared_error: 0.0998\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0991 - val_mean_squared_error: 0.0991\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0978 - val_mean_squared_error: 0.0978\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0938 - val_mean_squared_error: 0.0938\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0958 - val_mean_squared_error: 0.0958\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0896 - val_mean_squared_error: 0.0896\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0902 - val_mean_squared_error: 0.0902\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0909 - val_mean_squared_error: 0.0909\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0850 - val_mean_squared_error: 0.0850\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0855 - val_mean_squared_error: 0.0855\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0841 - val_mean_squared_error: 0.0841\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0829 - val_mean_squared_error: 0.0829\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0825 - val_mean_squared_error: 0.0825\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0824 - val_mean_squared_error: 0.0824\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0806 - val_mean_squared_error: 0.0806\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0813 - val_mean_squared_error: 0.0813\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0792 - val_mean_squared_error: 0.0792\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0791 - val_mean_squared_error: 0.0791\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0796 - val_mean_squared_error: 0.0796\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0777 - val_mean_squared_error: 0.0777\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0781 - val_mean_squared_error: 0.0781\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0773 - val_mean_squared_error: 0.0773\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0760 - val_mean_squared_error: 0.0760\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0820 - val_mean_squared_error: 0.0820\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0758 - val_mean_squared_error: 0.0758\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0798 - val_mean_squared_error: 0.0798\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0758 - val_mean_squared_error: 0.0758\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0798 - val_mean_squared_error: 0.0798\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0755 - val_mean_squared_error: 0.0755\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0784 - val_mean_squared_error: 0.0784\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0764 - val_mean_squared_error: 0.0764\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 43us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0759 - val_mean_squared_error: 0.0759\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0756 - val_mean_squared_error: 0.0756\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0743 - val_mean_squared_error: 0.0743\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0808 - val_mean_squared_error: 0.0808\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0832 - val_mean_squared_error: 0.0832\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0760 - val_mean_squared_error: 0.0760\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0803 - val_mean_squared_error: 0.0803\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0774 - val_mean_squared_error: 0.0774\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0797 - val_mean_squared_error: 0.0797\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0770 - val_mean_squared_error: 0.0770\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0797 - val_mean_squared_error: 0.0797\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0834 - val_mean_squared_error: 0.0834\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0833 - val_mean_squared_error: 0.0833\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0733 - val_mean_squared_error: 0.0733\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0959 - val_mean_squared_error: 0.0959\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0800 - val_mean_squared_error: 0.0800\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0810 - val_mean_squared_error: 0.0810\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0818 - val_mean_squared_error: 0.0818\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0895 - val_mean_squared_error: 0.0895\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0828 - val_mean_squared_error: 0.0828\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0848 - val_mean_squared_error: 0.0848\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0940 - val_mean_squared_error: 0.0940\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0854 - val_mean_squared_error: 0.0854\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0877 - val_mean_squared_error: 0.0877\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0931 - val_mean_squared_error: 0.0931\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0942 - val_mean_squared_error: 0.0942\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0912 - val_mean_squared_error: 0.0912\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0929 - val_mean_squared_error: 0.0929\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0913 - val_mean_squared_error: 0.0913\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0916 - val_mean_squared_error: 0.0916\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0951 - val_mean_squared_error: 0.0951\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1027 - val_mean_squared_error: 0.1027\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0937 - val_mean_squared_error: 0.0937\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0888 - val_mean_squared_error: 0.0888\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0933 - val_mean_squared_error: 0.0933\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0963 - val_mean_squared_error: 0.0963\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0974 - val_mean_squared_error: 0.0974\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0987 - val_mean_squared_error: 0.0987\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0879 - val_mean_squared_error: 0.0879\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0998 - val_mean_squared_error: 0.0998\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1117 - val_mean_squared_error: 0.1117\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1002 - val_mean_squared_error: 0.1002\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0938 - val_mean_squared_error: 0.0938\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0939 - val_mean_squared_error: 0.0939\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0989 - val_mean_squared_error: 0.0989\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1143 - val_mean_squared_error: 0.1143\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.1058 - val_mean_squared_error: 0.1058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.1184 - val_mean_squared_error: 0.1184\n",
      "It has been 2.995223045349121 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.0525 - mean_squared_error: 0.0525 - val_loss: 0.1961 - val_mean_squared_error: 0.1961\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0297 - mean_squared_error: 0.0297 - val_loss: 0.1868 - val_mean_squared_error: 0.1868\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.2160 - val_mean_squared_error: 0.2160\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.1755 - val_mean_squared_error: 0.1755\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.1926 - val_mean_squared_error: 0.1926\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.1757 - val_mean_squared_error: 0.1757\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.1796 - val_mean_squared_error: 0.1796\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.1646 - val_mean_squared_error: 0.1646\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.1660 - val_mean_squared_error: 0.1660\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.1487 - val_mean_squared_error: 0.1487\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.1269 - val_mean_squared_error: 0.1269\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.1240 - val_mean_squared_error: 0.1240\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.1422 - val_mean_squared_error: 0.1422\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.1080 - val_mean_squared_error: 0.1080\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.1122 - val_mean_squared_error: 0.1122\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.1127 - val_mean_squared_error: 0.1127\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.1144 - val_mean_squared_error: 0.1144\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.1076 - val_mean_squared_error: 0.1076\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0978 - val_mean_squared_error: 0.0978\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0965 - val_mean_squared_error: 0.0965\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1018 - val_mean_squared_error: 0.1018\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0949 - val_mean_squared_error: 0.0949\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0904 - val_mean_squared_error: 0.0904\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0886 - val_mean_squared_error: 0.0886\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0901 - val_mean_squared_error: 0.0901\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0884 - val_mean_squared_error: 0.0884\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0887 - val_mean_squared_error: 0.0887\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0832 - val_mean_squared_error: 0.0832\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0828 - val_mean_squared_error: 0.0828\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0806 - val_mean_squared_error: 0.0806\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0808 - val_mean_squared_error: 0.0808\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 35us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0907 - val_mean_squared_error: 0.0907\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0809 - val_mean_squared_error: 0.0809\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0810 - val_mean_squared_error: 0.0810\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0785 - val_mean_squared_error: 0.0785\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0787 - val_mean_squared_error: 0.0787\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0842 - val_mean_squared_error: 0.0842\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0777 - val_mean_squared_error: 0.0777\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0788 - val_mean_squared_error: 0.0788\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0766 - val_mean_squared_error: 0.0766\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0768 - val_mean_squared_error: 0.0768\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0994 - val_mean_squared_error: 0.0994\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0924 - val_mean_squared_error: 0.0924\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0752 - val_mean_squared_error: 0.0752\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0898 - val_mean_squared_error: 0.0898\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0919 - val_mean_squared_error: 0.0919\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0907 - val_mean_squared_error: 0.0907\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 43us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0897 - val_mean_squared_error: 0.0897\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0828 - val_mean_squared_error: 0.0828\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1012 - val_mean_squared_error: 0.1012\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0942 - val_mean_squared_error: 0.0942\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1094 - val_mean_squared_error: 0.1094\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0998 - val_mean_squared_error: 0.0998\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0891 - val_mean_squared_error: 0.0891\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1114 - val_mean_squared_error: 0.1114\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0998 - val_mean_squared_error: 0.0998\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0924 - val_mean_squared_error: 0.0924\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1119 - val_mean_squared_error: 0.1119\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1141 - val_mean_squared_error: 0.1141\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0966 - val_mean_squared_error: 0.0966\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1117 - val_mean_squared_error: 0.1117\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1181 - val_mean_squared_error: 0.1181\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1296 - val_mean_squared_error: 0.1296\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1287 - val_mean_squared_error: 0.1287\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1329 - val_mean_squared_error: 0.1329\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1438 - val_mean_squared_error: 0.1438\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1154 - val_mean_squared_error: 0.1154\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1376 - val_mean_squared_error: 0.1376\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1362 - val_mean_squared_error: 0.1362\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1389 - val_mean_squared_error: 0.1389\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1263 - val_mean_squared_error: 0.1263\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1173 - val_mean_squared_error: 0.1173\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1443 - val_mean_squared_error: 0.1443\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1613 - val_mean_squared_error: 0.1613\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1464 - val_mean_squared_error: 0.1464\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1355 - val_mean_squared_error: 0.1355\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1635 - val_mean_squared_error: 0.1635\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1858 - val_mean_squared_error: 0.1858\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1643 - val_mean_squared_error: 0.1643\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1381 - val_mean_squared_error: 0.1381\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1388 - val_mean_squared_error: 0.1388\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1482 - val_mean_squared_error: 0.1482\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1627 - val_mean_squared_error: 0.1627\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1873 - val_mean_squared_error: 0.1873\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2062 - val_mean_squared_error: 0.2062\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1709 - val_mean_squared_error: 0.1709\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1497 - val_mean_squared_error: 0.1497\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1622 - val_mean_squared_error: 0.1622\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1533 - val_mean_squared_error: 0.1533\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.2112 - val_mean_squared_error: 0.2112\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1728 - val_mean_squared_error: 0.1728\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1918 - val_mean_squared_error: 0.1918\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1672 - val_mean_squared_error: 0.1672\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2004 - val_mean_squared_error: 0.2004\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.2106 - val_mean_squared_error: 0.2106\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1800 - val_mean_squared_error: 0.1800\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2267 - val_mean_squared_error: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2003 - val_mean_squared_error: 0.2003\n",
      "It has been 3.0813891887664795 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.1080 - val_mean_squared_error: 0.1080\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0260 - mean_squared_error: 0.0260 - val_loss: 0.1177 - val_mean_squared_error: 0.1177\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.1092 - val_mean_squared_error: 0.1092\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.1061 - val_mean_squared_error: 0.1061\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0215 - mean_squared_error: 0.0215 - val_loss: 0.1002 - val_mean_squared_error: 0.1002\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0841 - val_mean_squared_error: 0.0841\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.1011 - val_mean_squared_error: 0.1011\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0884 - val_mean_squared_error: 0.0884\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0792 - val_mean_squared_error: 0.0792\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0947 - val_mean_squared_error: 0.0947\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0807 - val_mean_squared_error: 0.0807\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0883 - val_mean_squared_error: 0.0883\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0724 - val_mean_squared_error: 0.0724\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1066 - val_mean_squared_error: 0.1066\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0734 - val_mean_squared_error: 0.0734\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0933 - val_mean_squared_error: 0.0933\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0784 - val_mean_squared_error: 0.0784\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0683 - val_mean_squared_error: 0.0683\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0907 - val_mean_squared_error: 0.0907\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0691 - val_mean_squared_error: 0.0691\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0826 - val_mean_squared_error: 0.0826\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0690 - val_mean_squared_error: 0.0690\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0724 - val_mean_squared_error: 0.0724\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0687 - val_mean_squared_error: 0.0687\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0699 - val_mean_squared_error: 0.0699\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0696 - val_mean_squared_error: 0.0696\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0707 - val_mean_squared_error: 0.0707\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0716 - val_mean_squared_error: 0.0716\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0710 - val_mean_squared_error: 0.0710\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0691 - val_mean_squared_error: 0.0691\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0696 - val_mean_squared_error: 0.0696\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0693 - val_mean_squared_error: 0.0693\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0699 - val_mean_squared_error: 0.0699\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0692 - val_mean_squared_error: 0.0692\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0701 - val_mean_squared_error: 0.0701\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0719 - val_mean_squared_error: 0.0719\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0707 - val_mean_squared_error: 0.0707\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0717 - val_mean_squared_error: 0.0717\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 68us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0739 - val_mean_squared_error: 0.0739\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 80us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0719 - val_mean_squared_error: 0.0719\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 87us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0711 - val_mean_squared_error: 0.0711\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 103us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0726 - val_mean_squared_error: 0.0726\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 86us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0765 - val_mean_squared_error: 0.0765\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 86us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0768 - val_mean_squared_error: 0.0768\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 103us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0766 - val_mean_squared_error: 0.0766\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 100us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0785 - val_mean_squared_error: 0.0785\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 95us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0740 - val_mean_squared_error: 0.0740\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 98us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0758 - val_mean_squared_error: 0.0758\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0792 - val_mean_squared_error: 0.0792\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0816 - val_mean_squared_error: 0.0816\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0823 - val_mean_squared_error: 0.0823\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0877 - val_mean_squared_error: 0.0877\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0817 - val_mean_squared_error: 0.0817\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0796 - val_mean_squared_error: 0.0796\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0941 - val_mean_squared_error: 0.0941\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0957 - val_mean_squared_error: 0.0957\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0820 - val_mean_squared_error: 0.0820\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1082 - val_mean_squared_error: 0.1082\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0921 - val_mean_squared_error: 0.0921\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0849 - val_mean_squared_error: 0.0849\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0968 - val_mean_squared_error: 0.0968\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0993 - val_mean_squared_error: 0.0993\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0960 - val_mean_squared_error: 0.0960\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0889 - val_mean_squared_error: 0.0889\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1029 - val_mean_squared_error: 0.1029\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1018 - val_mean_squared_error: 0.1018\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1011 - val_mean_squared_error: 0.1011\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0968 - val_mean_squared_error: 0.0968\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1080 - val_mean_squared_error: 0.1080\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1166 - val_mean_squared_error: 0.1166\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1090 - val_mean_squared_error: 0.1090\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0970 - val_mean_squared_error: 0.0970\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1099 - val_mean_squared_error: 0.1099\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1098 - val_mean_squared_error: 0.1098\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1117 - val_mean_squared_error: 0.1117\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1198 - val_mean_squared_error: 0.1198\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1128 - val_mean_squared_error: 0.1128\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1135 - val_mean_squared_error: 0.1135\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1095 - val_mean_squared_error: 0.1095\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1169 - val_mean_squared_error: 0.1169\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1220 - val_mean_squared_error: 0.1220\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1352 - val_mean_squared_error: 0.1352\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1504 - val_mean_squared_error: 0.1504\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1230 - val_mean_squared_error: 0.1230\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1193 - val_mean_squared_error: 0.1193\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1245 - val_mean_squared_error: 0.1245\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1367 - val_mean_squared_error: 0.1367\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1336 - val_mean_squared_error: 0.1336\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1592 - val_mean_squared_error: 0.1592\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1204 - val_mean_squared_error: 0.1204\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1188 - val_mean_squared_error: 0.1188\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1361 - val_mean_squared_error: 0.1361\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1406 - val_mean_squared_error: 0.1406\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1459 - val_mean_squared_error: 0.1459\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1424 - val_mean_squared_error: 0.1424\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1381 - val_mean_squared_error: 0.1381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1265 - val_mean_squared_error: 0.1265\n",
      "It has been 3.3396661281585693 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.1645 - mean_squared_error: 0.1645 - val_loss: 0.2215 - val_mean_squared_error: 0.2215\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 92us/step - loss: 0.0861 - mean_squared_error: 0.0861 - val_loss: 0.2934 - val_mean_squared_error: 0.2934\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 82us/step - loss: 0.0463 - mean_squared_error: 0.0463 - val_loss: 0.1040 - val_mean_squared_error: 0.1040\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 89us/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.1190 - val_mean_squared_error: 0.1190\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 95us/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.1483 - val_mean_squared_error: 0.1483\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 73us/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.1111 - val_mean_squared_error: 0.1111\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.1150 - val_mean_squared_error: 0.1150\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.1114 - val_mean_squared_error: 0.1114\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.1076 - val_mean_squared_error: 0.1076\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.1084 - val_mean_squared_error: 0.1084\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.1042 - val_mean_squared_error: 0.1042\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.1029 - val_mean_squared_error: 0.1029\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.1000 - val_mean_squared_error: 0.1000\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.1001 - val_mean_squared_error: 0.1001\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.1003 - val_mean_squared_error: 0.1003\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0981 - val_mean_squared_error: 0.0981\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0979 - val_mean_squared_error: 0.0979\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0961 - val_mean_squared_error: 0.0961\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0955 - val_mean_squared_error: 0.0955\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0944 - val_mean_squared_error: 0.0944\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0944 - val_mean_squared_error: 0.0944\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0931 - val_mean_squared_error: 0.0931\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0922 - val_mean_squared_error: 0.0922\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0939 - val_mean_squared_error: 0.0939\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0902 - val_mean_squared_error: 0.0902\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0897 - val_mean_squared_error: 0.0897\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0903 - val_mean_squared_error: 0.0903\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0880 - val_mean_squared_error: 0.0880\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0852 - val_mean_squared_error: 0.0852\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0899 - val_mean_squared_error: 0.0899\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0859 - val_mean_squared_error: 0.0859\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0871 - val_mean_squared_error: 0.0871\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0833 - val_mean_squared_error: 0.0833\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0918 - val_mean_squared_error: 0.0918\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0852 - val_mean_squared_error: 0.0852\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0887 - val_mean_squared_error: 0.0887\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0871 - val_mean_squared_error: 0.0871\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0813 - val_mean_squared_error: 0.0813\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0948 - val_mean_squared_error: 0.0948\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0829 - val_mean_squared_error: 0.0829\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 70us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 68us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 77us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0904 - val_mean_squared_error: 0.0904\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 81us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0964 - val_mean_squared_error: 0.0964\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 86us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0830 - val_mean_squared_error: 0.0830\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 101us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0927 - val_mean_squared_error: 0.0927\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 103us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0992 - val_mean_squared_error: 0.0992\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 82us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0869 - val_mean_squared_error: 0.0869\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 87us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0913 - val_mean_squared_error: 0.0913\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 89us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0910 - val_mean_squared_error: 0.0910\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 81us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 91us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0893 - val_mean_squared_error: 0.0893\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 79us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1033 - val_mean_squared_error: 0.1033\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 96us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0921 - val_mean_squared_error: 0.0921\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 92us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 108us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1100 - val_mean_squared_error: 0.1100\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 82us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0809 - val_mean_squared_error: 0.0809\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 98us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0950 - val_mean_squared_error: 0.0950\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 85us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1006 - val_mean_squared_error: 0.1006\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 80us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0837 - val_mean_squared_error: 0.0837\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 95us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0948 - val_mean_squared_error: 0.0948\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 67us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1121 - val_mean_squared_error: 0.1121\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 90us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0913 - val_mean_squared_error: 0.0913\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 88us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1008 - val_mean_squared_error: 0.1008\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 87us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 99us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0978 - val_mean_squared_error: 0.0978\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 90us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1049 - val_mean_squared_error: 0.1049\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 78us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0968 - val_mean_squared_error: 0.0968\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 98us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1096 - val_mean_squared_error: 0.1096\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 73us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1085 - val_mean_squared_error: 0.1085\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 91us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0967 - val_mean_squared_error: 0.0967\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 71us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1191 - val_mean_squared_error: 0.1191\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 72us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0993 - val_mean_squared_error: 0.0993\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 90us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1001 - val_mean_squared_error: 0.1001\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 65us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1054 - val_mean_squared_error: 0.1054\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 79us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1185 - val_mean_squared_error: 0.1185\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 73us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1164 - val_mean_squared_error: 0.1164\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 70us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0954 - val_mean_squared_error: 0.0954\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 79us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1179 - val_mean_squared_error: 0.1179\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 85us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1105 - val_mean_squared_error: 0.1105\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 75us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1230 - val_mean_squared_error: 0.1230\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 84us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1081 - val_mean_squared_error: 0.1081\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 69us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1258 - val_mean_squared_error: 0.1258\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 86us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1063 - val_mean_squared_error: 0.1063\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 73us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1213 - val_mean_squared_error: 0.1213\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 63us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1394 - val_mean_squared_error: 0.1394\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 91us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1162 - val_mean_squared_error: 0.1162\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 86us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1178 - val_mean_squared_error: 0.1178\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 74us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1322 - val_mean_squared_error: 0.1322\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1105 - val_mean_squared_error: 0.1105\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1381 - val_mean_squared_error: 0.1381\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1405 - val_mean_squared_error: 0.1405\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1330 - val_mean_squared_error: 0.1330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0996 - val_mean_squared_error: 0.0996\n",
      "It has been 4.304979085922241 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.1298 - val_mean_squared_error: 0.1298\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.1357 - val_mean_squared_error: 0.1357\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.1226 - val_mean_squared_error: 0.1226\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.1196 - val_mean_squared_error: 0.1196\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.1325 - val_mean_squared_error: 0.1325\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.1203 - val_mean_squared_error: 0.1203\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.1213 - val_mean_squared_error: 0.1213\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.1487 - val_mean_squared_error: 0.1487\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.1083 - val_mean_squared_error: 0.1083\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.1179 - val_mean_squared_error: 0.1179\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.1125 - val_mean_squared_error: 0.1125\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1140 - val_mean_squared_error: 0.1140\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1072 - val_mean_squared_error: 0.1072\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1050 - val_mean_squared_error: 0.1050\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1018 - val_mean_squared_error: 0.1018\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1020 - val_mean_squared_error: 0.1020\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0990 - val_mean_squared_error: 0.0990\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0998 - val_mean_squared_error: 0.0998\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0988 - val_mean_squared_error: 0.0988\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0983 - val_mean_squared_error: 0.0983\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0981 - val_mean_squared_error: 0.0981\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1000 - val_mean_squared_error: 0.1000\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0978 - val_mean_squared_error: 0.0978\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0985 - val_mean_squared_error: 0.0985\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0991 - val_mean_squared_error: 0.0991\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0988 - val_mean_squared_error: 0.0988\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1008 - val_mean_squared_error: 0.1008\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1013 - val_mean_squared_error: 0.1013\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1110 - val_mean_squared_error: 0.1110\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1015 - val_mean_squared_error: 0.1015\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1043 - val_mean_squared_error: 0.1043\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1047 - val_mean_squared_error: 0.1047\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1102 - val_mean_squared_error: 0.1102\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1128 - val_mean_squared_error: 0.1128\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1057 - val_mean_squared_error: 0.1057\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1101 - val_mean_squared_error: 0.1101\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1121 - val_mean_squared_error: 0.1121\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1136 - val_mean_squared_error: 0.1136\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1158 - val_mean_squared_error: 0.1158\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1130 - val_mean_squared_error: 0.1130\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1190 - val_mean_squared_error: 0.1190\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1284 - val_mean_squared_error: 0.1284\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1182 - val_mean_squared_error: 0.1182\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1322 - val_mean_squared_error: 0.1322\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 43us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1348 - val_mean_squared_error: 0.1348\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1393 - val_mean_squared_error: 0.1393\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1318 - val_mean_squared_error: 0.1318\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1185 - val_mean_squared_error: 0.1185\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1255 - val_mean_squared_error: 0.1255\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1419 - val_mean_squared_error: 0.1419\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1501 - val_mean_squared_error: 0.1501\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1399 - val_mean_squared_error: 0.1399\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1361 - val_mean_squared_error: 0.1361\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1353 - val_mean_squared_error: 0.1353\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1439 - val_mean_squared_error: 0.1439\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1660 - val_mean_squared_error: 0.1660\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1580 - val_mean_squared_error: 0.1580\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1516 - val_mean_squared_error: 0.1516\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1478 - val_mean_squared_error: 0.1478\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1598 - val_mean_squared_error: 0.1598\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1558 - val_mean_squared_error: 0.1558\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1525 - val_mean_squared_error: 0.1525\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1574 - val_mean_squared_error: 0.1574\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1720 - val_mean_squared_error: 0.1720\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1853 - val_mean_squared_error: 0.1853\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1614 - val_mean_squared_error: 0.1614\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1607 - val_mean_squared_error: 0.1607\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1477 - val_mean_squared_error: 0.1477\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1669 - val_mean_squared_error: 0.1669\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1857 - val_mean_squared_error: 0.1857\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2268 - val_mean_squared_error: 0.2268\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1844 - val_mean_squared_error: 0.1844\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1795 - val_mean_squared_error: 0.1795\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1686 - val_mean_squared_error: 0.1686\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1779 - val_mean_squared_error: 0.1779\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.1789 - val_mean_squared_error: 0.1789\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1876 - val_mean_squared_error: 0.1876\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.1749 - val_mean_squared_error: 0.1749\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1900 - val_mean_squared_error: 0.1900\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.2059 - val_mean_squared_error: 0.2059\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.1989 - val_mean_squared_error: 0.1989\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.1994 - val_mean_squared_error: 0.1994\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.1966 - val_mean_squared_error: 0.1966\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.1928 - val_mean_squared_error: 0.1928\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.1908 - val_mean_squared_error: 0.1908\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.2002 - val_mean_squared_error: 0.2002\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.1972 - val_mean_squared_error: 0.1972\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.1818 - val_mean_squared_error: 0.1818\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.2018 - val_mean_squared_error: 0.2018\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.1853 - val_mean_squared_error: 0.1853\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.1915 - val_mean_squared_error: 0.1915\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.2023 - val_mean_squared_error: 0.2023\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.2199 - val_mean_squared_error: 0.2199\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.2216 - val_mean_squared_error: 0.2216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.2396 - val_mean_squared_error: 0.2396\n",
      "It has been 3.8149449825286865 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.1040 - mean_squared_error: 0.1040 - val_loss: 0.2513 - val_mean_squared_error: 0.2513\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0585 - mean_squared_error: 0.0585 - val_loss: 0.2397 - val_mean_squared_error: 0.2397\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.3359 - val_mean_squared_error: 0.3359\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.2606 - val_mean_squared_error: 0.2606\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0287 - mean_squared_error: 0.0287 - val_loss: 0.2339 - val_mean_squared_error: 0.2339\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.2586 - val_mean_squared_error: 0.2586\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.2550 - val_mean_squared_error: 0.2550\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.2453 - val_mean_squared_error: 0.2453\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.2463 - val_mean_squared_error: 0.2463\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.2470 - val_mean_squared_error: 0.2470\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0215 - mean_squared_error: 0.0215 - val_loss: 0.2425 - val_mean_squared_error: 0.2425\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.2489 - val_mean_squared_error: 0.2489\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.2502 - val_mean_squared_error: 0.2502\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.2414 - val_mean_squared_error: 0.2414\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.2444 - val_mean_squared_error: 0.2444\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.2490 - val_mean_squared_error: 0.2490\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.2461 - val_mean_squared_error: 0.2461\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.2393 - val_mean_squared_error: 0.2393\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.2561 - val_mean_squared_error: 0.2561\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.2395 - val_mean_squared_error: 0.2395\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.2479 - val_mean_squared_error: 0.2479\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.2483 - val_mean_squared_error: 0.2483\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.2477 - val_mean_squared_error: 0.2477\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.2563 - val_mean_squared_error: 0.2563\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.2530 - val_mean_squared_error: 0.2530\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.2468 - val_mean_squared_error: 0.2468\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.2608 - val_mean_squared_error: 0.2608\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.2541 - val_mean_squared_error: 0.2541\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.2412 - val_mean_squared_error: 0.2412\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.2661 - val_mean_squared_error: 0.2661\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.2515 - val_mean_squared_error: 0.2515\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.2604 - val_mean_squared_error: 0.2604\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.2427 - val_mean_squared_error: 0.2427\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.2631 - val_mean_squared_error: 0.2631\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.2475 - val_mean_squared_error: 0.2475\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.2560 - val_mean_squared_error: 0.2560\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.2677 - val_mean_squared_error: 0.2677\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.2571 - val_mean_squared_error: 0.2571\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.2725 - val_mean_squared_error: 0.2725\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.2759 - val_mean_squared_error: 0.2759\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.2493 - val_mean_squared_error: 0.2493\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.2741 - val_mean_squared_error: 0.2741\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.2904 - val_mean_squared_error: 0.2904\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.2624 - val_mean_squared_error: 0.2624\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.2595 - val_mean_squared_error: 0.2595\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.2774 - val_mean_squared_error: 0.2774\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.2674 - val_mean_squared_error: 0.2674\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.2976 - val_mean_squared_error: 0.2976\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.2538 - val_mean_squared_error: 0.2538\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 46us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.2950 - val_mean_squared_error: 0.2950\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.2840 - val_mean_squared_error: 0.2840\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.2716 - val_mean_squared_error: 0.2716\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.3069 - val_mean_squared_error: 0.3069\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.2644 - val_mean_squared_error: 0.2644\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.3089 - val_mean_squared_error: 0.3089\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.2706 - val_mean_squared_error: 0.2706\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.3105 - val_mean_squared_error: 0.3105\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.2792 - val_mean_squared_error: 0.2792\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.3089 - val_mean_squared_error: 0.3089\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.2877 - val_mean_squared_error: 0.2877\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.2821 - val_mean_squared_error: 0.2821\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.3144 - val_mean_squared_error: 0.3144\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.2904 - val_mean_squared_error: 0.2904\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.3029 - val_mean_squared_error: 0.3029\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2877 - val_mean_squared_error: 0.2877\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2987 - val_mean_squared_error: 0.2987\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.2760 - val_mean_squared_error: 0.2760\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.3367 - val_mean_squared_error: 0.3367\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2736 - val_mean_squared_error: 0.2736\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.3082 - val_mean_squared_error: 0.3082\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.3184 - val_mean_squared_error: 0.3184\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2847 - val_mean_squared_error: 0.2847\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.3164 - val_mean_squared_error: 0.3164\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2825 - val_mean_squared_error: 0.2825\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.3075 - val_mean_squared_error: 0.3075\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.3320 - val_mean_squared_error: 0.3320\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.2641 - val_mean_squared_error: 0.2641\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.3182 - val_mean_squared_error: 0.3182\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.3290 - val_mean_squared_error: 0.3290\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2792 - val_mean_squared_error: 0.2792\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.3363 - val_mean_squared_error: 0.3363\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.3214 - val_mean_squared_error: 0.3214\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.2899 - val_mean_squared_error: 0.2899\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.3315 - val_mean_squared_error: 0.3315\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.2967 - val_mean_squared_error: 0.2967\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.3129 - val_mean_squared_error: 0.3129\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.3397 - val_mean_squared_error: 0.3397\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.3131 - val_mean_squared_error: 0.3131\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2982 - val_mean_squared_error: 0.2982\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.3631 - val_mean_squared_error: 0.3631\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2963 - val_mean_squared_error: 0.2963\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2852 - val_mean_squared_error: 0.2852\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.3739 - val_mean_squared_error: 0.3739\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.3097 - val_mean_squared_error: 0.3097\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.3246 - val_mean_squared_error: 0.3246\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3468 - val_mean_squared_error: 0.3468\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.3376 - val_mean_squared_error: 0.3376\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.3332 - val_mean_squared_error: 0.3332\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.3071 - val_mean_squared_error: 0.3071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.3373 - val_mean_squared_error: 0.3373\n",
      "It has been 3.2323272228240967 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.0816 - mean_squared_error: 0.0816 - val_loss: 0.2362 - val_mean_squared_error: 0.2362\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0412 - mean_squared_error: 0.0412 - val_loss: 0.1046 - val_mean_squared_error: 0.1046\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 36us/step - loss: 0.0296 - mean_squared_error: 0.0296 - val_loss: 0.1465 - val_mean_squared_error: 0.1465\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.1096 - val_mean_squared_error: 0.1096\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.1445 - val_mean_squared_error: 0.1445\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.1332 - val_mean_squared_error: 0.1332\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.1433 - val_mean_squared_error: 0.1433\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.1383 - val_mean_squared_error: 0.1383\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.1464 - val_mean_squared_error: 0.1464\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.1298 - val_mean_squared_error: 0.1298\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.1564 - val_mean_squared_error: 0.1564\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.1280 - val_mean_squared_error: 0.1280\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.1420 - val_mean_squared_error: 0.1420\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.1332 - val_mean_squared_error: 0.1332\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.1409 - val_mean_squared_error: 0.1409\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.1313 - val_mean_squared_error: 0.1313\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.1312 - val_mean_squared_error: 0.1312\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.1212 - val_mean_squared_error: 0.1212\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.1404 - val_mean_squared_error: 0.1404\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.1266 - val_mean_squared_error: 0.1266\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.1277 - val_mean_squared_error: 0.1277\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1220 - val_mean_squared_error: 0.1220\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.1299 - val_mean_squared_error: 0.1299\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.1146 - val_mean_squared_error: 0.1146\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.1278 - val_mean_squared_error: 0.1278\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.1132 - val_mean_squared_error: 0.1132\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1177 - val_mean_squared_error: 0.1177\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.1243 - val_mean_squared_error: 0.1243\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.1116 - val_mean_squared_error: 0.1116\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1217 - val_mean_squared_error: 0.1217\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.1114 - val_mean_squared_error: 0.1114\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1094 - val_mean_squared_error: 0.1094\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1132 - val_mean_squared_error: 0.1132\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1092 - val_mean_squared_error: 0.1092\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1093 - val_mean_squared_error: 0.1093\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1071 - val_mean_squared_error: 0.1071\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1074 - val_mean_squared_error: 0.1074\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1057 - val_mean_squared_error: 0.1057\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1044 - val_mean_squared_error: 0.1044\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1049 - val_mean_squared_error: 0.1049\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1051 - val_mean_squared_error: 0.1051\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1035 - val_mean_squared_error: 0.1035\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1052 - val_mean_squared_error: 0.1052\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1023 - val_mean_squared_error: 0.1023\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1050 - val_mean_squared_error: 0.1050\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1040 - val_mean_squared_error: 0.1040\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1045 - val_mean_squared_error: 0.1045\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1085 - val_mean_squared_error: 0.1085\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 46us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1038 - val_mean_squared_error: 0.1038\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1123 - val_mean_squared_error: 0.1123\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1036 - val_mean_squared_error: 0.1036\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1050 - val_mean_squared_error: 0.1050\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1083 - val_mean_squared_error: 0.1083\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1159 - val_mean_squared_error: 0.1159\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1135 - val_mean_squared_error: 0.1135\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1074 - val_mean_squared_error: 0.1074\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1069 - val_mean_squared_error: 0.1069\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1127 - val_mean_squared_error: 0.1127\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1134 - val_mean_squared_error: 0.1134\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1210 - val_mean_squared_error: 0.1210\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1301 - val_mean_squared_error: 0.1301\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1385 - val_mean_squared_error: 0.1385\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1129 - val_mean_squared_error: 0.1129\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1203 - val_mean_squared_error: 0.1203\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1243 - val_mean_squared_error: 0.1243\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1280 - val_mean_squared_error: 0.1280\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1220 - val_mean_squared_error: 0.1220\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1332 - val_mean_squared_error: 0.1332\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1332 - val_mean_squared_error: 0.1332\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1349 - val_mean_squared_error: 0.1349\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1294 - val_mean_squared_error: 0.1294\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1357 - val_mean_squared_error: 0.1357\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1470 - val_mean_squared_error: 0.1470\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1468 - val_mean_squared_error: 0.1468\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1415 - val_mean_squared_error: 0.1415\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1570 - val_mean_squared_error: 0.1570\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1509 - val_mean_squared_error: 0.1509\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1482 - val_mean_squared_error: 0.1482\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1507 - val_mean_squared_error: 0.1507\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1399 - val_mean_squared_error: 0.1399\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1559 - val_mean_squared_error: 0.1559\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1784 - val_mean_squared_error: 0.1784\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1805 - val_mean_squared_error: 0.1805\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1590 - val_mean_squared_error: 0.1590\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1598 - val_mean_squared_error: 0.1598\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1437 - val_mean_squared_error: 0.1437\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1816 - val_mean_squared_error: 0.1816\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1574 - val_mean_squared_error: 0.1574\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1690 - val_mean_squared_error: 0.1690\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1737 - val_mean_squared_error: 0.1737\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 67us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1564 - val_mean_squared_error: 0.1564\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 63us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.1712 - val_mean_squared_error: 0.1712\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.1756 - val_mean_squared_error: 0.1756\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.1829 - val_mean_squared_error: 0.1829\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.2010 - val_mean_squared_error: 0.2010\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.1668 - val_mean_squared_error: 0.1668\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.1699 - val_mean_squared_error: 0.1699\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.1821 - val_mean_squared_error: 0.1821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.2001 - val_mean_squared_error: 0.2001\n",
      "It has been 3.3192079067230225 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.0886 - mean_squared_error: 0.0886 - val_loss: 0.0652 - val_mean_squared_error: 0.0652\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0392 - mean_squared_error: 0.0392 - val_loss: 0.1531 - val_mean_squared_error: 0.1531\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 34us/step - loss: 0.0297 - mean_squared_error: 0.0297 - val_loss: 0.1261 - val_mean_squared_error: 0.1261\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.1797 - val_mean_squared_error: 0.1797\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0780 - val_mean_squared_error: 0.0780\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.1098 - val_mean_squared_error: 0.1098\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.1132 - val_mean_squared_error: 0.1132\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.1149 - val_mean_squared_error: 0.1149\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.1289 - val_mean_squared_error: 0.1289\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.1292 - val_mean_squared_error: 0.1292\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.1108 - val_mean_squared_error: 0.1108\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.2090 - val_mean_squared_error: 0.2090\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.1062 - val_mean_squared_error: 0.1062\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.1375 - val_mean_squared_error: 0.1375\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.1808 - val_mean_squared_error: 0.1808\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.1478 - val_mean_squared_error: 0.1478\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.1507 - val_mean_squared_error: 0.1507\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1693 - val_mean_squared_error: 0.1693\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1530 - val_mean_squared_error: 0.1530\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.1662 - val_mean_squared_error: 0.1662\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1750 - val_mean_squared_error: 0.1750\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.1780 - val_mean_squared_error: 0.1780\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1845 - val_mean_squared_error: 0.1845\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.1458 - val_mean_squared_error: 0.1458\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1972 - val_mean_squared_error: 0.1972\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1637 - val_mean_squared_error: 0.1637\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1760 - val_mean_squared_error: 0.1760\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.2050 - val_mean_squared_error: 0.2050\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1609 - val_mean_squared_error: 0.1609\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1656 - val_mean_squared_error: 0.1656\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1890 - val_mean_squared_error: 0.1890\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.2091 - val_mean_squared_error: 0.2091\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1475 - val_mean_squared_error: 0.1475\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1805 - val_mean_squared_error: 0.1805\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1890 - val_mean_squared_error: 0.1890\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.2165 - val_mean_squared_error: 0.2165\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1712 - val_mean_squared_error: 0.1712\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.2152 - val_mean_squared_error: 0.2152\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1913 - val_mean_squared_error: 0.1913\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.2091 - val_mean_squared_error: 0.2091\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1720 - val_mean_squared_error: 0.1720\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.2313 - val_mean_squared_error: 0.2313\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.2167 - val_mean_squared_error: 0.2167\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.2050 - val_mean_squared_error: 0.2050\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2210 - val_mean_squared_error: 0.2210\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2136 - val_mean_squared_error: 0.2136\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2065 - val_mean_squared_error: 0.2065\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.2713 - val_mean_squared_error: 0.2713\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2375 - val_mean_squared_error: 0.2375\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 43us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2204 - val_mean_squared_error: 0.2204\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1917 - val_mean_squared_error: 0.1917\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2322 - val_mean_squared_error: 0.2322\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.2886 - val_mean_squared_error: 0.2886\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2432 - val_mean_squared_error: 0.2432\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2080 - val_mean_squared_error: 0.2080\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.2489 - val_mean_squared_error: 0.2489\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2397 - val_mean_squared_error: 0.2397\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.2158 - val_mean_squared_error: 0.2158\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.2539 - val_mean_squared_error: 0.2539\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2517 - val_mean_squared_error: 0.2517\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2493 - val_mean_squared_error: 0.2493\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.2720 - val_mean_squared_error: 0.2720\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2695 - val_mean_squared_error: 0.2695\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2432 - val_mean_squared_error: 0.2432\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2181 - val_mean_squared_error: 0.2181\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2223 - val_mean_squared_error: 0.2223\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2921 - val_mean_squared_error: 0.2921\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2702 - val_mean_squared_error: 0.2702\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2300 - val_mean_squared_error: 0.2300\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2218 - val_mean_squared_error: 0.2218\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.3096 - val_mean_squared_error: 0.3096\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2713 - val_mean_squared_error: 0.2713\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2196 - val_mean_squared_error: 0.2196\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2428 - val_mean_squared_error: 0.2428\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2472 - val_mean_squared_error: 0.2472\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2285 - val_mean_squared_error: 0.2285\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2692 - val_mean_squared_error: 0.2692\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2734 - val_mean_squared_error: 0.2734\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2859 - val_mean_squared_error: 0.2859\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2319 - val_mean_squared_error: 0.2319\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2426 - val_mean_squared_error: 0.2426\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2990 - val_mean_squared_error: 0.2990\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2863 - val_mean_squared_error: 0.2863\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.2707 - val_mean_squared_error: 0.2707\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2411 - val_mean_squared_error: 0.2411\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2719 - val_mean_squared_error: 0.2719\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.3091 - val_mean_squared_error: 0.3091\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2808 - val_mean_squared_error: 0.2808\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.2724 - val_mean_squared_error: 0.2724\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2914 - val_mean_squared_error: 0.2914\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2677 - val_mean_squared_error: 0.2677\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.3034 - val_mean_squared_error: 0.3034\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2894 - val_mean_squared_error: 0.2894\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2453 - val_mean_squared_error: 0.2453\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2790 - val_mean_squared_error: 0.2790\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2614 - val_mean_squared_error: 0.2614\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2776 - val_mean_squared_error: 0.2776\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.3131 - val_mean_squared_error: 0.3131\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.3057 - val_mean_squared_error: 0.3057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.2736 - val_mean_squared_error: 0.2736\n",
      "It has been 3.3254048824310303 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.1202 - mean_squared_error: 0.1202 - val_loss: 0.6994 - val_mean_squared_error: 0.6994\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0618 - mean_squared_error: 0.0618 - val_loss: 0.2640 - val_mean_squared_error: 0.2640\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.1382 - val_mean_squared_error: 0.1382\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.2040 - val_mean_squared_error: 0.2040\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0307 - mean_squared_error: 0.0307 - val_loss: 0.1313 - val_mean_squared_error: 0.1313\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.1696 - val_mean_squared_error: 0.1696\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.1440 - val_mean_squared_error: 0.1440\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.1527 - val_mean_squared_error: 0.1527\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.1373 - val_mean_squared_error: 0.1373\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.1294 - val_mean_squared_error: 0.1294\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.1224 - val_mean_squared_error: 0.1224\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.1228 - val_mean_squared_error: 0.1228\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.1115 - val_mean_squared_error: 0.1115\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.1139 - val_mean_squared_error: 0.1139\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.1082 - val_mean_squared_error: 0.1082\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.1201 - val_mean_squared_error: 0.1201\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0817 - val_mean_squared_error: 0.0817\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.1125 - val_mean_squared_error: 0.1125\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0773 - val_mean_squared_error: 0.0773\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0857 - val_mean_squared_error: 0.0857\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0806 - val_mean_squared_error: 0.0806\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0779 - val_mean_squared_error: 0.0779\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0730 - val_mean_squared_error: 0.0730\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0786 - val_mean_squared_error: 0.0786\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0667 - val_mean_squared_error: 0.0667\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0743 - val_mean_squared_error: 0.0743\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0643 - val_mean_squared_error: 0.0643\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0740 - val_mean_squared_error: 0.0740\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0629 - val_mean_squared_error: 0.0629\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0671 - val_mean_squared_error: 0.0671\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0610 - val_mean_squared_error: 0.0610\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0676 - val_mean_squared_error: 0.0676\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0609 - val_mean_squared_error: 0.0609\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0622 - val_mean_squared_error: 0.0622\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0615 - val_mean_squared_error: 0.0615\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0603 - val_mean_squared_error: 0.0603\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0602 - val_mean_squared_error: 0.0602\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0605 - val_mean_squared_error: 0.0605\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0632 - val_mean_squared_error: 0.0632\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0601 - val_mean_squared_error: 0.0601\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0602 - val_mean_squared_error: 0.0602\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0609 - val_mean_squared_error: 0.0609\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0598 - val_mean_squared_error: 0.0598\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0621 - val_mean_squared_error: 0.0621\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0603 - val_mean_squared_error: 0.0603\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0604 - val_mean_squared_error: 0.0604\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0646 - val_mean_squared_error: 0.0646\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 46us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0635 - val_mean_squared_error: 0.0635\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0627 - val_mean_squared_error: 0.0627\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0660 - val_mean_squared_error: 0.0660\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0639 - val_mean_squared_error: 0.0639\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0672 - val_mean_squared_error: 0.0672\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0654 - val_mean_squared_error: 0.0654\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0810 - val_mean_squared_error: 0.0810\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0620 - val_mean_squared_error: 0.0620\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0716 - val_mean_squared_error: 0.0716\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.00 - 0s 43us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0747 - val_mean_squared_error: 0.0747\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0786 - val_mean_squared_error: 0.0786\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0686 - val_mean_squared_error: 0.0686\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0724 - val_mean_squared_error: 0.0724\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0754 - val_mean_squared_error: 0.0754\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0882 - val_mean_squared_error: 0.0882\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0746 - val_mean_squared_error: 0.0746\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0869 - val_mean_squared_error: 0.0869\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0877 - val_mean_squared_error: 0.0877\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0789 - val_mean_squared_error: 0.0789\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0861 - val_mean_squared_error: 0.0861\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0861 - val_mean_squared_error: 0.0861\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0836 - val_mean_squared_error: 0.0836\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1043 - val_mean_squared_error: 0.1043\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0961 - val_mean_squared_error: 0.0961\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0848 - val_mean_squared_error: 0.0848\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0980 - val_mean_squared_error: 0.0980\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0977 - val_mean_squared_error: 0.0977\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0963 - val_mean_squared_error: 0.0963\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0954 - val_mean_squared_error: 0.0954\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1028 - val_mean_squared_error: 0.1028\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1047 - val_mean_squared_error: 0.1047\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1031 - val_mean_squared_error: 0.1031\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1155 - val_mean_squared_error: 0.1155\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0908 - val_mean_squared_error: 0.0908\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1221 - val_mean_squared_error: 0.1221\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1169 - val_mean_squared_error: 0.1169\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1016 - val_mean_squared_error: 0.1016\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1084 - val_mean_squared_error: 0.1084\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1201 - val_mean_squared_error: 0.1201\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0995 - val_mean_squared_error: 0.0995\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1206 - val_mean_squared_error: 0.1206\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1421 - val_mean_squared_error: 0.1421\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1273 - val_mean_squared_error: 0.1273\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1020 - val_mean_squared_error: 0.1020\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1192 - val_mean_squared_error: 0.1192\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1469 - val_mean_squared_error: 0.1469\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1173 - val_mean_squared_error: 0.1173\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 42us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.1203 - val_mean_squared_error: 0.1203\n",
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1205 - val_mean_squared_error: 0.1205\n",
      "It has been 3.4003326892852783 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.2551 - mean_squared_error: 0.2551 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0557 - mean_squared_error: 0.0557 - val_loss: 0.0923 - val_mean_squared_error: 0.0923\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0670 - mean_squared_error: 0.0670 - val_loss: 0.0403 - val_mean_squared_error: 0.0403\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.1394 - val_mean_squared_error: 0.1394\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.1159 - val_mean_squared_error: 0.1159\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.0689 - val_mean_squared_error: 0.0689\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0301 - mean_squared_error: 0.0301 - val_loss: 0.0825 - val_mean_squared_error: 0.0825\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0276 - mean_squared_error: 0.0276 - val_loss: 0.1028 - val_mean_squared_error: 0.1028\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0262 - mean_squared_error: 0.0262 - val_loss: 0.1077 - val_mean_squared_error: 0.1077\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.1110 - val_mean_squared_error: 0.1110\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.1073 - val_mean_squared_error: 0.1073\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.1146 - val_mean_squared_error: 0.1146\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0216 - mean_squared_error: 0.0216 - val_loss: 0.1182 - val_mean_squared_error: 0.1182\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.1226 - val_mean_squared_error: 0.1226\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.1320 - val_mean_squared_error: 0.1320\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.1193 - val_mean_squared_error: 0.1193\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.1276 - val_mean_squared_error: 0.1276\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.1314 - val_mean_squared_error: 0.1314\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.1348 - val_mean_squared_error: 0.1348\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.1368 - val_mean_squared_error: 0.1368\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1412 - val_mean_squared_error: 0.1412\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.1449 - val_mean_squared_error: 0.1449\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.1422 - val_mean_squared_error: 0.1422\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.1409 - val_mean_squared_error: 0.1409\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.1526 - val_mean_squared_error: 0.1526\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1551 - val_mean_squared_error: 0.1551\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1598 - val_mean_squared_error: 0.1598\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.1427 - val_mean_squared_error: 0.1427\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.1685 - val_mean_squared_error: 0.1685\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1535 - val_mean_squared_error: 0.1535\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.1613 - val_mean_squared_error: 0.1613\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.1611 - val_mean_squared_error: 0.1611\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1616 - val_mean_squared_error: 0.1616\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.1640 - val_mean_squared_error: 0.1640\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.1754 - val_mean_squared_error: 0.1754\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1698 - val_mean_squared_error: 0.1698\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.1653 - val_mean_squared_error: 0.1653\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1863 - val_mean_squared_error: 0.1863\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1663 - val_mean_squared_error: 0.1663\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.1888 - val_mean_squared_error: 0.1888\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.1618 - val_mean_squared_error: 0.1618\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1907 - val_mean_squared_error: 0.1907\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.1800 - val_mean_squared_error: 0.1800\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.1741 - val_mean_squared_error: 0.1741\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1823 - val_mean_squared_error: 0.1823\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1844 - val_mean_squared_error: 0.1844\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1883 - val_mean_squared_error: 0.1883\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1868 - val_mean_squared_error: 0.1868\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1911 - val_mean_squared_error: 0.1911\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 44us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1963 - val_mean_squared_error: 0.1963\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.2010 - val_mean_squared_error: 0.2010\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1894 - val_mean_squared_error: 0.1894\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.2034 - val_mean_squared_error: 0.2034\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1940 - val_mean_squared_error: 0.1940\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.2096 - val_mean_squared_error: 0.2096\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1997 - val_mean_squared_error: 0.1997\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.2112 - val_mean_squared_error: 0.2112\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.2077 - val_mean_squared_error: 0.2077\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1920 - val_mean_squared_error: 0.1920\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.2166 - val_mean_squared_error: 0.2166\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.2037 - val_mean_squared_error: 0.2037\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.2196 - val_mean_squared_error: 0.2196\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.2055 - val_mean_squared_error: 0.2055\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.2213 - val_mean_squared_error: 0.2213\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.2076 - val_mean_squared_error: 0.2076\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.2192 - val_mean_squared_error: 0.2192\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.2209 - val_mean_squared_error: 0.2209\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.2172 - val_mean_squared_error: 0.2172\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.2457 - val_mean_squared_error: 0.2457\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.2122 - val_mean_squared_error: 0.2122\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.2273 - val_mean_squared_error: 0.2273\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2218 - val_mean_squared_error: 0.2218\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.2308 - val_mean_squared_error: 0.2308\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2244 - val_mean_squared_error: 0.2244\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2405 - val_mean_squared_error: 0.2405\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.2428 - val_mean_squared_error: 0.2428\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.2355 - val_mean_squared_error: 0.2355\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2283 - val_mean_squared_error: 0.2283\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.2526 - val_mean_squared_error: 0.2526\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.2397 - val_mean_squared_error: 0.2397\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.2307 - val_mean_squared_error: 0.2307\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.2284 - val_mean_squared_error: 0.2284\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.2583 - val_mean_squared_error: 0.2583\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2359 - val_mean_squared_error: 0.2359\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2425 - val_mean_squared_error: 0.2425\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2587 - val_mean_squared_error: 0.2587\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.2611 - val_mean_squared_error: 0.2611\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2460 - val_mean_squared_error: 0.2460\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2587 - val_mean_squared_error: 0.2587\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.2501 - val_mean_squared_error: 0.2501\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.2600 - val_mean_squared_error: 0.2600\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2533 - val_mean_squared_error: 0.2533\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2654 - val_mean_squared_error: 0.2654\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.2492 - val_mean_squared_error: 0.2492\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2748 - val_mean_squared_error: 0.2748\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2399 - val_mean_squared_error: 0.2399\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2731 - val_mean_squared_error: 0.2731\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2585 - val_mean_squared_error: 0.2585\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2654 - val_mean_squared_error: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2700 - val_mean_squared_error: 0.2700\n",
      "It has been 3.4192771911621094 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.0711 - mean_squared_error: 0.0711 - val_loss: 0.1117 - val_mean_squared_error: 0.1117\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0404 - mean_squared_error: 0.0404 - val_loss: 0.0702 - val_mean_squared_error: 0.0702\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 37us/step - loss: 0.0304 - mean_squared_error: 0.0304 - val_loss: 0.0770 - val_mean_squared_error: 0.0770\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0265 - mean_squared_error: 0.0265 - val_loss: 0.0707 - val_mean_squared_error: 0.0707\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0846 - val_mean_squared_error: 0.0846\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0796 - val_mean_squared_error: 0.0796\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0798 - val_mean_squared_error: 0.0798\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0800 - val_mean_squared_error: 0.0800\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0857 - val_mean_squared_error: 0.0857\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.0781 - val_mean_squared_error: 0.0781\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0873 - val_mean_squared_error: 0.0873\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0806 - val_mean_squared_error: 0.0806\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0819 - val_mean_squared_error: 0.0819\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0866 - val_mean_squared_error: 0.0866\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0849 - val_mean_squared_error: 0.0849\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0870 - val_mean_squared_error: 0.0870\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0798 - val_mean_squared_error: 0.0798\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0973 - val_mean_squared_error: 0.0973\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0795 - val_mean_squared_error: 0.0795\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0977 - val_mean_squared_error: 0.0977\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0744 - val_mean_squared_error: 0.0744\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0904 - val_mean_squared_error: 0.0904\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0852 - val_mean_squared_error: 0.0852\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0854 - val_mean_squared_error: 0.0854\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0886 - val_mean_squared_error: 0.0886\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0885 - val_mean_squared_error: 0.0885\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0919 - val_mean_squared_error: 0.0919\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0844 - val_mean_squared_error: 0.0844\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.1002 - val_mean_squared_error: 0.1002\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0858 - val_mean_squared_error: 0.0858\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0967 - val_mean_squared_error: 0.0967\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0898 - val_mean_squared_error: 0.0898\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0965 - val_mean_squared_error: 0.0965\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0906 - val_mean_squared_error: 0.0906\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1080 - val_mean_squared_error: 0.1080\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0920 - val_mean_squared_error: 0.0920\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0880 - val_mean_squared_error: 0.0880\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1013 - val_mean_squared_error: 0.1013\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.1018 - val_mean_squared_error: 0.1018\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0881 - val_mean_squared_error: 0.0881\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1086 - val_mean_squared_error: 0.1086\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0966 - val_mean_squared_error: 0.0966\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0911 - val_mean_squared_error: 0.0911\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0955 - val_mean_squared_error: 0.0955\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1077 - val_mean_squared_error: 0.1077\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1066 - val_mean_squared_error: 0.1066\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0869 - val_mean_squared_error: 0.0869\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0975 - val_mean_squared_error: 0.0975\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1154 - val_mean_squared_error: 0.1154\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 44us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1020 - val_mean_squared_error: 0.1020\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0982 - val_mean_squared_error: 0.0982\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1196 - val_mean_squared_error: 0.1196\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1054 - val_mean_squared_error: 0.1054\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0983 - val_mean_squared_error: 0.0983\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1030 - val_mean_squared_error: 0.1030\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1338 - val_mean_squared_error: 0.1338\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1082 - val_mean_squared_error: 0.1082\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1116 - val_mean_squared_error: 0.1116\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1075 - val_mean_squared_error: 0.1075\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1065 - val_mean_squared_error: 0.1065\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1287 - val_mean_squared_error: 0.1287\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1368 - val_mean_squared_error: 0.1368\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1162 - val_mean_squared_error: 0.1162\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1185 - val_mean_squared_error: 0.1185\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1179 - val_mean_squared_error: 0.1179\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1355 - val_mean_squared_error: 0.1355\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1163 - val_mean_squared_error: 0.1163\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1027 - val_mean_squared_error: 0.1027\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1398 - val_mean_squared_error: 0.1398\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1227 - val_mean_squared_error: 0.1227\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1135 - val_mean_squared_error: 0.1135\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1418 - val_mean_squared_error: 0.1418\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1262 - val_mean_squared_error: 0.1262\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1203 - val_mean_squared_error: 0.1203\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1514 - val_mean_squared_error: 0.1514\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1380 - val_mean_squared_error: 0.1380\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1171 - val_mean_squared_error: 0.1171\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1253 - val_mean_squared_error: 0.1253\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1504 - val_mean_squared_error: 0.1504\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1607 - val_mean_squared_error: 0.1607\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1310 - val_mean_squared_error: 0.1310\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1396 - val_mean_squared_error: 0.1396\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1513 - val_mean_squared_error: 0.1513\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1561 - val_mean_squared_error: 0.1561\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1273 - val_mean_squared_error: 0.1273\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1316 - val_mean_squared_error: 0.1316\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1400 - val_mean_squared_error: 0.1400\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1457 - val_mean_squared_error: 0.1457\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1772 - val_mean_squared_error: 0.1772\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1305 - val_mean_squared_error: 0.1305\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1347 - val_mean_squared_error: 0.1347\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1667 - val_mean_squared_error: 0.1667\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1339 - val_mean_squared_error: 0.1339\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1704 - val_mean_squared_error: 0.1704\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1689 - val_mean_squared_error: 0.1689\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1437 - val_mean_squared_error: 0.1437\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1378 - val_mean_squared_error: 0.1378\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1430 - val_mean_squared_error: 0.1430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1653 - val_mean_squared_error: 0.1653\n",
      "It has been 3.4921910762786865 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.2076 - mean_squared_error: 0.2076 - val_loss: 0.4036 - val_mean_squared_error: 0.4036\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0739 - mean_squared_error: 0.0739 - val_loss: 0.9291 - val_mean_squared_error: 0.9291\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0646 - mean_squared_error: 0.0646 - val_loss: 0.3870 - val_mean_squared_error: 0.3870\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0471 - mean_squared_error: 0.0471 - val_loss: 0.2009 - val_mean_squared_error: 0.2009\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0442 - mean_squared_error: 0.0442 - val_loss: 0.2828 - val_mean_squared_error: 0.2828\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0388 - mean_squared_error: 0.0388 - val_loss: 0.3367 - val_mean_squared_error: 0.3367\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.2426 - val_mean_squared_error: 0.2426\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.2319 - val_mean_squared_error: 0.2319\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.2489 - val_mean_squared_error: 0.2489\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.2245 - val_mean_squared_error: 0.2245\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.2165 - val_mean_squared_error: 0.2165\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.2023 - val_mean_squared_error: 0.2023\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0297 - mean_squared_error: 0.0297 - val_loss: 0.2122 - val_mean_squared_error: 0.2122\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.1921 - val_mean_squared_error: 0.1921\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0282 - mean_squared_error: 0.0282 - val_loss: 0.1835 - val_mean_squared_error: 0.1835\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0272 - mean_squared_error: 0.0272 - val_loss: 0.1943 - val_mean_squared_error: 0.1943\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.1707 - val_mean_squared_error: 0.1707\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.1698 - val_mean_squared_error: 0.1698\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.1538 - val_mean_squared_error: 0.1538\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.1556 - val_mean_squared_error: 0.1556\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.1626 - val_mean_squared_error: 0.1626\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.1379 - val_mean_squared_error: 0.1379\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.1451 - val_mean_squared_error: 0.1451\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.1397 - val_mean_squared_error: 0.1397\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0215 - mean_squared_error: 0.0215 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.1283 - val_mean_squared_error: 0.1283\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.1193 - val_mean_squared_error: 0.1193\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.1249 - val_mean_squared_error: 0.1249\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.1087 - val_mean_squared_error: 0.1087\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.1140 - val_mean_squared_error: 0.1140\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.1072 - val_mean_squared_error: 0.1072\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.1115 - val_mean_squared_error: 0.1115\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0955 - val_mean_squared_error: 0.0955\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.1042 - val_mean_squared_error: 0.1042\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0988 - val_mean_squared_error: 0.0988\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0923 - val_mean_squared_error: 0.0923\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0950 - val_mean_squared_error: 0.0950\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0882 - val_mean_squared_error: 0.0882\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0845 - val_mean_squared_error: 0.0845\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0818 - val_mean_squared_error: 0.0818\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0815 - val_mean_squared_error: 0.0815\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0794 - val_mean_squared_error: 0.0794\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0787 - val_mean_squared_error: 0.0787\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0764 - val_mean_squared_error: 0.0764\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0738 - val_mean_squared_error: 0.0738\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0754 - val_mean_squared_error: 0.0754\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0716 - val_mean_squared_error: 0.0716\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0722 - val_mean_squared_error: 0.0722\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 47us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0700 - val_mean_squared_error: 0.0700\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0697 - val_mean_squared_error: 0.0697\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0683 - val_mean_squared_error: 0.0683\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0676 - val_mean_squared_error: 0.0676\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0667 - val_mean_squared_error: 0.0667\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0660 - val_mean_squared_error: 0.0660\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0655 - val_mean_squared_error: 0.0655\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0635 - val_mean_squared_error: 0.0635\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0646 - val_mean_squared_error: 0.0646\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0641 - val_mean_squared_error: 0.0641\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0637 - val_mean_squared_error: 0.0637\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0645 - val_mean_squared_error: 0.0645\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0642 - val_mean_squared_error: 0.0642\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0654 - val_mean_squared_error: 0.0654\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0599 - val_mean_squared_error: 0.0599\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0684 - val_mean_squared_error: 0.0684\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0596 - val_mean_squared_error: 0.0596\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0670 - val_mean_squared_error: 0.0670\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0602 - val_mean_squared_error: 0.0602\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0688 - val_mean_squared_error: 0.0688\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0605 - val_mean_squared_error: 0.0605\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0712 - val_mean_squared_error: 0.0712\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0683 - val_mean_squared_error: 0.0683\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0604 - val_mean_squared_error: 0.0604\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0803 - val_mean_squared_error: 0.0803\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0648 - val_mean_squared_error: 0.0648\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0732 - val_mean_squared_error: 0.0732\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0694 - val_mean_squared_error: 0.0694\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0663 - val_mean_squared_error: 0.0663\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0731 - val_mean_squared_error: 0.0731\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0704 - val_mean_squared_error: 0.0704\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0658 - val_mean_squared_error: 0.0658\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0727 - val_mean_squared_error: 0.0727\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0756 - val_mean_squared_error: 0.0756\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0700 - val_mean_squared_error: 0.0700\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0772 - val_mean_squared_error: 0.0772\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0685 - val_mean_squared_error: 0.0685\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0896 - val_mean_squared_error: 0.0896\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0663 - val_mean_squared_error: 0.0663\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1000 - val_mean_squared_error: 0.1000\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0624 - val_mean_squared_error: 0.0624\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0989 - val_mean_squared_error: 0.0989\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0757 - val_mean_squared_error: 0.0757\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0832 - val_mean_squared_error: 0.0832\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0904 - val_mean_squared_error: 0.0904\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0871 - val_mean_squared_error: 0.0871\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0785 - val_mean_squared_error: 0.0785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0960 - val_mean_squared_error: 0.0960\n",
      "It has been 3.558757781982422 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.1222 - mean_squared_error: 0.1222 - val_loss: 0.2321 - val_mean_squared_error: 0.2321\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0592 - mean_squared_error: 0.0592 - val_loss: 0.3564 - val_mean_squared_error: 0.3564\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0395 - mean_squared_error: 0.0395 - val_loss: 0.1115 - val_mean_squared_error: 0.1115\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.1132 - val_mean_squared_error: 0.1132\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0293 - mean_squared_error: 0.0293 - val_loss: 0.1784 - val_mean_squared_error: 0.1784\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.1375 - val_mean_squared_error: 0.1375\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.1269 - val_mean_squared_error: 0.1269\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.1504 - val_mean_squared_error: 0.1504\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.1330 - val_mean_squared_error: 0.1330\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.1405 - val_mean_squared_error: 0.1405\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.1408 - val_mean_squared_error: 0.1408\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.1323 - val_mean_squared_error: 0.1323\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.1412 - val_mean_squared_error: 0.1412\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.1242 - val_mean_squared_error: 0.1242\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.1287 - val_mean_squared_error: 0.1287\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.1269 - val_mean_squared_error: 0.1269\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.1237 - val_mean_squared_error: 0.1237\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.1206 - val_mean_squared_error: 0.1206\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.1260 - val_mean_squared_error: 0.1260\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1166 - val_mean_squared_error: 0.1166\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.1218 - val_mean_squared_error: 0.1218\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.1108 - val_mean_squared_error: 0.1108\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.1114 - val_mean_squared_error: 0.1114\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.1091 - val_mean_squared_error: 0.1091\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.1120 - val_mean_squared_error: 0.1120\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1098 - val_mean_squared_error: 0.1098\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.1077 - val_mean_squared_error: 0.1077\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.1053 - val_mean_squared_error: 0.1053\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1046 - val_mean_squared_error: 0.1046\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1005 - val_mean_squared_error: 0.1005\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1039 - val_mean_squared_error: 0.1039\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1012 - val_mean_squared_error: 0.1012\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1003 - val_mean_squared_error: 0.1003\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0952 - val_mean_squared_error: 0.0952\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0943 - val_mean_squared_error: 0.0943\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.1011 - val_mean_squared_error: 0.1011\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0914 - val_mean_squared_error: 0.0914\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0913 - val_mean_squared_error: 0.0913\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0910 - val_mean_squared_error: 0.0910\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0901 - val_mean_squared_error: 0.0901\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0920 - val_mean_squared_error: 0.0920\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0870 - val_mean_squared_error: 0.0870\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0847 - val_mean_squared_error: 0.0847\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0888 - val_mean_squared_error: 0.0888\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0869 - val_mean_squared_error: 0.0869\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0836 - val_mean_squared_error: 0.0836\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0810 - val_mean_squared_error: 0.0810\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0848 - val_mean_squared_error: 0.0848\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0827 - val_mean_squared_error: 0.0827\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 42us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0800 - val_mean_squared_error: 0.0800\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0827 - val_mean_squared_error: 0.0827\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0783 - val_mean_squared_error: 0.0783\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0812 - val_mean_squared_error: 0.0812\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0807 - val_mean_squared_error: 0.0807\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0772 - val_mean_squared_error: 0.0772\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0816 - val_mean_squared_error: 0.0816\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0794 - val_mean_squared_error: 0.0794\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0761 - val_mean_squared_error: 0.0761\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0765 - val_mean_squared_error: 0.0765\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0775 - val_mean_squared_error: 0.0775\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0763 - val_mean_squared_error: 0.0763\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0778 - val_mean_squared_error: 0.0778\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0756 - val_mean_squared_error: 0.0756\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0765 - val_mean_squared_error: 0.0765\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0749 - val_mean_squared_error: 0.0749\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0784 - val_mean_squared_error: 0.0784\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0767 - val_mean_squared_error: 0.0767\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0804 - val_mean_squared_error: 0.0804\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0768 - val_mean_squared_error: 0.0768\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0783 - val_mean_squared_error: 0.0783\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0752 - val_mean_squared_error: 0.0752\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0762 - val_mean_squared_error: 0.0762\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0756 - val_mean_squared_error: 0.0756\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0749 - val_mean_squared_error: 0.0749\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0765 - val_mean_squared_error: 0.0765\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0752 - val_mean_squared_error: 0.0752\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0762 - val_mean_squared_error: 0.0762\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0767 - val_mean_squared_error: 0.0767\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0757 - val_mean_squared_error: 0.0757\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0763 - val_mean_squared_error: 0.0763\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0759 - val_mean_squared_error: 0.0759\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0766 - val_mean_squared_error: 0.0766\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0781 - val_mean_squared_error: 0.0781\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0767 - val_mean_squared_error: 0.0767\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0814 - val_mean_squared_error: 0.0814\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0767 - val_mean_squared_error: 0.0767\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0776 - val_mean_squared_error: 0.0776\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0786 - val_mean_squared_error: 0.0786\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0772 - val_mean_squared_error: 0.0772\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0797 - val_mean_squared_error: 0.0797\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0808 - val_mean_squared_error: 0.0808\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0809 - val_mean_squared_error: 0.0809\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0803 - val_mean_squared_error: 0.0803\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0792 - val_mean_squared_error: 0.0792\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0852 - val_mean_squared_error: 0.0852\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0802 - val_mean_squared_error: 0.0802\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0831 - val_mean_squared_error: 0.0831\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0848 - val_mean_squared_error: 0.0848\n",
      "It has been 3.6131341457366943 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 3ms/step - loss: 0.1430 - mean_squared_error: 0.1430 - val_loss: 0.1325 - val_mean_squared_error: 0.1325\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0516 - mean_squared_error: 0.0516 - val_loss: 0.2140 - val_mean_squared_error: 0.2140\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0394 - mean_squared_error: 0.0394 - val_loss: 0.0739 - val_mean_squared_error: 0.0739\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0296 - mean_squared_error: 0.0296 - val_loss: 0.0773 - val_mean_squared_error: 0.0773\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0670 - val_mean_squared_error: 0.0670\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.0645 - val_mean_squared_error: 0.0645\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0677 - val_mean_squared_error: 0.0677\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.0643 - val_mean_squared_error: 0.0643\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.0638 - val_mean_squared_error: 0.0638\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0662 - val_mean_squared_error: 0.0662\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0677 - val_mean_squared_error: 0.0677\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0647 - val_mean_squared_error: 0.0647\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0691 - val_mean_squared_error: 0.0691\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0702 - val_mean_squared_error: 0.0702\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0688 - val_mean_squared_error: 0.0688\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0707 - val_mean_squared_error: 0.0707\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0721 - val_mean_squared_error: 0.0721\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0732 - val_mean_squared_error: 0.0732\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0732 - val_mean_squared_error: 0.0732\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0755 - val_mean_squared_error: 0.0755\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0739 - val_mean_squared_error: 0.0739\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0765 - val_mean_squared_error: 0.0765\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0762 - val_mean_squared_error: 0.0762\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0864 - val_mean_squared_error: 0.0864\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0870 - val_mean_squared_error: 0.0870\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0913 - val_mean_squared_error: 0.0913\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0778 - val_mean_squared_error: 0.0778\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0913 - val_mean_squared_error: 0.0913\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0876 - val_mean_squared_error: 0.0876\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0979 - val_mean_squared_error: 0.0979\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0894 - val_mean_squared_error: 0.0894\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0997 - val_mean_squared_error: 0.0997\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0974 - val_mean_squared_error: 0.0974\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0915 - val_mean_squared_error: 0.0915\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0959 - val_mean_squared_error: 0.0959\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1012 - val_mean_squared_error: 0.1012\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1092 - val_mean_squared_error: 0.1092\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1006 - val_mean_squared_error: 0.1006\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1156 - val_mean_squared_error: 0.1156\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0993 - val_mean_squared_error: 0.0993\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.1182 - val_mean_squared_error: 0.1182\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.1022 - val_mean_squared_error: 0.1022\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1086 - val_mean_squared_error: 0.1086\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1229 - val_mean_squared_error: 0.1229\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1002 - val_mean_squared_error: 0.1002\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 46us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1187 - val_mean_squared_error: 0.1187\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1123 - val_mean_squared_error: 0.1123\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1189 - val_mean_squared_error: 0.1189\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1244 - val_mean_squared_error: 0.1244\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1297 - val_mean_squared_error: 0.1297\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1112 - val_mean_squared_error: 0.1112\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 68us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1356 - val_mean_squared_error: 0.1356\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1224 - val_mean_squared_error: 0.1224\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1376 - val_mean_squared_error: 0.1376\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1275 - val_mean_squared_error: 0.1275\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1306 - val_mean_squared_error: 0.1306\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1388 - val_mean_squared_error: 0.1388\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1304 - val_mean_squared_error: 0.1304\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1292 - val_mean_squared_error: 0.1292\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1460 - val_mean_squared_error: 0.1460\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1306 - val_mean_squared_error: 0.1306\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1542 - val_mean_squared_error: 0.1542\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1283 - val_mean_squared_error: 0.1283\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1481 - val_mean_squared_error: 0.1481\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1446 - val_mean_squared_error: 0.1446\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1589 - val_mean_squared_error: 0.1589\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1430 - val_mean_squared_error: 0.1430\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1566 - val_mean_squared_error: 0.1566\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1488 - val_mean_squared_error: 0.1488\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1657 - val_mean_squared_error: 0.1657\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1538 - val_mean_squared_error: 0.1538\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1560 - val_mean_squared_error: 0.1560\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1720 - val_mean_squared_error: 0.1720\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1525 - val_mean_squared_error: 0.1525\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1611 - val_mean_squared_error: 0.1611\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1697 - val_mean_squared_error: 0.1697\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1582 - val_mean_squared_error: 0.1582\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1763 - val_mean_squared_error: 0.1763\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1841 - val_mean_squared_error: 0.1841\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1560 - val_mean_squared_error: 0.1560\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1866 - val_mean_squared_error: 0.1866\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1585 - val_mean_squared_error: 0.1585\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1791 - val_mean_squared_error: 0.1791\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1841 - val_mean_squared_error: 0.1841\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1785 - val_mean_squared_error: 0.1785\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2068 - val_mean_squared_error: 0.2068\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1831 - val_mean_squared_error: 0.1831\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1880 - val_mean_squared_error: 0.1880\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1892 - val_mean_squared_error: 0.1892\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2014 - val_mean_squared_error: 0.2014\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1931 - val_mean_squared_error: 0.1931\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2114 - val_mean_squared_error: 0.2114\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1840 - val_mean_squared_error: 0.1840\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2062 - val_mean_squared_error: 0.2062\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1964 - val_mean_squared_error: 0.1964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2019 - val_mean_squared_error: 0.2019\n",
      "It has been 3.6363179683685303 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.1675 - mean_squared_error: 0.1675 - val_loss: 0.3095 - val_mean_squared_error: 0.3095\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.2406 - val_mean_squared_error: 0.2406\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0564 - mean_squared_error: 0.0564 - val_loss: 0.0628 - val_mean_squared_error: 0.0628\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0445 - mean_squared_error: 0.0445 - val_loss: 0.0600 - val_mean_squared_error: 0.0600\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0736 - val_mean_squared_error: 0.0736\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0296 - mean_squared_error: 0.0296 - val_loss: 0.0616 - val_mean_squared_error: 0.0616\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0619 - val_mean_squared_error: 0.0619\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0637 - val_mean_squared_error: 0.0637\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0640 - val_mean_squared_error: 0.0640\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0643 - val_mean_squared_error: 0.0643\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0645 - val_mean_squared_error: 0.0645\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0647 - val_mean_squared_error: 0.0647\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0661 - val_mean_squared_error: 0.0661\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0658 - val_mean_squared_error: 0.0658\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0664 - val_mean_squared_error: 0.0664\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0665 - val_mean_squared_error: 0.0665\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0679 - val_mean_squared_error: 0.0679\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0693 - val_mean_squared_error: 0.0693\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0678 - val_mean_squared_error: 0.0678\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0715 - val_mean_squared_error: 0.0715\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0691 - val_mean_squared_error: 0.0691\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0694 - val_mean_squared_error: 0.0694\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0765 - val_mean_squared_error: 0.0765\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0674 - val_mean_squared_error: 0.0674\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0772 - val_mean_squared_error: 0.0772\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0719 - val_mean_squared_error: 0.0719\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0743 - val_mean_squared_error: 0.0743\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0845 - val_mean_squared_error: 0.0845\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0754 - val_mean_squared_error: 0.0754\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0808 - val_mean_squared_error: 0.0808\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0802 - val_mean_squared_error: 0.0802\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0808 - val_mean_squared_error: 0.0808\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0794 - val_mean_squared_error: 0.0794\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0839 - val_mean_squared_error: 0.0839\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0873 - val_mean_squared_error: 0.0873\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0795 - val_mean_squared_error: 0.0795\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0833 - val_mean_squared_error: 0.0833\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0899 - val_mean_squared_error: 0.0899\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0898 - val_mean_squared_error: 0.0898\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0822 - val_mean_squared_error: 0.0822\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1000 - val_mean_squared_error: 0.1000\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0888 - val_mean_squared_error: 0.0888\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0853 - val_mean_squared_error: 0.0853\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1049 - val_mean_squared_error: 0.1049\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0879 - val_mean_squared_error: 0.0879\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.1182 - val_mean_squared_error: 0.1182\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0906 - val_mean_squared_error: 0.0906\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 49us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1113 - val_mean_squared_error: 0.1113\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0894 - val_mean_squared_error: 0.0894\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1194 - val_mean_squared_error: 0.1194\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0998 - val_mean_squared_error: 0.0998\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1235 - val_mean_squared_error: 0.1235\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0987 - val_mean_squared_error: 0.0987\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1261 - val_mean_squared_error: 0.1261\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1129 - val_mean_squared_error: 0.1129\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1136 - val_mean_squared_error: 0.1136\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1330 - val_mean_squared_error: 0.1330\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1046 - val_mean_squared_error: 0.1046\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1240 - val_mean_squared_error: 0.1240\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1210 - val_mean_squared_error: 0.1210\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1310 - val_mean_squared_error: 0.1310\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1187 - val_mean_squared_error: 0.1187\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1300 - val_mean_squared_error: 0.1300\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1273 - val_mean_squared_error: 0.1273\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1333 - val_mean_squared_error: 0.1333\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1387 - val_mean_squared_error: 0.1387\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1400 - val_mean_squared_error: 0.1400\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1155 - val_mean_squared_error: 0.1155\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1595 - val_mean_squared_error: 0.1595\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1501 - val_mean_squared_error: 0.1501\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1266 - val_mean_squared_error: 0.1266\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1488 - val_mean_squared_error: 0.1488\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1516 - val_mean_squared_error: 0.1516\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1402 - val_mean_squared_error: 0.1402\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1482 - val_mean_squared_error: 0.1482\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1729 - val_mean_squared_error: 0.1729\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1434 - val_mean_squared_error: 0.1434\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1429 - val_mean_squared_error: 0.1429\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1906 - val_mean_squared_error: 0.1906\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1511 - val_mean_squared_error: 0.1511\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1951 - val_mean_squared_error: 0.1951\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1828 - val_mean_squared_error: 0.1828\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1807 - val_mean_squared_error: 0.1807\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1670 - val_mean_squared_error: 0.1670\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1491 - val_mean_squared_error: 0.1491\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2018 - val_mean_squared_error: 0.2018\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1516 - val_mean_squared_error: 0.1516\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1626 - val_mean_squared_error: 0.1626\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1773 - val_mean_squared_error: 0.1773\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1850 - val_mean_squared_error: 0.1850\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1586 - val_mean_squared_error: 0.1586\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1698 - val_mean_squared_error: 0.1698\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.2197 - val_mean_squared_error: 0.2197\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1791 - val_mean_squared_error: 0.1791\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.1737 - val_mean_squared_error: 0.1737\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1913 - val_mean_squared_error: 0.1913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2171 - val_mean_squared_error: 0.2171\n",
      "It has been 3.764559030532837 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.2424 - mean_squared_error: 0.2424 - val_loss: 0.8139 - val_mean_squared_error: 0.8139\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.1330 - mean_squared_error: 0.1330 - val_loss: 0.5390 - val_mean_squared_error: 0.5390\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 38us/step - loss: 0.0709 - mean_squared_error: 0.0709 - val_loss: 0.2123 - val_mean_squared_error: 0.2123\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0466 - mean_squared_error: 0.0466 - val_loss: 0.2171 - val_mean_squared_error: 0.2171\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.2012 - val_mean_squared_error: 0.2012\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.1721 - val_mean_squared_error: 0.1721\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.1837 - val_mean_squared_error: 0.1837\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.1760 - val_mean_squared_error: 0.1760\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0309 - mean_squared_error: 0.0309 - val_loss: 0.1833 - val_mean_squared_error: 0.1833\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.1765 - val_mean_squared_error: 0.1765\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.1757 - val_mean_squared_error: 0.1757\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0272 - mean_squared_error: 0.0272 - val_loss: 0.1671 - val_mean_squared_error: 0.1671\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0261 - mean_squared_error: 0.0261 - val_loss: 0.1656 - val_mean_squared_error: 0.1656\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.1604 - val_mean_squared_error: 0.1604\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.1590 - val_mean_squared_error: 0.1590\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.1559 - val_mean_squared_error: 0.1559\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.1570 - val_mean_squared_error: 0.1570\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.1499 - val_mean_squared_error: 0.1499\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.1488 - val_mean_squared_error: 0.1488\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.1450 - val_mean_squared_error: 0.1450\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.1439 - val_mean_squared_error: 0.1439\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.1408 - val_mean_squared_error: 0.1408\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.1374 - val_mean_squared_error: 0.1374\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.1368 - val_mean_squared_error: 0.1368\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.1356 - val_mean_squared_error: 0.1356\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.1304 - val_mean_squared_error: 0.1304\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.1299 - val_mean_squared_error: 0.1299\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.1278 - val_mean_squared_error: 0.1278\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1265 - val_mean_squared_error: 0.1265\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.1256 - val_mean_squared_error: 0.1256\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.1245 - val_mean_squared_error: 0.1245\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.1228 - val_mean_squared_error: 0.1228\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.1210 - val_mean_squared_error: 0.1210\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.1233 - val_mean_squared_error: 0.1233\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1187 - val_mean_squared_error: 0.1187\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.1201 - val_mean_squared_error: 0.1201\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.1171 - val_mean_squared_error: 0.1171\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.1211 - val_mean_squared_error: 0.1211\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.1187 - val_mean_squared_error: 0.1187\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.1156 - val_mean_squared_error: 0.1156\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1188 - val_mean_squared_error: 0.1188\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1122 - val_mean_squared_error: 0.1122\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1189 - val_mean_squared_error: 0.1189\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.1167 - val_mean_squared_error: 0.1167\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1102 - val_mean_squared_error: 0.1102\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.1148 - val_mean_squared_error: 0.1148\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.1186 - val_mean_squared_error: 0.1186\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.1103 - val_mean_squared_error: 0.1103\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 49us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1184 - val_mean_squared_error: 0.1184\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1176 - val_mean_squared_error: 0.1176\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1081 - val_mean_squared_error: 0.1081\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.1272 - val_mean_squared_error: 0.1272\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1094 - val_mean_squared_error: 0.1094\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.1152 - val_mean_squared_error: 0.1152\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1098 - val_mean_squared_error: 0.1098\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.1105 - val_mean_squared_error: 0.1105\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1162 - val_mean_squared_error: 0.1162\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1234 - val_mean_squared_error: 0.1234\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1258 - val_mean_squared_error: 0.1258\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1226 - val_mean_squared_error: 0.1226\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1058 - val_mean_squared_error: 0.1058\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.1311 - val_mean_squared_error: 0.1311\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1140 - val_mean_squared_error: 0.1140\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1178 - val_mean_squared_error: 0.1178\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1270 - val_mean_squared_error: 0.1270\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1187 - val_mean_squared_error: 0.1187\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1271 - val_mean_squared_error: 0.1271\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1182 - val_mean_squared_error: 0.1182\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1310 - val_mean_squared_error: 0.1310\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1229 - val_mean_squared_error: 0.1229\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1252 - val_mean_squared_error: 0.1252\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1290 - val_mean_squared_error: 0.1290\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1212 - val_mean_squared_error: 0.1212\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1392 - val_mean_squared_error: 0.1392\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1262 - val_mean_squared_error: 0.1262\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1290 - val_mean_squared_error: 0.1290\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1547 - val_mean_squared_error: 0.1547\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1060 - val_mean_squared_error: 0.1060\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1460 - val_mean_squared_error: 0.1460\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1352 - val_mean_squared_error: 0.1352\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1257 - val_mean_squared_error: 0.1257\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1461 - val_mean_squared_error: 0.1461\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1424 - val_mean_squared_error: 0.1424\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1291 - val_mean_squared_error: 0.1291\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1512 - val_mean_squared_error: 0.1512\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1542 - val_mean_squared_error: 0.1542\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1228 - val_mean_squared_error: 0.1228\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1633 - val_mean_squared_error: 0.1633\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1435 - val_mean_squared_error: 0.1435\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1410 - val_mean_squared_error: 0.1410\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1607 - val_mean_squared_error: 0.1607\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1560 - val_mean_squared_error: 0.1560\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1563 - val_mean_squared_error: 0.1563\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1504 - val_mean_squared_error: 0.1504\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1429 - val_mean_squared_error: 0.1429\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1672 - val_mean_squared_error: 0.1672\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1497 - val_mean_squared_error: 0.1497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1571 - val_mean_squared_error: 0.1571\n",
      "It has been 3.817858934402466 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.1124 - mean_squared_error: 0.1124 - val_loss: 0.4813 - val_mean_squared_error: 0.4813\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0621 - mean_squared_error: 0.0621 - val_loss: 0.2457 - val_mean_squared_error: 0.2457\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0395 - mean_squared_error: 0.0395 - val_loss: 0.2386 - val_mean_squared_error: 0.2386\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0281 - mean_squared_error: 0.0281 - val_loss: 0.2316 - val_mean_squared_error: 0.2316\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.2201 - val_mean_squared_error: 0.2201\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.2119 - val_mean_squared_error: 0.2119\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 44us/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.2161 - val_mean_squared_error: 0.2161\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.2090 - val_mean_squared_error: 0.2090\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.2139 - val_mean_squared_error: 0.2139\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.2022 - val_mean_squared_error: 0.2022\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.2105 - val_mean_squared_error: 0.2105\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.1933 - val_mean_squared_error: 0.1933\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.2090 - val_mean_squared_error: 0.2090\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1938 - val_mean_squared_error: 0.1938\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.1906 - val_mean_squared_error: 0.1906\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.1998 - val_mean_squared_error: 0.1998\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.1789 - val_mean_squared_error: 0.1789\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.1798 - val_mean_squared_error: 0.1798\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.1724 - val_mean_squared_error: 0.1724\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.1830 - val_mean_squared_error: 0.1830\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.1574 - val_mean_squared_error: 0.1574\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.1918 - val_mean_squared_error: 0.1918\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.1522 - val_mean_squared_error: 0.1522\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.1737 - val_mean_squared_error: 0.1737\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.1584 - val_mean_squared_error: 0.1584\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1658 - val_mean_squared_error: 0.1658\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.1478 - val_mean_squared_error: 0.1478\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.1604 - val_mean_squared_error: 0.1604\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.1416 - val_mean_squared_error: 0.1416\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.1512 - val_mean_squared_error: 0.1512\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1402 - val_mean_squared_error: 0.1402\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.1477 - val_mean_squared_error: 0.1477\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1336 - val_mean_squared_error: 0.1336\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1422 - val_mean_squared_error: 0.1422\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1470 - val_mean_squared_error: 0.1470\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1220 - val_mean_squared_error: 0.1220\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1212 - val_mean_squared_error: 0.1212\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.1268 - val_mean_squared_error: 0.1268\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1488 - val_mean_squared_error: 0.1488\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1088 - val_mean_squared_error: 0.1088\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.1366 - val_mean_squared_error: 0.1366\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1111 - val_mean_squared_error: 0.1111\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1282 - val_mean_squared_error: 0.1282\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1182 - val_mean_squared_error: 0.1182\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1121 - val_mean_squared_error: 0.1121\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1201 - val_mean_squared_error: 0.1201\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1165 - val_mean_squared_error: 0.1165\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1080 - val_mean_squared_error: 0.1080\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 49us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1047 - val_mean_squared_error: 0.1047\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1161 - val_mean_squared_error: 0.1161\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1083 - val_mean_squared_error: 0.1083\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0974 - val_mean_squared_error: 0.0974\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1102 - val_mean_squared_error: 0.1102\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0993 - val_mean_squared_error: 0.0993\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0993 - val_mean_squared_error: 0.0993\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0994 - val_mean_squared_error: 0.0994\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0949 - val_mean_squared_error: 0.0949\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1046 - val_mean_squared_error: 0.1046\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0913 - val_mean_squared_error: 0.0913\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0916 - val_mean_squared_error: 0.0916\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0977 - val_mean_squared_error: 0.0977\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0941 - val_mean_squared_error: 0.0941\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0905 - val_mean_squared_error: 0.0905\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0983 - val_mean_squared_error: 0.0983\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0867 - val_mean_squared_error: 0.0867\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0960 - val_mean_squared_error: 0.0960\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0940 - val_mean_squared_error: 0.0940\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0866 - val_mean_squared_error: 0.0866\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0853 - val_mean_squared_error: 0.0853\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0875 - val_mean_squared_error: 0.0875\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0935 - val_mean_squared_error: 0.0935\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0846 - val_mean_squared_error: 0.0846\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0869 - val_mean_squared_error: 0.0869\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0849 - val_mean_squared_error: 0.0849\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0830 - val_mean_squared_error: 0.0830\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0904 - val_mean_squared_error: 0.0904\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0837 - val_mean_squared_error: 0.0837\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0870 - val_mean_squared_error: 0.0870\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0839 - val_mean_squared_error: 0.0839\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0827 - val_mean_squared_error: 0.0827\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0818 - val_mean_squared_error: 0.0818\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0831 - val_mean_squared_error: 0.0831\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0825 - val_mean_squared_error: 0.0825\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0817 - val_mean_squared_error: 0.0817\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0854 - val_mean_squared_error: 0.0854\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0866 - val_mean_squared_error: 0.0866\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0829 - val_mean_squared_error: 0.0829\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0827 - val_mean_squared_error: 0.0827\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0878 - val_mean_squared_error: 0.0878\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0826 - val_mean_squared_error: 0.0826\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0828 - val_mean_squared_error: 0.0828\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0841 - val_mean_squared_error: 0.0841\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0849 - val_mean_squared_error: 0.0849\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0828 - val_mean_squared_error: 0.0828\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0863 - val_mean_squared_error: 0.0863\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0843 - val_mean_squared_error: 0.0843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0841 - val_mean_squared_error: 0.0841\n",
      "It has been 3.820227861404419 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.1033 - mean_squared_error: 0.1033 - val_loss: 0.1179 - val_mean_squared_error: 0.1179\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 39us/step - loss: 0.0458 - mean_squared_error: 0.0458 - val_loss: 0.0669 - val_mean_squared_error: 0.0669\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 40us/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0741 - val_mean_squared_error: 0.0741\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0800 - val_mean_squared_error: 0.0800\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0301 - mean_squared_error: 0.0301 - val_loss: 0.0709 - val_mean_squared_error: 0.0709\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0281 - mean_squared_error: 0.0281 - val_loss: 0.0648 - val_mean_squared_error: 0.0648\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.0711 - val_mean_squared_error: 0.0711\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0261 - mean_squared_error: 0.0261 - val_loss: 0.0736 - val_mean_squared_error: 0.0736\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0710 - val_mean_squared_error: 0.0710\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.0653 - val_mean_squared_error: 0.0653\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0888 - val_mean_squared_error: 0.0888\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0743 - val_mean_squared_error: 0.0743\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0884 - val_mean_squared_error: 0.0884\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0732 - val_mean_squared_error: 0.0732\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0809 - val_mean_squared_error: 0.0809\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.1091 - val_mean_squared_error: 0.1091\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0803 - val_mean_squared_error: 0.0803\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0961 - val_mean_squared_error: 0.0961\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0955 - val_mean_squared_error: 0.0955\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0737 - val_mean_squared_error: 0.0737\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0877 - val_mean_squared_error: 0.0877\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.1299 - val_mean_squared_error: 0.1299\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0934 - val_mean_squared_error: 0.0934\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0860 - val_mean_squared_error: 0.0860\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.1105 - val_mean_squared_error: 0.1105\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0954 - val_mean_squared_error: 0.0954\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0869 - val_mean_squared_error: 0.0869\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.1140 - val_mean_squared_error: 0.1140\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1253 - val_mean_squared_error: 0.1253\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0967 - val_mean_squared_error: 0.0967\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.1354 - val_mean_squared_error: 0.1354\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0995 - val_mean_squared_error: 0.0995\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.1135 - val_mean_squared_error: 0.1135\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1017 - val_mean_squared_error: 0.1017\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.1144 - val_mean_squared_error: 0.1144\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1500 - val_mean_squared_error: 0.1500\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1034 - val_mean_squared_error: 0.1034\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1283 - val_mean_squared_error: 0.1283\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.1005 - val_mean_squared_error: 0.1005\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1457 - val_mean_squared_error: 0.1457\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1225 - val_mean_squared_error: 0.1225\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1255 - val_mean_squared_error: 0.1255\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1448 - val_mean_squared_error: 0.1448\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1395 - val_mean_squared_error: 0.1395\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1216 - val_mean_squared_error: 0.1216\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1286 - val_mean_squared_error: 0.1286\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1628 - val_mean_squared_error: 0.1628\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1672 - val_mean_squared_error: 0.1672\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1450 - val_mean_squared_error: 0.1450\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 52us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1594 - val_mean_squared_error: 0.1594\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1226 - val_mean_squared_error: 0.1226\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1625 - val_mean_squared_error: 0.1625\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1685 - val_mean_squared_error: 0.1685\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1291 - val_mean_squared_error: 0.1291\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1670 - val_mean_squared_error: 0.1670\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1443 - val_mean_squared_error: 0.1443\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1548 - val_mean_squared_error: 0.1548\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.2210 - val_mean_squared_error: 0.2210\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1952 - val_mean_squared_error: 0.1952\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1487 - val_mean_squared_error: 0.1487\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1500 - val_mean_squared_error: 0.1500\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1804 - val_mean_squared_error: 0.1804\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1577 - val_mean_squared_error: 0.1577\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1773 - val_mean_squared_error: 0.1773\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.2291 - val_mean_squared_error: 0.2291\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1973 - val_mean_squared_error: 0.1973\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1548 - val_mean_squared_error: 0.1548\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2027 - val_mean_squared_error: 0.2027\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1980 - val_mean_squared_error: 0.1980\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1917 - val_mean_squared_error: 0.1917\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1753 - val_mean_squared_error: 0.1753\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1963 - val_mean_squared_error: 0.1963\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.1590 - val_mean_squared_error: 0.1590\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1884 - val_mean_squared_error: 0.1884\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.2048 - val_mean_squared_error: 0.2048\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1699 - val_mean_squared_error: 0.1699\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1741 - val_mean_squared_error: 0.1741\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1772 - val_mean_squared_error: 0.1772\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.2185 - val_mean_squared_error: 0.2185\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2018 - val_mean_squared_error: 0.2018\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2343 - val_mean_squared_error: 0.2343\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2228 - val_mean_squared_error: 0.2228\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2182 - val_mean_squared_error: 0.2182\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1844 - val_mean_squared_error: 0.1844\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2031 - val_mean_squared_error: 0.2031\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.2661 - val_mean_squared_error: 0.2661\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2097 - val_mean_squared_error: 0.2097\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2067 - val_mean_squared_error: 0.2067\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.1989 - val_mean_squared_error: 0.1989\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2260 - val_mean_squared_error: 0.2260\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2157 - val_mean_squared_error: 0.2157\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2316 - val_mean_squared_error: 0.2316\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2625 - val_mean_squared_error: 0.2625\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2040 - val_mean_squared_error: 0.2040\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1974 - val_mean_squared_error: 0.1974\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2512 - val_mean_squared_error: 0.2512\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2363 - val_mean_squared_error: 0.2363\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.2310 - val_mean_squared_error: 0.2310\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.2588 - val_mean_squared_error: 0.2588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2640 - val_mean_squared_error: 0.2640\n",
      "It has been 3.952662229537964 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.1514 - mean_squared_error: 0.1514 - val_loss: 0.2746 - val_mean_squared_error: 0.2746\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0827 - mean_squared_error: 0.0827 - val_loss: 0.2054 - val_mean_squared_error: 0.2054\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 41us/step - loss: 0.0481 - mean_squared_error: 0.0481 - val_loss: 0.1172 - val_mean_squared_error: 0.1172\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0410 - mean_squared_error: 0.0410 - val_loss: 0.1048 - val_mean_squared_error: 0.1048\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.1019 - val_mean_squared_error: 0.1019\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0283 - mean_squared_error: 0.0283 - val_loss: 0.1101 - val_mean_squared_error: 0.1101\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.1046 - val_mean_squared_error: 0.1046\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.1027 - val_mean_squared_error: 0.1027\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.1087 - val_mean_squared_error: 0.1087\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.1071 - val_mean_squared_error: 0.1071\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.1109 - val_mean_squared_error: 0.1109\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.1142 - val_mean_squared_error: 0.1142\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.1136 - val_mean_squared_error: 0.1136\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.1153 - val_mean_squared_error: 0.1153\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.1174 - val_mean_squared_error: 0.1174\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.1186 - val_mean_squared_error: 0.1186\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.1193 - val_mean_squared_error: 0.1193\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.1183 - val_mean_squared_error: 0.1183\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.1202 - val_mean_squared_error: 0.1202\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.1234 - val_mean_squared_error: 0.1234\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.1193 - val_mean_squared_error: 0.1193\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.1216 - val_mean_squared_error: 0.1216\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.1232 - val_mean_squared_error: 0.1232\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1232 - val_mean_squared_error: 0.1232\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1211 - val_mean_squared_error: 0.1211\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1216 - val_mean_squared_error: 0.1216\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.1232 - val_mean_squared_error: 0.1232\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1239 - val_mean_squared_error: 0.1239\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.1217 - val_mean_squared_error: 0.1217\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1256 - val_mean_squared_error: 0.1256\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.1198 - val_mean_squared_error: 0.1198\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1275 - val_mean_squared_error: 0.1275\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1257 - val_mean_squared_error: 0.1257\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.1287 - val_mean_squared_error: 0.1287\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1300 - val_mean_squared_error: 0.1300\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1213 - val_mean_squared_error: 0.1213\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1258 - val_mean_squared_error: 0.1258\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1363 - val_mean_squared_error: 0.1363\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1282 - val_mean_squared_error: 0.1282\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1296 - val_mean_squared_error: 0.1296\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1337 - val_mean_squared_error: 0.1337\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1264 - val_mean_squared_error: 0.1264\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1415 - val_mean_squared_error: 0.1415\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1340 - val_mean_squared_error: 0.1340\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1457 - val_mean_squared_error: 0.1457\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1391 - val_mean_squared_error: 0.1391\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1406 - val_mean_squared_error: 0.1406\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1303 - val_mean_squared_error: 0.1303\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 48us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1442 - val_mean_squared_error: 0.1442\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1388 - val_mean_squared_error: 0.1388\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1394 - val_mean_squared_error: 0.1394\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1606 - val_mean_squared_error: 0.1606\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1437 - val_mean_squared_error: 0.1437\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1485 - val_mean_squared_error: 0.1485\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1552 - val_mean_squared_error: 0.1552\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1460 - val_mean_squared_error: 0.1460\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1531 - val_mean_squared_error: 0.1531\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1665 - val_mean_squared_error: 0.1665\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1537 - val_mean_squared_error: 0.1537\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1763 - val_mean_squared_error: 0.1763\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1504 - val_mean_squared_error: 0.1504\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1631 - val_mean_squared_error: 0.1631\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1779 - val_mean_squared_error: 0.1779\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1505 - val_mean_squared_error: 0.1505\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1678 - val_mean_squared_error: 0.1678\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1750 - val_mean_squared_error: 0.1750\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1733 - val_mean_squared_error: 0.1733\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1785 - val_mean_squared_error: 0.1785\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1670 - val_mean_squared_error: 0.1670\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1720 - val_mean_squared_error: 0.1720\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1760 - val_mean_squared_error: 0.1760\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1804 - val_mean_squared_error: 0.1804\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1793 - val_mean_squared_error: 0.1793\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1800 - val_mean_squared_error: 0.1800\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1635 - val_mean_squared_error: 0.1635\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.2112 - val_mean_squared_error: 0.2112\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.1769 - val_mean_squared_error: 0.1769\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.2015 - val_mean_squared_error: 0.2015\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1968 - val_mean_squared_error: 0.1968\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1914 - val_mean_squared_error: 0.1914\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2026 - val_mean_squared_error: 0.2026\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1930 - val_mean_squared_error: 0.1930\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1994 - val_mean_squared_error: 0.1994\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.2306 - val_mean_squared_error: 0.2306\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.1900 - val_mean_squared_error: 0.1900\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2129 - val_mean_squared_error: 0.2129\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2181 - val_mean_squared_error: 0.2181\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2097 - val_mean_squared_error: 0.2097\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1845 - val_mean_squared_error: 0.1845\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.2250 - val_mean_squared_error: 0.2250\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2431 - val_mean_squared_error: 0.2431\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.2135 - val_mean_squared_error: 0.2135\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2065 - val_mean_squared_error: 0.2065\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2282 - val_mean_squared_error: 0.2282\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2183 - val_mean_squared_error: 0.2183\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.2141 - val_mean_squared_error: 0.2141\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2362 - val_mean_squared_error: 0.2362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2430 - val_mean_squared_error: 0.2430\n",
      "It has been 3.9794998168945312 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.2330 - mean_squared_error: 0.2330 - val_loss: 0.3765 - val_mean_squared_error: 0.3765\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.0861 - mean_squared_error: 0.0861 - val_loss: 0.9075 - val_mean_squared_error: 0.9075\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 43us/step - loss: 0.0733 - mean_squared_error: 0.0733 - val_loss: 0.3410 - val_mean_squared_error: 0.3410\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0490 - mean_squared_error: 0.0490 - val_loss: 0.1825 - val_mean_squared_error: 0.1825\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0409 - mean_squared_error: 0.0409 - val_loss: 0.2715 - val_mean_squared_error: 0.2715\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.2857 - val_mean_squared_error: 0.2857\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.2411 - val_mean_squared_error: 0.2411\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.2188 - val_mean_squared_error: 0.2188\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.2520 - val_mean_squared_error: 0.2520\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.2249 - val_mean_squared_error: 0.2249\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.2090 - val_mean_squared_error: 0.2090\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0262 - mean_squared_error: 0.0262 - val_loss: 0.2241 - val_mean_squared_error: 0.2241\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.2306 - val_mean_squared_error: 0.2306\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.1975 - val_mean_squared_error: 0.1975\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.2079 - val_mean_squared_error: 0.2079\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.2098 - val_mean_squared_error: 0.2098\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.1859 - val_mean_squared_error: 0.1859\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.2052 - val_mean_squared_error: 0.2052\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0216 - mean_squared_error: 0.0216 - val_loss: 0.1887 - val_mean_squared_error: 0.1887\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.1866 - val_mean_squared_error: 0.1866\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.1807 - val_mean_squared_error: 0.1807\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.1804 - val_mean_squared_error: 0.1804\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.1733 - val_mean_squared_error: 0.1733\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.1687 - val_mean_squared_error: 0.1687\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.1723 - val_mean_squared_error: 0.1723\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.1643 - val_mean_squared_error: 0.1643\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.1657 - val_mean_squared_error: 0.1657\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.1599 - val_mean_squared_error: 0.1599\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.1562 - val_mean_squared_error: 0.1562\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.1539 - val_mean_squared_error: 0.1539\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.1513 - val_mean_squared_error: 0.1513\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.1439 - val_mean_squared_error: 0.1439\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.1438 - val_mean_squared_error: 0.1438\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.1415 - val_mean_squared_error: 0.1415\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.1370 - val_mean_squared_error: 0.1370\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.1371 - val_mean_squared_error: 0.1371\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.1363 - val_mean_squared_error: 0.1363\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.1324 - val_mean_squared_error: 0.1324\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.1264 - val_mean_squared_error: 0.1264\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.1267 - val_mean_squared_error: 0.1267\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.1228 - val_mean_squared_error: 0.1228\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1227 - val_mean_squared_error: 0.1227\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1183 - val_mean_squared_error: 0.1183\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.1205 - val_mean_squared_error: 0.1205\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.1174 - val_mean_squared_error: 0.1174\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.1170 - val_mean_squared_error: 0.1170\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.1142 - val_mean_squared_error: 0.1142\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1134 - val_mean_squared_error: 0.1134\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 50us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.1130 - val_mean_squared_error: 0.1130\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1114 - val_mean_squared_error: 0.1114\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1104 - val_mean_squared_error: 0.1104\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.1105 - val_mean_squared_error: 0.1105\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1084 - val_mean_squared_error: 0.1084\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1071 - val_mean_squared_error: 0.1071\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1066 - val_mean_squared_error: 0.1066\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.1061 - val_mean_squared_error: 0.1061\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.1042 - val_mean_squared_error: 0.1042\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1053 - val_mean_squared_error: 0.1053\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1049 - val_mean_squared_error: 0.1049\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.1037 - val_mean_squared_error: 0.1037\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1035 - val_mean_squared_error: 0.1035\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.1038 - val_mean_squared_error: 0.1038\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1029 - val_mean_squared_error: 0.1029\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1034 - val_mean_squared_error: 0.1034\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1032 - val_mean_squared_error: 0.1032\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1011 - val_mean_squared_error: 0.1011\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1039 - val_mean_squared_error: 0.1039\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.1011 - val_mean_squared_error: 0.1011\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1036 - val_mean_squared_error: 0.1036\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1015 - val_mean_squared_error: 0.1015\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.1040 - val_mean_squared_error: 0.1040\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1040 - val_mean_squared_error: 0.1040\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1073 - val_mean_squared_error: 0.1073\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1019 - val_mean_squared_error: 0.1019\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.1066 - val_mean_squared_error: 0.1066\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1067 - val_mean_squared_error: 0.1067\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1065 - val_mean_squared_error: 0.1065\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.1020 - val_mean_squared_error: 0.1020\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1110 - val_mean_squared_error: 0.1110\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1021 - val_mean_squared_error: 0.1021\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1155 - val_mean_squared_error: 0.1155\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.1067 - val_mean_squared_error: 0.1067\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1144 - val_mean_squared_error: 0.1144\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1145 - val_mean_squared_error: 0.1145\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.1038 - val_mean_squared_error: 0.1038\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1160 - val_mean_squared_error: 0.1160\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1120 - val_mean_squared_error: 0.1120\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1081 - val_mean_squared_error: 0.1081\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1258 - val_mean_squared_error: 0.1258\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1048 - val_mean_squared_error: 0.1048\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1184 - val_mean_squared_error: 0.1184\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1221 - val_mean_squared_error: 0.1221\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1128 - val_mean_squared_error: 0.1128\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1252 - val_mean_squared_error: 0.1252\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1227 - val_mean_squared_error: 0.1227\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1254 - val_mean_squared_error: 0.1254\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1124 - val_mean_squared_error: 0.1124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1336 - val_mean_squared_error: 0.1336\n",
      "It has been 4.0123069286346436 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.1648 - mean_squared_error: 0.1648 - val_loss: 0.8851 - val_mean_squared_error: 0.8851\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 45us/step - loss: 0.1031 - mean_squared_error: 0.1031 - val_loss: 0.6069 - val_mean_squared_error: 0.6069\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 42us/step - loss: 0.0648 - mean_squared_error: 0.0648 - val_loss: 0.2081 - val_mean_squared_error: 0.2081\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0504 - mean_squared_error: 0.0504 - val_loss: 0.2592 - val_mean_squared_error: 0.2592\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.2697 - val_mean_squared_error: 0.2697\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.2197 - val_mean_squared_error: 0.2197\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.2253 - val_mean_squared_error: 0.2253\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.2053 - val_mean_squared_error: 0.2053\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0267 - mean_squared_error: 0.0267 - val_loss: 0.1959 - val_mean_squared_error: 0.1959\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.1963 - val_mean_squared_error: 0.1963\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.1946 - val_mean_squared_error: 0.1946\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 46us/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.1956 - val_mean_squared_error: 0.1956\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.1802 - val_mean_squared_error: 0.1802\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.1692 - val_mean_squared_error: 0.1692\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.1850 - val_mean_squared_error: 0.1850\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.1765 - val_mean_squared_error: 0.1765\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.1533 - val_mean_squared_error: 0.1533\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.1748 - val_mean_squared_error: 0.1748\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.1496 - val_mean_squared_error: 0.1496\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.1539 - val_mean_squared_error: 0.1539\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.1511 - val_mean_squared_error: 0.1511\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.1336 - val_mean_squared_error: 0.1336\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.1544 - val_mean_squared_error: 0.1544\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.1307 - val_mean_squared_error: 0.1307\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.1345 - val_mean_squared_error: 0.1345\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1310 - val_mean_squared_error: 0.1310\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.1188 - val_mean_squared_error: 0.1188\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.1167 - val_mean_squared_error: 0.1167\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.1201 - val_mean_squared_error: 0.1201\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.1150 - val_mean_squared_error: 0.1150\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1052 - val_mean_squared_error: 0.1052\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1084 - val_mean_squared_error: 0.1084\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0998 - val_mean_squared_error: 0.0998\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1045 - val_mean_squared_error: 0.1045\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0937 - val_mean_squared_error: 0.0937\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.1100 - val_mean_squared_error: 0.1100\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0919 - val_mean_squared_error: 0.0919\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0992 - val_mean_squared_error: 0.0992\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0832 - val_mean_squared_error: 0.0832\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0866 - val_mean_squared_error: 0.0866\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0787 - val_mean_squared_error: 0.0787\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0804 - val_mean_squared_error: 0.0804\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0798 - val_mean_squared_error: 0.0798\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0791 - val_mean_squared_error: 0.0791\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0726 - val_mean_squared_error: 0.0726\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0764 - val_mean_squared_error: 0.0764\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0719 - val_mean_squared_error: 0.0719\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0670 - val_mean_squared_error: 0.0670\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0711 - val_mean_squared_error: 0.0711\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 52us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0656 - val_mean_squared_error: 0.0656\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0663 - val_mean_squared_error: 0.0663\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0625 - val_mean_squared_error: 0.0625\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0669 - val_mean_squared_error: 0.0669\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0606 - val_mean_squared_error: 0.0606\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0602 - val_mean_squared_error: 0.0602\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0610 - val_mean_squared_error: 0.0610\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0580 - val_mean_squared_error: 0.0580\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0559 - val_mean_squared_error: 0.0559\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0627 - val_mean_squared_error: 0.0627\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0549 - val_mean_squared_error: 0.0549\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0562 - val_mean_squared_error: 0.0562\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0556 - val_mean_squared_error: 0.0556\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0547 - val_mean_squared_error: 0.0547\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0540 - val_mean_squared_error: 0.0540\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0543 - val_mean_squared_error: 0.0543\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0543 - val_mean_squared_error: 0.0543\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0534 - val_mean_squared_error: 0.0534\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0534 - val_mean_squared_error: 0.0534\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0533 - val_mean_squared_error: 0.0533\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0536 - val_mean_squared_error: 0.0536\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0536 - val_mean_squared_error: 0.0536\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0531 - val_mean_squared_error: 0.0531\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0541 - val_mean_squared_error: 0.0541\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0540 - val_mean_squared_error: 0.0540\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0533 - val_mean_squared_error: 0.0533\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0566 - val_mean_squared_error: 0.0566\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0542 - val_mean_squared_error: 0.0542\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0543 - val_mean_squared_error: 0.0543\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0540 - val_mean_squared_error: 0.0540\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0540 - val_mean_squared_error: 0.0540\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0569 - val_mean_squared_error: 0.0569\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0567 - val_mean_squared_error: 0.0567\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0543 - val_mean_squared_error: 0.0543\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0533 - val_mean_squared_error: 0.0533\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0590 - val_mean_squared_error: 0.0590\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0673 - val_mean_squared_error: 0.0673\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0563 - val_mean_squared_error: 0.0563\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0558 - val_mean_squared_error: 0.0558\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0606 - val_mean_squared_error: 0.0606\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0627 - val_mean_squared_error: 0.0627\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0575 - val_mean_squared_error: 0.0575\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 48us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0640 - val_mean_squared_error: 0.0640\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0726 - val_mean_squared_error: 0.0726\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 47us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0597 - val_mean_squared_error: 0.0597\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0617 - val_mean_squared_error: 0.0617\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0673 - val_mean_squared_error: 0.0673\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0664 - val_mean_squared_error: 0.0664\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0639 - val_mean_squared_error: 0.0639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0769 - val_mean_squared_error: 0.0769\n",
      "It has been 4.098490953445435 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.1480 - mean_squared_error: 0.1480 - val_loss: 0.8450 - val_mean_squared_error: 0.8450\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0808 - mean_squared_error: 0.0808 - val_loss: 0.5549 - val_mean_squared_error: 0.5549\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0447 - mean_squared_error: 0.0447 - val_loss: 0.2049 - val_mean_squared_error: 0.2049\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.2633 - val_mean_squared_error: 0.2633\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.2929 - val_mean_squared_error: 0.2929\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 60us/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.2222 - val_mean_squared_error: 0.2222\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 62us/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.2597 - val_mean_squared_error: 0.2597\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 62us/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.2557 - val_mean_squared_error: 0.2557\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.2499 - val_mean_squared_error: 0.2499\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.2429 - val_mean_squared_error: 0.2429\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.2441 - val_mean_squared_error: 0.2441\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.2329 - val_mean_squared_error: 0.2329\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.2367 - val_mean_squared_error: 0.2367\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.2135 - val_mean_squared_error: 0.2135\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.2300 - val_mean_squared_error: 0.2300\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.2120 - val_mean_squared_error: 0.2120\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 50us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.2096 - val_mean_squared_error: 0.2096\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.2012 - val_mean_squared_error: 0.2012\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.1988 - val_mean_squared_error: 0.1988\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.2035 - val_mean_squared_error: 0.2035\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.1893 - val_mean_squared_error: 0.1893\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.1969 - val_mean_squared_error: 0.1969\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.1803 - val_mean_squared_error: 0.1803\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 58us/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.1803 - val_mean_squared_error: 0.1803\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 60us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.1820 - val_mean_squared_error: 0.1820\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 61us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1690 - val_mean_squared_error: 0.1690\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 61us/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.1735 - val_mean_squared_error: 0.1735\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 61us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.1593 - val_mean_squared_error: 0.1593\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 60us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.1720 - val_mean_squared_error: 0.1720\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 61us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.1578 - val_mean_squared_error: 0.1578\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.1501 - val_mean_squared_error: 0.1501\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.1570 - val_mean_squared_error: 0.1570\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.1409 - val_mean_squared_error: 0.1409\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.1492 - val_mean_squared_error: 0.1492\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1353 - val_mean_squared_error: 0.1353\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.1457 - val_mean_squared_error: 0.1457\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1322 - val_mean_squared_error: 0.1322\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.1343 - val_mean_squared_error: 0.1343\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.1308 - val_mean_squared_error: 0.1308\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1243 - val_mean_squared_error: 0.1243\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1308 - val_mean_squared_error: 0.1308\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1364 - val_mean_squared_error: 0.1364\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.1195 - val_mean_squared_error: 0.1195\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.1132 - val_mean_squared_error: 0.1132\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1199 - val_mean_squared_error: 0.1199\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.1130 - val_mean_squared_error: 0.1130\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1053 - val_mean_squared_error: 0.1053\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1167 - val_mean_squared_error: 0.1167\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 52us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.1114 - val_mean_squared_error: 0.1114\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1048 - val_mean_squared_error: 0.1048\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1013 - val_mean_squared_error: 0.1013\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1000 - val_mean_squared_error: 0.1000\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.1051 - val_mean_squared_error: 0.1051\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0965 - val_mean_squared_error: 0.0965\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.1010 - val_mean_squared_error: 0.1010\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 49us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0991 - val_mean_squared_error: 0.0991\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0908 - val_mean_squared_error: 0.0908\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0951 - val_mean_squared_error: 0.0951\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 75us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0994 - val_mean_squared_error: 0.0994\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 96us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0875 - val_mean_squared_error: 0.0875\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 91us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0925 - val_mean_squared_error: 0.0925\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 111us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0970 - val_mean_squared_error: 0.0970\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 103us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0857 - val_mean_squared_error: 0.0857\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 118us/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0906 - val_mean_squared_error: 0.0906\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 96us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0902 - val_mean_squared_error: 0.0902\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 72us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0859 - val_mean_squared_error: 0.0859\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 59us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0857 - val_mean_squared_error: 0.0857\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 59us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0867 - val_mean_squared_error: 0.0867\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0841 - val_mean_squared_error: 0.0841\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0881 - val_mean_squared_error: 0.0881\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 58us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0843 - val_mean_squared_error: 0.0843\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0852 - val_mean_squared_error: 0.0852\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0853 - val_mean_squared_error: 0.0853\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0854 - val_mean_squared_error: 0.0854\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0830 - val_mean_squared_error: 0.0830\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0831 - val_mean_squared_error: 0.0831\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 52us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0837 - val_mean_squared_error: 0.0837\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 67us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0823 - val_mean_squared_error: 0.0823\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 94us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0840 - val_mean_squared_error: 0.0840\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 101us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0826 - val_mean_squared_error: 0.0826\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 99us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0818 - val_mean_squared_error: 0.0818\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 95us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0833 - val_mean_squared_error: 0.0833\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 97us/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0825 - val_mean_squared_error: 0.0825\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 75us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0816 - val_mean_squared_error: 0.0816\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 74us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0829 - val_mean_squared_error: 0.0829\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 74us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0823 - val_mean_squared_error: 0.0823\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 67us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0828 - val_mean_squared_error: 0.0828\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 72us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 69us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0819 - val_mean_squared_error: 0.0819\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 73us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0842 - val_mean_squared_error: 0.0842\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 73us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0833 - val_mean_squared_error: 0.0833\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 69us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0829 - val_mean_squared_error: 0.0829\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 76us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0831 - val_mean_squared_error: 0.0831\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 65us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0837 - val_mean_squared_error: 0.0837\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 73us/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0817 - val_mean_squared_error: 0.0817\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 70us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 73us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0823 - val_mean_squared_error: 0.0823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 88us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0814 - val_mean_squared_error: 0.0814\n",
      "It has been 4.602020025253296 seconds since this iteration started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00899663, 0.08226673, 0.08325124])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(287, 360)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.0589 - mean_squared_error: 0.0589 - val_loss: 0.1590 - val_mean_squared_error: 0.1590\n",
      "Epoch 2/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0867 - val_mean_squared_error: 0.0867\n",
      "Epoch 3/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.0901 - val_mean_squared_error: 0.0901\n",
      "Epoch 4/100\n",
      "287/287 [==============================] - 0s 62us/step - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0919 - val_mean_squared_error: 0.0919\n",
      "Epoch 5/100\n",
      "287/287 [==============================] - 0s 59us/step - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0919 - val_mean_squared_error: 0.0919\n",
      "Epoch 6/100\n",
      "287/287 [==============================] - 0s 61us/step - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0944 - val_mean_squared_error: 0.0944\n",
      "Epoch 7/100\n",
      "287/287 [==============================] - 0s 60us/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0949 - val_mean_squared_error: 0.0949\n",
      "Epoch 8/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0944 - val_mean_squared_error: 0.0944\n",
      "Epoch 9/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0960 - val_mean_squared_error: 0.0960\n",
      "Epoch 10/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.0943 - val_mean_squared_error: 0.0943\n",
      "Epoch 11/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0985 - val_mean_squared_error: 0.0985\n",
      "Epoch 12/100\n",
      "287/287 [==============================] - 0s 59us/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.1001 - val_mean_squared_error: 0.1001\n",
      "Epoch 13/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0955 - val_mean_squared_error: 0.0955\n",
      "Epoch 14/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.1017 - val_mean_squared_error: 0.1017\n",
      "Epoch 15/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0922 - val_mean_squared_error: 0.0922\n",
      "Epoch 16/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.1061 - val_mean_squared_error: 0.1061\n",
      "Epoch 17/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0887 - val_mean_squared_error: 0.0887\n",
      "Epoch 18/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.1139 - val_mean_squared_error: 0.1139\n",
      "Epoch 19/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0941 - val_mean_squared_error: 0.0941\n",
      "Epoch 20/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0982 - val_mean_squared_error: 0.0982\n",
      "Epoch 21/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.1066 - val_mean_squared_error: 0.1066\n",
      "Epoch 22/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0953 - val_mean_squared_error: 0.0953\n",
      "Epoch 23/100\n",
      "287/287 [==============================] - 0s 64us/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.1117 - val_mean_squared_error: 0.1117\n",
      "Epoch 24/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0926 - val_mean_squared_error: 0.0926\n",
      "Epoch 25/100\n",
      "287/287 [==============================] - 0s 53us/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.1052 - val_mean_squared_error: 0.1052\n",
      "Epoch 26/100\n",
      "287/287 [==============================] - 0s 70us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.1052 - val_mean_squared_error: 0.1052\n",
      "Epoch 27/100\n",
      "287/287 [==============================] - 0s 89us/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.1113 - val_mean_squared_error: 0.1113\n",
      "Epoch 28/100\n",
      "287/287 [==============================] - 0s 100us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0987 - val_mean_squared_error: 0.0987\n",
      "Epoch 29/100\n",
      "287/287 [==============================] - 0s 90us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.1114 - val_mean_squared_error: 0.1114\n",
      "Epoch 30/100\n",
      "287/287 [==============================] - 0s 86us/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.1104 - val_mean_squared_error: 0.1104\n",
      "Epoch 31/100\n",
      "287/287 [==============================] - 0s 68us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.1044 - val_mean_squared_error: 0.1044\n",
      "Epoch 32/100\n",
      "287/287 [==============================] - 0s 74us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.1190 - val_mean_squared_error: 0.1190\n",
      "Epoch 33/100\n",
      "287/287 [==============================] - 0s 82us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1008 - val_mean_squared_error: 0.1008\n",
      "Epoch 34/100\n",
      "287/287 [==============================] - 0s 69us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0964 - val_mean_squared_error: 0.0964\n",
      "Epoch 35/100\n",
      "287/287 [==============================] - 0s 70us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.1202 - val_mean_squared_error: 0.1202\n",
      "Epoch 36/100\n",
      "287/287 [==============================] - 0s 86us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.1175 - val_mean_squared_error: 0.1175\n",
      "Epoch 37/100\n",
      "287/287 [==============================] - 0s 73us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.1144 - val_mean_squared_error: 0.1144\n",
      "Epoch 38/100\n",
      "287/287 [==============================] - 0s 59us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.1106 - val_mean_squared_error: 0.1106\n",
      "Epoch 39/100\n",
      "287/287 [==============================] - 0s 66us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.1214 - val_mean_squared_error: 0.1214\n",
      "Epoch 40/100\n",
      "287/287 [==============================] - 0s 59us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.1256 - val_mean_squared_error: 0.1256\n",
      "Epoch 41/100\n",
      "287/287 [==============================] - 0s 62us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.1310 - val_mean_squared_error: 0.1310\n",
      "Epoch 42/100\n",
      "287/287 [==============================] - 0s 61us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.1199 - val_mean_squared_error: 0.1199\n",
      "Epoch 43/100\n",
      "287/287 [==============================] - 0s 63us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1316 - val_mean_squared_error: 0.1316\n",
      "Epoch 44/100\n",
      "287/287 [==============================] - 0s 62us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.1361 - val_mean_squared_error: 0.1361\n",
      "Epoch 45/100\n",
      "287/287 [==============================] - 0s 60us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.1190 - val_mean_squared_error: 0.1190\n",
      "Epoch 46/100\n",
      "287/287 [==============================] - 0s 65us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.1467 - val_mean_squared_error: 0.1467\n",
      "Epoch 47/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1314 - val_mean_squared_error: 0.1314\n",
      "Epoch 48/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.1478 - val_mean_squared_error: 0.1478\n",
      "Epoch 49/100\n",
      "287/287 [==============================] - 0s 62us/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.1177 - val_mean_squared_error: 0.1177\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s 64us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1437 - val_mean_squared_error: 0.1437\n",
      "Epoch 51/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1192 - val_mean_squared_error: 0.1192\n",
      "Epoch 52/100\n",
      "287/287 [==============================] - 0s 61us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.1254 - val_mean_squared_error: 0.1254\n",
      "Epoch 53/100\n",
      "287/287 [==============================] - 0s 61us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.1672 - val_mean_squared_error: 0.1672\n",
      "Epoch 54/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.1541 - val_mean_squared_error: 0.1541\n",
      "Epoch 55/100\n",
      "287/287 [==============================] - 0s 59us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.1319 - val_mean_squared_error: 0.1319\n",
      "Epoch 56/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1528 - val_mean_squared_error: 0.1528\n",
      "Epoch 57/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.1640 - val_mean_squared_error: 0.1640\n",
      "Epoch 58/100\n",
      "287/287 [==============================] - 0s 60us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1446 - val_mean_squared_error: 0.1446\n",
      "Epoch 59/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.1253 - val_mean_squared_error: 0.1253\n",
      "Epoch 60/100\n",
      "287/287 [==============================] - 0s 58us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.1699 - val_mean_squared_error: 0.1699\n",
      "Epoch 61/100\n",
      "287/287 [==============================] - 0s 58us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.1825 - val_mean_squared_error: 0.1825\n",
      "Epoch 62/100\n",
      "287/287 [==============================] - 0s 59us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.1494 - val_mean_squared_error: 0.1494\n",
      "Epoch 63/100\n",
      "287/287 [==============================] - 0s 61us/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.1736 - val_mean_squared_error: 0.1736\n",
      "Epoch 64/100\n",
      "287/287 [==============================] - 0s 67us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1420 - val_mean_squared_error: 0.1420\n",
      "Epoch 65/100\n",
      "287/287 [==============================] - 0s 59us/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.1517 - val_mean_squared_error: 0.1517\n",
      "Epoch 66/100\n",
      "287/287 [==============================] - 0s 59us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1823 - val_mean_squared_error: 0.1823\n",
      "Epoch 67/100\n",
      "287/287 [==============================] - 0s 62us/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.1960 - val_mean_squared_error: 0.1960\n",
      "Epoch 68/100\n",
      "287/287 [==============================] - 0s 60us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1685 - val_mean_squared_error: 0.1685\n",
      "Epoch 69/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.1774 - val_mean_squared_error: 0.1774\n",
      "Epoch 70/100\n",
      "287/287 [==============================] - 0s 58us/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.2021 - val_mean_squared_error: 0.2021\n",
      "Epoch 71/100\n",
      "287/287 [==============================] - 0s 58us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.1691 - val_mean_squared_error: 0.1691\n",
      "Epoch 72/100\n",
      "287/287 [==============================] - 0s 58us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1614 - val_mean_squared_error: 0.1614\n",
      "Epoch 73/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1885 - val_mean_squared_error: 0.1885\n",
      "Epoch 74/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.1897 - val_mean_squared_error: 0.1897\n",
      "Epoch 75/100\n",
      "287/287 [==============================] - 0s 61us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1753 - val_mean_squared_error: 0.1753\n",
      "Epoch 76/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1934 - val_mean_squared_error: 0.1934\n",
      "Epoch 77/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.1852 - val_mean_squared_error: 0.1852\n",
      "Epoch 78/100\n",
      "287/287 [==============================] - 0s 55us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.2059 - val_mean_squared_error: 0.2059\n",
      "Epoch 79/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.2120 - val_mean_squared_error: 0.2120\n",
      "Epoch 80/100\n",
      "287/287 [==============================] - 0s 51us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.1739 - val_mean_squared_error: 0.1739\n",
      "Epoch 81/100\n",
      "287/287 [==============================] - 0s 54us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1869 - val_mean_squared_error: 0.1869\n",
      "Epoch 82/100\n",
      "287/287 [==============================] - 0s 56us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2382 - val_mean_squared_error: 0.2382\n",
      "Epoch 83/100\n",
      "287/287 [==============================] - 0s 60us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.2126 - val_mean_squared_error: 0.2126\n",
      "Epoch 84/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2130 - val_mean_squared_error: 0.2130\n",
      "Epoch 85/100\n",
      "287/287 [==============================] - 0s 57us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.1718 - val_mean_squared_error: 0.1718\n",
      "Epoch 86/100\n",
      "287/287 [==============================] - 0s 58us/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.1984 - val_mean_squared_error: 0.1984\n",
      "Epoch 87/100\n",
      "287/287 [==============================] - 0s 60us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.2091 - val_mean_squared_error: 0.2091\n",
      "Epoch 88/100\n",
      "287/287 [==============================] - 0s 62us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2280 - val_mean_squared_error: 0.2280\n",
      "Epoch 89/100\n",
      "287/287 [==============================] - 0s 68us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2205 - val_mean_squared_error: 0.2205\n",
      "Epoch 90/100\n",
      "287/287 [==============================] - 0s 82us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2192 - val_mean_squared_error: 0.2192\n",
      "Epoch 91/100\n",
      "287/287 [==============================] - 0s 98us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2023 - val_mean_squared_error: 0.2023\n",
      "Epoch 92/100\n",
      "287/287 [==============================] - 0s 108us/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.2215 - val_mean_squared_error: 0.2215\n",
      "Epoch 93/100\n",
      "287/287 [==============================] - 0s 97us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.2562 - val_mean_squared_error: 0.2562\n",
      "Epoch 94/100\n",
      "287/287 [==============================] - 0s 82us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2061 - val_mean_squared_error: 0.2061\n",
      "Epoch 95/100\n",
      "287/287 [==============================] - 0s 90us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.1989 - val_mean_squared_error: 0.1989\n",
      "Epoch 96/100\n",
      "287/287 [==============================] - 0s 80us/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.2144 - val_mean_squared_error: 0.2144\n",
      "Epoch 97/100\n",
      "287/287 [==============================] - 0s 82us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.2548 - val_mean_squared_error: 0.2548\n",
      "Epoch 98/100\n",
      "287/287 [==============================] - 0s 84us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2446 - val_mean_squared_error: 0.2446\n",
      "Epoch 99/100\n",
      "287/287 [==============================] - 0s 97us/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.2211 - val_mean_squared_error: 0.2211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "287/287 [==============================] - 0s 88us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.2035 - val_mean_squared_error: 0.2035\n",
      "It has been 4.878367900848389 seconds since this iteration started\n",
      "It has been 145.48865294456482 seconds since the loop started\n"
     ]
    }
   ],
   "source": [
    "gvkey_dict = {}\n",
    "\n",
    "loop_start = time.time()\n",
    "\n",
    "for gvkey in df['gvkey'].unique()[:50]:\n",
    "    stock_start = time.time()\n",
    "    df_temp = df[df['gvkey'] == 1266]\n",
    "    df_temp['year'] = df_temp['year'].map(lambda x: str(x))\n",
    "    df_temp['month'] = df_temp['month'].map(lambda x: str(x))\n",
    "    df_temp['-'] = '-'\n",
    "    df_temp['timestemp'] = df_temp['year'] + df_temp['-'] + df_temp['month']\n",
    "    df_temp['timestemp'] = pd.to_datetime(df_temp['timestemp'])\n",
    "    df_temp = df_temp.set_index('timestemp')\n",
    "    df_temp = df_temp.drop(['active', 'year', 'month', '-', 'date'], axis=1)\n",
    "    df_temp['EBIT'] = df_temp['saleq_ttm'] - df_temp['cogsq_ttm'] - df_temp['xsgaq_ttm']\n",
    "    df_temp['EBIT/EV'] = df_temp['EBIT'] / df_temp['entval']\n",
    "    \n",
    "    featureList = ['mom1m','mom3m','cogsq_ttm', 'xsgaq_ttm', 'oiadpq_ttm',\n",
    "       'niq_ttm', 'cheq_mrq', 'rectq_mrq', 'invtq_mrq', 'acoq_mrq',\n",
    "       'ppentq_mrq', 'aoq_mrq', 'dlcq_mrq', 'apq_mrq', 'txpq_mrq', 'lcoq_mrq',\n",
    "       'ltq_mrq', 'seqq_mrq', 'atq_mrq', 'csho_1yr_avg', 'adjusted_price',\n",
    "       'prccm', 'ajexm']\n",
    "\n",
    "    df_temp.drop(['gvkey', 'gics-sector'], axis=1, inplace=True)\n",
    "    df_temp = df_temp[~df_temp.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "    df_temp.dropna(inplace=True)\n",
    "    \n",
    "    periods = 12\n",
    "    \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    df_temp = pd.DataFrame(min_max_scaler.fit_transform(df_temp), columns=df_temp.columns.values)\n",
    "\n",
    "    df_temp['Y'] = df_temp.iloc[:, -1].shift(periods=-periods)\n",
    "    df_temp.dropna(inplace=True)\n",
    "    \n",
    "    seq_df = []\n",
    "    prev_months = deque(maxlen=12)\n",
    "\n",
    "    for i in df_temp.values:\n",
    "        prev_months.append(i)\n",
    "        if len(prev_months) == 12:\n",
    "            seq_df.append(np.array(prev_months))  \n",
    "\n",
    "    seq_df = np.array(seq_df)\n",
    "    \n",
    "    Y = seq_df[:, -1, -1]\n",
    "    X = seq_df[:, :, :-1]\n",
    "\n",
    "    display(X.shape[1:])\n",
    "    X_temp = X.reshape((X.shape[0], X.shape[1]*X.shape[2]))\n",
    "\n",
    "    display(X_temp[0,[29,59,89]])\n",
    "    \n",
    "    X_train = X_temp[:int(len(X)*0.7)]\n",
    "    X_test = X_temp[int(len(X)*0.7):]\n",
    "\n",
    "    Y_train = Y[:int(len(X)*0.7)]\n",
    "    Y_test = Y[int(len(X)*0.7):]\n",
    "    \n",
    "    display(X_train.shape)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_shape=(360,)))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "    \n",
    "    model.fit(X_train, Y_train, epochs=100, validation_data=(X_test, Y_test))\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    \n",
    "    gvkey_dict[gvkey] = Y_pred[:,0]\n",
    "    stock_end = time.time()\n",
    "    print(\"It has been {0} seconds since this iteration started\".format(stock_end - stock_start))\n",
    "    \n",
    "loop_end = time.time()\n",
    "print(\"It has been {0} seconds since the loop started\".format(loop_end - loop_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>61527</th>\n",
       "      <th>9715</th>\n",
       "      <th>1266</th>\n",
       "      <th>26753</th>\n",
       "      <th>28629</th>\n",
       "      <th>187406</th>\n",
       "      <th>10453</th>\n",
       "      <th>188157</th>\n",
       "      <th>183257</th>\n",
       "      <th>137432</th>\n",
       "      <th>9846</th>\n",
       "      <th>65671</th>\n",
       "      <th>10232</th>\n",
       "      <th>12216</th>\n",
       "      <th>20089</th>\n",
       "      <th>1718</th>\n",
       "      <th>112754</th>\n",
       "      <th>163118</th>\n",
       "      <th>180466</th>\n",
       "      <th>27965</th>\n",
       "      <th>144235</th>\n",
       "      <th>24832</th>\n",
       "      <th>2271</th>\n",
       "      <th>127282</th>\n",
       "      <th>19580</th>\n",
       "      <th>116504</th>\n",
       "      <th>20949</th>\n",
       "      <th>182701</th>\n",
       "      <th>14954</th>\n",
       "      <th>16582</th>\n",
       "      <th>8497</th>\n",
       "      <th>9372</th>\n",
       "      <th>111961</th>\n",
       "      <th>10247</th>\n",
       "      <th>146669</th>\n",
       "      <th>29143</th>\n",
       "      <th>64549</th>\n",
       "      <th>6565</th>\n",
       "      <th>63383</th>\n",
       "      <th>65142</th>\n",
       "      <th>175741</th>\n",
       "      <th>174663</th>\n",
       "      <th>10420</th>\n",
       "      <th>28317</th>\n",
       "      <th>176343</th>\n",
       "      <th>5977</th>\n",
       "      <th>27119</th>\n",
       "      <th>12304</th>\n",
       "      <th>3813</th>\n",
       "      <th>162198</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.372936</td>\n",
       "      <td>0.313453</td>\n",
       "      <td>0.361009</td>\n",
       "      <td>0.281325</td>\n",
       "      <td>0.335872</td>\n",
       "      <td>0.404536</td>\n",
       "      <td>0.358857</td>\n",
       "      <td>0.367288</td>\n",
       "      <td>0.302574</td>\n",
       "      <td>0.209094</td>\n",
       "      <td>0.198159</td>\n",
       "      <td>0.209285</td>\n",
       "      <td>0.215278</td>\n",
       "      <td>0.195743</td>\n",
       "      <td>0.352122</td>\n",
       "      <td>0.253826</td>\n",
       "      <td>0.348131</td>\n",
       "      <td>0.219558</td>\n",
       "      <td>0.269325</td>\n",
       "      <td>0.266666</td>\n",
       "      <td>0.347717</td>\n",
       "      <td>0.284155</td>\n",
       "      <td>0.271331</td>\n",
       "      <td>0.216798</td>\n",
       "      <td>0.271040</td>\n",
       "      <td>0.271145</td>\n",
       "      <td>0.195531</td>\n",
       "      <td>0.262811</td>\n",
       "      <td>0.308864</td>\n",
       "      <td>0.379743</td>\n",
       "      <td>0.263345</td>\n",
       "      <td>0.217624</td>\n",
       "      <td>0.251623</td>\n",
       "      <td>0.272728</td>\n",
       "      <td>0.321540</td>\n",
       "      <td>0.358869</td>\n",
       "      <td>0.277360</td>\n",
       "      <td>0.265544</td>\n",
       "      <td>0.277809</td>\n",
       "      <td>0.289896</td>\n",
       "      <td>0.320668</td>\n",
       "      <td>0.323520</td>\n",
       "      <td>0.282735</td>\n",
       "      <td>0.239620</td>\n",
       "      <td>0.207744</td>\n",
       "      <td>0.372803</td>\n",
       "      <td>0.330268</td>\n",
       "      <td>0.286602</td>\n",
       "      <td>0.276973</td>\n",
       "      <td>0.357234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247632</td>\n",
       "      <td>0.189511</td>\n",
       "      <td>0.294154</td>\n",
       "      <td>0.279754</td>\n",
       "      <td>0.259953</td>\n",
       "      <td>0.328689</td>\n",
       "      <td>0.277413</td>\n",
       "      <td>0.231324</td>\n",
       "      <td>0.182667</td>\n",
       "      <td>0.155974</td>\n",
       "      <td>0.161146</td>\n",
       "      <td>0.141840</td>\n",
       "      <td>0.202451</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>0.245930</td>\n",
       "      <td>0.217812</td>\n",
       "      <td>0.306169</td>\n",
       "      <td>0.109960</td>\n",
       "      <td>0.157142</td>\n",
       "      <td>0.217545</td>\n",
       "      <td>0.298609</td>\n",
       "      <td>0.235861</td>\n",
       "      <td>0.213686</td>\n",
       "      <td>-0.018245</td>\n",
       "      <td>0.252988</td>\n",
       "      <td>0.157969</td>\n",
       "      <td>0.216606</td>\n",
       "      <td>0.195708</td>\n",
       "      <td>0.240630</td>\n",
       "      <td>0.348939</td>\n",
       "      <td>0.056084</td>\n",
       "      <td>0.097883</td>\n",
       "      <td>0.206605</td>\n",
       "      <td>0.235600</td>\n",
       "      <td>0.209253</td>\n",
       "      <td>0.224642</td>\n",
       "      <td>0.185036</td>\n",
       "      <td>0.172388</td>\n",
       "      <td>0.227713</td>\n",
       "      <td>0.277210</td>\n",
       "      <td>0.271938</td>\n",
       "      <td>0.247293</td>\n",
       "      <td>0.216092</td>\n",
       "      <td>0.222373</td>\n",
       "      <td>0.274162</td>\n",
       "      <td>0.357947</td>\n",
       "      <td>0.220470</td>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.174281</td>\n",
       "      <td>0.243080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058523</td>\n",
       "      <td>0.162405</td>\n",
       "      <td>0.191868</td>\n",
       "      <td>0.113815</td>\n",
       "      <td>0.079654</td>\n",
       "      <td>0.211740</td>\n",
       "      <td>0.237915</td>\n",
       "      <td>0.120882</td>\n",
       "      <td>0.070739</td>\n",
       "      <td>-0.026516</td>\n",
       "      <td>0.046043</td>\n",
       "      <td>-0.003559</td>\n",
       "      <td>0.183392</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.175308</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.110757</td>\n",
       "      <td>0.064913</td>\n",
       "      <td>0.144177</td>\n",
       "      <td>0.068862</td>\n",
       "      <td>0.083351</td>\n",
       "      <td>0.177589</td>\n",
       "      <td>0.206479</td>\n",
       "      <td>-0.025643</td>\n",
       "      <td>0.194804</td>\n",
       "      <td>0.088915</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.031859</td>\n",
       "      <td>0.095810</td>\n",
       "      <td>0.289610</td>\n",
       "      <td>-0.013152</td>\n",
       "      <td>0.126501</td>\n",
       "      <td>0.128803</td>\n",
       "      <td>0.042756</td>\n",
       "      <td>0.161213</td>\n",
       "      <td>0.113067</td>\n",
       "      <td>0.073122</td>\n",
       "      <td>0.063851</td>\n",
       "      <td>0.079764</td>\n",
       "      <td>0.139080</td>\n",
       "      <td>0.208870</td>\n",
       "      <td>0.161428</td>\n",
       "      <td>0.112787</td>\n",
       "      <td>0.222864</td>\n",
       "      <td>0.035919</td>\n",
       "      <td>0.247249</td>\n",
       "      <td>0.021399</td>\n",
       "      <td>0.147159</td>\n",
       "      <td>0.100773</td>\n",
       "      <td>0.243362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073664</td>\n",
       "      <td>0.114170</td>\n",
       "      <td>0.218529</td>\n",
       "      <td>0.122037</td>\n",
       "      <td>0.143496</td>\n",
       "      <td>0.203789</td>\n",
       "      <td>0.309487</td>\n",
       "      <td>0.211944</td>\n",
       "      <td>0.085880</td>\n",
       "      <td>0.067252</td>\n",
       "      <td>0.065528</td>\n",
       "      <td>-0.017248</td>\n",
       "      <td>0.367542</td>\n",
       "      <td>0.099089</td>\n",
       "      <td>0.249496</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>0.128803</td>\n",
       "      <td>0.048902</td>\n",
       "      <td>0.216848</td>\n",
       "      <td>0.147681</td>\n",
       "      <td>0.112468</td>\n",
       "      <td>0.089752</td>\n",
       "      <td>0.166870</td>\n",
       "      <td>0.102114</td>\n",
       "      <td>0.103849</td>\n",
       "      <td>0.102405</td>\n",
       "      <td>0.152297</td>\n",
       "      <td>0.159705</td>\n",
       "      <td>0.167432</td>\n",
       "      <td>0.318652</td>\n",
       "      <td>0.080127</td>\n",
       "      <td>0.071383</td>\n",
       "      <td>0.054716</td>\n",
       "      <td>0.096657</td>\n",
       "      <td>0.195862</td>\n",
       "      <td>0.159630</td>\n",
       "      <td>0.051918</td>\n",
       "      <td>0.190569</td>\n",
       "      <td>0.156976</td>\n",
       "      <td>0.109007</td>\n",
       "      <td>0.352991</td>\n",
       "      <td>0.217857</td>\n",
       "      <td>0.109674</td>\n",
       "      <td>0.337363</td>\n",
       "      <td>0.136518</td>\n",
       "      <td>0.228692</td>\n",
       "      <td>0.079239</td>\n",
       "      <td>0.150963</td>\n",
       "      <td>0.194843</td>\n",
       "      <td>0.241494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015711</td>\n",
       "      <td>0.143272</td>\n",
       "      <td>0.137247</td>\n",
       "      <td>0.073499</td>\n",
       "      <td>0.076554</td>\n",
       "      <td>0.222898</td>\n",
       "      <td>0.284347</td>\n",
       "      <td>0.205669</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>0.067326</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>-0.021081</td>\n",
       "      <td>0.268664</td>\n",
       "      <td>0.075927</td>\n",
       "      <td>0.209668</td>\n",
       "      <td>-0.019635</td>\n",
       "      <td>0.114066</td>\n",
       "      <td>0.098024</td>\n",
       "      <td>0.184648</td>\n",
       "      <td>0.107594</td>\n",
       "      <td>0.083285</td>\n",
       "      <td>0.102307</td>\n",
       "      <td>0.142782</td>\n",
       "      <td>0.119033</td>\n",
       "      <td>0.125184</td>\n",
       "      <td>0.156690</td>\n",
       "      <td>0.207526</td>\n",
       "      <td>0.041764</td>\n",
       "      <td>0.139821</td>\n",
       "      <td>0.289175</td>\n",
       "      <td>0.106451</td>\n",
       "      <td>0.087394</td>\n",
       "      <td>0.075093</td>\n",
       "      <td>0.117162</td>\n",
       "      <td>0.169748</td>\n",
       "      <td>0.141135</td>\n",
       "      <td>-0.084092</td>\n",
       "      <td>0.101683</td>\n",
       "      <td>0.089265</td>\n",
       "      <td>0.112456</td>\n",
       "      <td>0.365963</td>\n",
       "      <td>0.126538</td>\n",
       "      <td>0.122090</td>\n",
       "      <td>0.276541</td>\n",
       "      <td>0.191310</td>\n",
       "      <td>0.177421</td>\n",
       "      <td>0.020299</td>\n",
       "      <td>0.030568</td>\n",
       "      <td>0.199866</td>\n",
       "      <td>0.235520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.079742</td>\n",
       "      <td>0.095236</td>\n",
       "      <td>-0.003763</td>\n",
       "      <td>-0.057279</td>\n",
       "      <td>-0.029884</td>\n",
       "      <td>0.083431</td>\n",
       "      <td>0.074889</td>\n",
       "      <td>0.124714</td>\n",
       "      <td>-0.068619</td>\n",
       "      <td>-0.067247</td>\n",
       "      <td>-0.100649</td>\n",
       "      <td>-0.155613</td>\n",
       "      <td>0.209775</td>\n",
       "      <td>-0.088601</td>\n",
       "      <td>0.112394</td>\n",
       "      <td>-0.070185</td>\n",
       "      <td>0.026698</td>\n",
       "      <td>-0.073622</td>\n",
       "      <td>0.109167</td>\n",
       "      <td>-0.038995</td>\n",
       "      <td>-0.073830</td>\n",
       "      <td>-0.020948</td>\n",
       "      <td>-0.025234</td>\n",
       "      <td>0.115233</td>\n",
       "      <td>-0.028842</td>\n",
       "      <td>0.092637</td>\n",
       "      <td>0.161262</td>\n",
       "      <td>-0.086275</td>\n",
       "      <td>-0.019982</td>\n",
       "      <td>0.164529</td>\n",
       "      <td>0.088248</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.068365</td>\n",
       "      <td>0.021097</td>\n",
       "      <td>-0.109810</td>\n",
       "      <td>-0.032682</td>\n",
       "      <td>0.045321</td>\n",
       "      <td>0.140841</td>\n",
       "      <td>0.269546</td>\n",
       "      <td>0.064223</td>\n",
       "      <td>-0.035656</td>\n",
       "      <td>0.246404</td>\n",
       "      <td>0.032535</td>\n",
       "      <td>0.044332</td>\n",
       "      <td>-0.124832</td>\n",
       "      <td>0.029706</td>\n",
       "      <td>-0.002131</td>\n",
       "      <td>0.141588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.069322</td>\n",
       "      <td>0.097980</td>\n",
       "      <td>0.084701</td>\n",
       "      <td>0.126759</td>\n",
       "      <td>0.068219</td>\n",
       "      <td>0.272452</td>\n",
       "      <td>0.165449</td>\n",
       "      <td>0.233261</td>\n",
       "      <td>0.105181</td>\n",
       "      <td>0.057028</td>\n",
       "      <td>0.031725</td>\n",
       "      <td>-0.016970</td>\n",
       "      <td>0.298982</td>\n",
       "      <td>0.036071</td>\n",
       "      <td>0.240418</td>\n",
       "      <td>-0.019781</td>\n",
       "      <td>0.095429</td>\n",
       "      <td>0.190542</td>\n",
       "      <td>0.131572</td>\n",
       "      <td>0.130716</td>\n",
       "      <td>0.047422</td>\n",
       "      <td>0.148510</td>\n",
       "      <td>0.115993</td>\n",
       "      <td>0.127789</td>\n",
       "      <td>0.106464</td>\n",
       "      <td>0.146827</td>\n",
       "      <td>0.224910</td>\n",
       "      <td>0.060305</td>\n",
       "      <td>0.047767</td>\n",
       "      <td>0.278523</td>\n",
       "      <td>0.236458</td>\n",
       "      <td>0.070263</td>\n",
       "      <td>0.122270</td>\n",
       "      <td>0.117528</td>\n",
       "      <td>0.154738</td>\n",
       "      <td>0.185960</td>\n",
       "      <td>-0.097929</td>\n",
       "      <td>0.077106</td>\n",
       "      <td>0.292083</td>\n",
       "      <td>0.353519</td>\n",
       "      <td>0.369430</td>\n",
       "      <td>0.189685</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>0.318495</td>\n",
       "      <td>0.101868</td>\n",
       "      <td>0.226494</td>\n",
       "      <td>0.062536</td>\n",
       "      <td>0.286916</td>\n",
       "      <td>0.078775</td>\n",
       "      <td>0.296743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.152635</td>\n",
       "      <td>0.029626</td>\n",
       "      <td>-0.015289</td>\n",
       "      <td>0.061833</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>0.263355</td>\n",
       "      <td>0.214671</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>-0.003504</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.056222</td>\n",
       "      <td>-0.075485</td>\n",
       "      <td>0.204089</td>\n",
       "      <td>-0.045828</td>\n",
       "      <td>0.235217</td>\n",
       "      <td>-0.048512</td>\n",
       "      <td>0.218550</td>\n",
       "      <td>0.180063</td>\n",
       "      <td>-0.109804</td>\n",
       "      <td>-0.045635</td>\n",
       "      <td>0.072894</td>\n",
       "      <td>0.137141</td>\n",
       "      <td>0.136315</td>\n",
       "      <td>0.086111</td>\n",
       "      <td>0.035894</td>\n",
       "      <td>0.150088</td>\n",
       "      <td>0.101508</td>\n",
       "      <td>0.067199</td>\n",
       "      <td>0.093556</td>\n",
       "      <td>0.156266</td>\n",
       "      <td>0.139910</td>\n",
       "      <td>-0.016109</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>0.019016</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>0.188593</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>0.038524</td>\n",
       "      <td>0.062262</td>\n",
       "      <td>0.363722</td>\n",
       "      <td>0.312214</td>\n",
       "      <td>0.128012</td>\n",
       "      <td>-0.007997</td>\n",
       "      <td>0.350361</td>\n",
       "      <td>0.012420</td>\n",
       "      <td>0.187150</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>0.268333</td>\n",
       "      <td>0.119426</td>\n",
       "      <td>0.245892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.395712</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>-0.208092</td>\n",
       "      <td>-0.267113</td>\n",
       "      <td>-0.269032</td>\n",
       "      <td>0.043462</td>\n",
       "      <td>-0.124646</td>\n",
       "      <td>-0.154744</td>\n",
       "      <td>-0.218230</td>\n",
       "      <td>-0.178641</td>\n",
       "      <td>-0.157338</td>\n",
       "      <td>-0.319617</td>\n",
       "      <td>0.130286</td>\n",
       "      <td>-0.246706</td>\n",
       "      <td>-0.116321</td>\n",
       "      <td>-0.413040</td>\n",
       "      <td>-0.039938</td>\n",
       "      <td>-0.097018</td>\n",
       "      <td>-0.173248</td>\n",
       "      <td>-0.292369</td>\n",
       "      <td>-0.137237</td>\n",
       "      <td>-0.236763</td>\n",
       "      <td>-0.041914</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>-0.204750</td>\n",
       "      <td>0.089817</td>\n",
       "      <td>-0.247513</td>\n",
       "      <td>-0.133512</td>\n",
       "      <td>-0.195840</td>\n",
       "      <td>0.089234</td>\n",
       "      <td>0.130273</td>\n",
       "      <td>-0.220309</td>\n",
       "      <td>-0.072417</td>\n",
       "      <td>-0.061472</td>\n",
       "      <td>-0.106618</td>\n",
       "      <td>-0.135268</td>\n",
       "      <td>-0.073102</td>\n",
       "      <td>-0.241012</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>0.349697</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>-0.076554</td>\n",
       "      <td>-0.148497</td>\n",
       "      <td>0.251708</td>\n",
       "      <td>-0.096017</td>\n",
       "      <td>-0.002080</td>\n",
       "      <td>-0.008839</td>\n",
       "      <td>0.105078</td>\n",
       "      <td>-0.099958</td>\n",
       "      <td>0.046074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.326336</td>\n",
       "      <td>-0.082070</td>\n",
       "      <td>-0.081708</td>\n",
       "      <td>-0.162793</td>\n",
       "      <td>-0.216118</td>\n",
       "      <td>0.296902</td>\n",
       "      <td>0.130639</td>\n",
       "      <td>-0.123317</td>\n",
       "      <td>-0.129727</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>-0.080409</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>-0.014780</td>\n",
       "      <td>0.229470</td>\n",
       "      <td>-0.309483</td>\n",
       "      <td>0.079347</td>\n",
       "      <td>0.020901</td>\n",
       "      <td>0.080169</td>\n",
       "      <td>-0.286900</td>\n",
       "      <td>-0.109094</td>\n",
       "      <td>-0.130708</td>\n",
       "      <td>0.149289</td>\n",
       "      <td>0.199875</td>\n",
       "      <td>-0.080769</td>\n",
       "      <td>0.157991</td>\n",
       "      <td>0.132997</td>\n",
       "      <td>-0.194768</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.211394</td>\n",
       "      <td>0.082543</td>\n",
       "      <td>0.031185</td>\n",
       "      <td>0.093658</td>\n",
       "      <td>0.134398</td>\n",
       "      <td>0.186392</td>\n",
       "      <td>-0.003937</td>\n",
       "      <td>-0.026910</td>\n",
       "      <td>-0.026312</td>\n",
       "      <td>0.214065</td>\n",
       "      <td>0.358064</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.215607</td>\n",
       "      <td>0.166750</td>\n",
       "      <td>0.509753</td>\n",
       "      <td>0.021276</td>\n",
       "      <td>0.151219</td>\n",
       "      <td>0.138169</td>\n",
       "      <td>0.274923</td>\n",
       "      <td>0.211489</td>\n",
       "      <td>0.190111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.361904</td>\n",
       "      <td>-0.167232</td>\n",
       "      <td>-0.468011</td>\n",
       "      <td>-0.217991</td>\n",
       "      <td>-0.204485</td>\n",
       "      <td>0.255593</td>\n",
       "      <td>-0.040046</td>\n",
       "      <td>-0.024514</td>\n",
       "      <td>-0.297009</td>\n",
       "      <td>0.145356</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>-0.007344</td>\n",
       "      <td>0.257123</td>\n",
       "      <td>-0.260728</td>\n",
       "      <td>0.236208</td>\n",
       "      <td>-0.342761</td>\n",
       "      <td>-0.106322</td>\n",
       "      <td>-0.185359</td>\n",
       "      <td>-0.014785</td>\n",
       "      <td>-0.614176</td>\n",
       "      <td>-0.077744</td>\n",
       "      <td>-0.217088</td>\n",
       "      <td>-0.014837</td>\n",
       "      <td>0.180212</td>\n",
       "      <td>-0.238953</td>\n",
       "      <td>-0.022820</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>-0.321828</td>\n",
       "      <td>0.059648</td>\n",
       "      <td>0.160644</td>\n",
       "      <td>0.212175</td>\n",
       "      <td>0.030965</td>\n",
       "      <td>0.077540</td>\n",
       "      <td>-0.059546</td>\n",
       "      <td>0.131257</td>\n",
       "      <td>-0.012506</td>\n",
       "      <td>-0.065761</td>\n",
       "      <td>-0.105310</td>\n",
       "      <td>0.224070</td>\n",
       "      <td>0.413903</td>\n",
       "      <td>0.204807</td>\n",
       "      <td>0.146606</td>\n",
       "      <td>0.195828</td>\n",
       "      <td>0.543502</td>\n",
       "      <td>-0.065858</td>\n",
       "      <td>-0.042332</td>\n",
       "      <td>-0.016582</td>\n",
       "      <td>0.137951</td>\n",
       "      <td>0.072579</td>\n",
       "      <td>0.110238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.473304</td>\n",
       "      <td>-0.547676</td>\n",
       "      <td>-0.623182</td>\n",
       "      <td>-0.312157</td>\n",
       "      <td>-0.296103</td>\n",
       "      <td>0.016107</td>\n",
       "      <td>-0.322330</td>\n",
       "      <td>-0.305331</td>\n",
       "      <td>-0.561365</td>\n",
       "      <td>-0.251529</td>\n",
       "      <td>-0.364605</td>\n",
       "      <td>-0.255505</td>\n",
       "      <td>-0.065601</td>\n",
       "      <td>-0.565420</td>\n",
       "      <td>0.174470</td>\n",
       "      <td>-0.482054</td>\n",
       "      <td>-0.420815</td>\n",
       "      <td>-0.408419</td>\n",
       "      <td>-0.408951</td>\n",
       "      <td>-0.730861</td>\n",
       "      <td>-0.222490</td>\n",
       "      <td>-0.295325</td>\n",
       "      <td>-0.201226</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>-0.375870</td>\n",
       "      <td>-0.294305</td>\n",
       "      <td>-0.102914</td>\n",
       "      <td>-0.415590</td>\n",
       "      <td>-0.274121</td>\n",
       "      <td>-0.084977</td>\n",
       "      <td>-0.069345</td>\n",
       "      <td>-0.142698</td>\n",
       "      <td>-0.273367</td>\n",
       "      <td>-0.102407</td>\n",
       "      <td>-0.178602</td>\n",
       "      <td>-0.193331</td>\n",
       "      <td>-0.401381</td>\n",
       "      <td>-0.060041</td>\n",
       "      <td>-0.036428</td>\n",
       "      <td>0.101469</td>\n",
       "      <td>0.173273</td>\n",
       "      <td>-0.283664</td>\n",
       "      <td>-0.088006</td>\n",
       "      <td>0.130056</td>\n",
       "      <td>-0.350578</td>\n",
       "      <td>-0.484415</td>\n",
       "      <td>-0.329986</td>\n",
       "      <td>0.235003</td>\n",
       "      <td>-0.114855</td>\n",
       "      <td>-0.167627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.312686</td>\n",
       "      <td>-0.537834</td>\n",
       "      <td>-0.675650</td>\n",
       "      <td>-0.145455</td>\n",
       "      <td>-0.420748</td>\n",
       "      <td>0.035508</td>\n",
       "      <td>-0.333433</td>\n",
       "      <td>-0.377377</td>\n",
       "      <td>-0.649795</td>\n",
       "      <td>-0.272984</td>\n",
       "      <td>-0.304594</td>\n",
       "      <td>-0.334070</td>\n",
       "      <td>-0.315408</td>\n",
       "      <td>-0.858876</td>\n",
       "      <td>-0.038033</td>\n",
       "      <td>-0.720228</td>\n",
       "      <td>-0.163709</td>\n",
       "      <td>-0.411480</td>\n",
       "      <td>-0.663141</td>\n",
       "      <td>-0.856824</td>\n",
       "      <td>-0.120436</td>\n",
       "      <td>-0.241743</td>\n",
       "      <td>-0.274898</td>\n",
       "      <td>0.054365</td>\n",
       "      <td>-0.439969</td>\n",
       "      <td>-0.249143</td>\n",
       "      <td>-0.365627</td>\n",
       "      <td>-0.325716</td>\n",
       "      <td>-0.481110</td>\n",
       "      <td>0.031201</td>\n",
       "      <td>0.114467</td>\n",
       "      <td>-0.240774</td>\n",
       "      <td>-0.359459</td>\n",
       "      <td>-0.227468</td>\n",
       "      <td>-0.297503</td>\n",
       "      <td>-0.325283</td>\n",
       "      <td>-0.396153</td>\n",
       "      <td>-0.190282</td>\n",
       "      <td>-0.115896</td>\n",
       "      <td>-0.071274</td>\n",
       "      <td>0.028402</td>\n",
       "      <td>-0.253241</td>\n",
       "      <td>-0.123871</td>\n",
       "      <td>-0.097177</td>\n",
       "      <td>-0.509481</td>\n",
       "      <td>-0.543864</td>\n",
       "      <td>-0.299990</td>\n",
       "      <td>-0.071562</td>\n",
       "      <td>-0.217935</td>\n",
       "      <td>-0.069784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.354687</td>\n",
       "      <td>-0.540751</td>\n",
       "      <td>-0.865755</td>\n",
       "      <td>-0.391292</td>\n",
       "      <td>-0.747320</td>\n",
       "      <td>-0.128471</td>\n",
       "      <td>-0.333748</td>\n",
       "      <td>-0.462422</td>\n",
       "      <td>-0.801041</td>\n",
       "      <td>-0.303570</td>\n",
       "      <td>-0.222938</td>\n",
       "      <td>-0.246239</td>\n",
       "      <td>-0.356380</td>\n",
       "      <td>-0.690930</td>\n",
       "      <td>-0.166254</td>\n",
       "      <td>-0.983501</td>\n",
       "      <td>-0.284073</td>\n",
       "      <td>-0.355618</td>\n",
       "      <td>-0.990834</td>\n",
       "      <td>-0.736393</td>\n",
       "      <td>-0.302266</td>\n",
       "      <td>-0.573248</td>\n",
       "      <td>-0.329084</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>-0.751161</td>\n",
       "      <td>-0.379354</td>\n",
       "      <td>-0.507032</td>\n",
       "      <td>-0.380995</td>\n",
       "      <td>-0.611857</td>\n",
       "      <td>0.073608</td>\n",
       "      <td>-0.172680</td>\n",
       "      <td>-0.486497</td>\n",
       "      <td>-0.200909</td>\n",
       "      <td>-0.272332</td>\n",
       "      <td>-0.555172</td>\n",
       "      <td>-0.434007</td>\n",
       "      <td>-0.404185</td>\n",
       "      <td>-0.270488</td>\n",
       "      <td>-0.142555</td>\n",
       "      <td>-0.226011</td>\n",
       "      <td>-0.058979</td>\n",
       "      <td>-0.459488</td>\n",
       "      <td>-0.310817</td>\n",
       "      <td>0.052909</td>\n",
       "      <td>-0.368690</td>\n",
       "      <td>-0.709470</td>\n",
       "      <td>-0.441586</td>\n",
       "      <td>-0.086878</td>\n",
       "      <td>-0.312617</td>\n",
       "      <td>-0.176702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.638777</td>\n",
       "      <td>-0.353745</td>\n",
       "      <td>-0.966301</td>\n",
       "      <td>-0.402861</td>\n",
       "      <td>-0.947130</td>\n",
       "      <td>-0.435667</td>\n",
       "      <td>-0.076658</td>\n",
       "      <td>-0.497688</td>\n",
       "      <td>-1.072940</td>\n",
       "      <td>-0.369848</td>\n",
       "      <td>-0.210237</td>\n",
       "      <td>-0.210895</td>\n",
       "      <td>-0.483279</td>\n",
       "      <td>-0.844235</td>\n",
       "      <td>-0.343883</td>\n",
       "      <td>-1.133619</td>\n",
       "      <td>-0.292958</td>\n",
       "      <td>-0.308613</td>\n",
       "      <td>-0.750303</td>\n",
       "      <td>-0.815577</td>\n",
       "      <td>-0.376557</td>\n",
       "      <td>-0.562630</td>\n",
       "      <td>-0.311164</td>\n",
       "      <td>0.014953</td>\n",
       "      <td>-0.860834</td>\n",
       "      <td>-0.118722</td>\n",
       "      <td>-0.281836</td>\n",
       "      <td>-0.580791</td>\n",
       "      <td>-0.720648</td>\n",
       "      <td>-0.182303</td>\n",
       "      <td>-0.255371</td>\n",
       "      <td>-0.535371</td>\n",
       "      <td>-0.208387</td>\n",
       "      <td>-0.470044</td>\n",
       "      <td>-0.516519</td>\n",
       "      <td>-0.599964</td>\n",
       "      <td>-0.445595</td>\n",
       "      <td>-0.605811</td>\n",
       "      <td>-0.300207</td>\n",
       "      <td>-0.387447</td>\n",
       "      <td>-0.232115</td>\n",
       "      <td>-0.531548</td>\n",
       "      <td>-0.353836</td>\n",
       "      <td>-0.008093</td>\n",
       "      <td>-0.726058</td>\n",
       "      <td>-0.704853</td>\n",
       "      <td>-0.477034</td>\n",
       "      <td>-0.309188</td>\n",
       "      <td>-0.395085</td>\n",
       "      <td>-0.387250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.419912</td>\n",
       "      <td>-0.375699</td>\n",
       "      <td>-0.656453</td>\n",
       "      <td>-0.633559</td>\n",
       "      <td>-0.807960</td>\n",
       "      <td>-0.096499</td>\n",
       "      <td>-0.082185</td>\n",
       "      <td>-0.187428</td>\n",
       "      <td>-0.997987</td>\n",
       "      <td>-0.241157</td>\n",
       "      <td>-0.284238</td>\n",
       "      <td>-0.128679</td>\n",
       "      <td>-0.086361</td>\n",
       "      <td>-0.526763</td>\n",
       "      <td>-0.171466</td>\n",
       "      <td>-0.842419</td>\n",
       "      <td>-0.347031</td>\n",
       "      <td>-0.197935</td>\n",
       "      <td>-0.443031</td>\n",
       "      <td>-0.530300</td>\n",
       "      <td>-0.257730</td>\n",
       "      <td>-0.384252</td>\n",
       "      <td>-0.280217</td>\n",
       "      <td>0.075741</td>\n",
       "      <td>-0.723302</td>\n",
       "      <td>0.026294</td>\n",
       "      <td>-0.327641</td>\n",
       "      <td>-0.237731</td>\n",
       "      <td>-0.487260</td>\n",
       "      <td>-0.173630</td>\n",
       "      <td>-0.266871</td>\n",
       "      <td>-0.451418</td>\n",
       "      <td>-0.278086</td>\n",
       "      <td>-0.361810</td>\n",
       "      <td>-0.341219</td>\n",
       "      <td>-0.391964</td>\n",
       "      <td>-0.353001</td>\n",
       "      <td>-0.266106</td>\n",
       "      <td>-0.051790</td>\n",
       "      <td>-0.080152</td>\n",
       "      <td>0.097663</td>\n",
       "      <td>-0.665680</td>\n",
       "      <td>-0.040810</td>\n",
       "      <td>0.176289</td>\n",
       "      <td>-0.474043</td>\n",
       "      <td>-0.539643</td>\n",
       "      <td>-0.621413</td>\n",
       "      <td>-0.076252</td>\n",
       "      <td>-0.205322</td>\n",
       "      <td>-0.397105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.445354</td>\n",
       "      <td>-0.495739</td>\n",
       "      <td>-0.685296</td>\n",
       "      <td>-0.486845</td>\n",
       "      <td>-0.864911</td>\n",
       "      <td>-0.033199</td>\n",
       "      <td>0.038888</td>\n",
       "      <td>-0.186348</td>\n",
       "      <td>-1.060373</td>\n",
       "      <td>-0.179427</td>\n",
       "      <td>-0.126552</td>\n",
       "      <td>-0.146691</td>\n",
       "      <td>-0.405920</td>\n",
       "      <td>-0.595306</td>\n",
       "      <td>-0.069270</td>\n",
       "      <td>-0.777290</td>\n",
       "      <td>-0.425913</td>\n",
       "      <td>-0.428001</td>\n",
       "      <td>-0.645835</td>\n",
       "      <td>-0.755365</td>\n",
       "      <td>-0.063607</td>\n",
       "      <td>-0.322219</td>\n",
       "      <td>-0.451009</td>\n",
       "      <td>0.157744</td>\n",
       "      <td>-0.426568</td>\n",
       "      <td>0.027712</td>\n",
       "      <td>-0.194782</td>\n",
       "      <td>-0.202735</td>\n",
       "      <td>-0.338154</td>\n",
       "      <td>-0.270107</td>\n",
       "      <td>-0.238484</td>\n",
       "      <td>-0.340429</td>\n",
       "      <td>-0.283157</td>\n",
       "      <td>-0.202123</td>\n",
       "      <td>-0.298893</td>\n",
       "      <td>-0.296774</td>\n",
       "      <td>-0.444393</td>\n",
       "      <td>-0.434338</td>\n",
       "      <td>-0.157869</td>\n",
       "      <td>-0.092879</td>\n",
       "      <td>-0.077929</td>\n",
       "      <td>-0.573161</td>\n",
       "      <td>0.291723</td>\n",
       "      <td>0.217401</td>\n",
       "      <td>-0.670375</td>\n",
       "      <td>-0.382362</td>\n",
       "      <td>-0.412916</td>\n",
       "      <td>-0.274443</td>\n",
       "      <td>0.078820</td>\n",
       "      <td>-0.317417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.477452</td>\n",
       "      <td>-0.466505</td>\n",
       "      <td>-0.794798</td>\n",
       "      <td>-0.552558</td>\n",
       "      <td>-1.153417</td>\n",
       "      <td>-0.276803</td>\n",
       "      <td>-0.082676</td>\n",
       "      <td>-0.210985</td>\n",
       "      <td>-1.190040</td>\n",
       "      <td>-0.096890</td>\n",
       "      <td>-0.373259</td>\n",
       "      <td>-0.304887</td>\n",
       "      <td>-0.226744</td>\n",
       "      <td>-0.853855</td>\n",
       "      <td>-0.177248</td>\n",
       "      <td>-0.637043</td>\n",
       "      <td>-0.469824</td>\n",
       "      <td>-0.588503</td>\n",
       "      <td>-0.726256</td>\n",
       "      <td>-0.941813</td>\n",
       "      <td>-0.302522</td>\n",
       "      <td>-0.559103</td>\n",
       "      <td>-0.461226</td>\n",
       "      <td>0.322271</td>\n",
       "      <td>-0.515065</td>\n",
       "      <td>-0.118187</td>\n",
       "      <td>-0.428195</td>\n",
       "      <td>-0.373750</td>\n",
       "      <td>-0.600341</td>\n",
       "      <td>-0.205353</td>\n",
       "      <td>-0.101212</td>\n",
       "      <td>-0.379254</td>\n",
       "      <td>-0.440199</td>\n",
       "      <td>-0.595475</td>\n",
       "      <td>-0.531208</td>\n",
       "      <td>-0.610333</td>\n",
       "      <td>-0.342577</td>\n",
       "      <td>-0.398561</td>\n",
       "      <td>-0.178419</td>\n",
       "      <td>-0.277926</td>\n",
       "      <td>-0.230459</td>\n",
       "      <td>-0.648294</td>\n",
       "      <td>0.226803</td>\n",
       "      <td>0.108789</td>\n",
       "      <td>-0.834684</td>\n",
       "      <td>-0.583402</td>\n",
       "      <td>-0.502980</td>\n",
       "      <td>-0.272357</td>\n",
       "      <td>0.025125</td>\n",
       "      <td>-0.376921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.099147</td>\n",
       "      <td>-0.576819</td>\n",
       "      <td>-0.717625</td>\n",
       "      <td>-0.122438</td>\n",
       "      <td>-0.789810</td>\n",
       "      <td>-0.291432</td>\n",
       "      <td>0.216458</td>\n",
       "      <td>0.074015</td>\n",
       "      <td>-0.919503</td>\n",
       "      <td>0.254655</td>\n",
       "      <td>-0.253172</td>\n",
       "      <td>-0.001306</td>\n",
       "      <td>-0.023094</td>\n",
       "      <td>-0.325656</td>\n",
       "      <td>0.103543</td>\n",
       "      <td>-0.322369</td>\n",
       "      <td>-0.223730</td>\n",
       "      <td>-0.171729</td>\n",
       "      <td>-0.437926</td>\n",
       "      <td>-0.595665</td>\n",
       "      <td>-0.161409</td>\n",
       "      <td>-0.312172</td>\n",
       "      <td>-0.166559</td>\n",
       "      <td>0.300614</td>\n",
       "      <td>-0.404764</td>\n",
       "      <td>0.187709</td>\n",
       "      <td>-0.096079</td>\n",
       "      <td>-0.203769</td>\n",
       "      <td>-0.619645</td>\n",
       "      <td>0.117189</td>\n",
       "      <td>0.262083</td>\n",
       "      <td>-0.273097</td>\n",
       "      <td>0.050328</td>\n",
       "      <td>-0.023427</td>\n",
       "      <td>-0.274098</td>\n",
       "      <td>-0.450924</td>\n",
       "      <td>-0.399095</td>\n",
       "      <td>0.054326</td>\n",
       "      <td>0.201704</td>\n",
       "      <td>-0.105383</td>\n",
       "      <td>-0.024619</td>\n",
       "      <td>-0.056391</td>\n",
       "      <td>0.222617</td>\n",
       "      <td>0.395175</td>\n",
       "      <td>-0.448804</td>\n",
       "      <td>-0.087718</td>\n",
       "      <td>-0.119534</td>\n",
       "      <td>-0.152898</td>\n",
       "      <td>0.213055</td>\n",
       "      <td>-0.123759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.113152</td>\n",
       "      <td>-0.570533</td>\n",
       "      <td>-0.702088</td>\n",
       "      <td>0.043746</td>\n",
       "      <td>-0.570542</td>\n",
       "      <td>-0.259183</td>\n",
       "      <td>0.219803</td>\n",
       "      <td>-0.130700</td>\n",
       "      <td>-0.957726</td>\n",
       "      <td>0.135747</td>\n",
       "      <td>0.177071</td>\n",
       "      <td>-0.170973</td>\n",
       "      <td>0.213725</td>\n",
       "      <td>-0.356890</td>\n",
       "      <td>0.153675</td>\n",
       "      <td>-0.252570</td>\n",
       "      <td>-0.119382</td>\n",
       "      <td>-0.089626</td>\n",
       "      <td>-0.306704</td>\n",
       "      <td>-0.627201</td>\n",
       "      <td>-0.212944</td>\n",
       "      <td>-0.320686</td>\n",
       "      <td>-0.108504</td>\n",
       "      <td>0.279748</td>\n",
       "      <td>-0.324380</td>\n",
       "      <td>0.218616</td>\n",
       "      <td>-0.193110</td>\n",
       "      <td>-0.212544</td>\n",
       "      <td>-0.574532</td>\n",
       "      <td>0.149585</td>\n",
       "      <td>0.173695</td>\n",
       "      <td>-0.091008</td>\n",
       "      <td>0.101715</td>\n",
       "      <td>0.068913</td>\n",
       "      <td>-0.428288</td>\n",
       "      <td>-0.371383</td>\n",
       "      <td>-0.292584</td>\n",
       "      <td>0.177370</td>\n",
       "      <td>-0.064540</td>\n",
       "      <td>-0.053942</td>\n",
       "      <td>0.148540</td>\n",
       "      <td>0.157017</td>\n",
       "      <td>0.454961</td>\n",
       "      <td>0.588418</td>\n",
       "      <td>-0.061545</td>\n",
       "      <td>-0.003374</td>\n",
       "      <td>-0.299626</td>\n",
       "      <td>-0.020425</td>\n",
       "      <td>0.331586</td>\n",
       "      <td>-0.060002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.323203</td>\n",
       "      <td>-0.590595</td>\n",
       "      <td>-0.789562</td>\n",
       "      <td>-0.072279</td>\n",
       "      <td>-0.616411</td>\n",
       "      <td>-0.414006</td>\n",
       "      <td>0.023212</td>\n",
       "      <td>-0.111910</td>\n",
       "      <td>-1.019267</td>\n",
       "      <td>-0.126561</td>\n",
       "      <td>-0.032537</td>\n",
       "      <td>-0.243629</td>\n",
       "      <td>-0.163071</td>\n",
       "      <td>-0.638171</td>\n",
       "      <td>-0.353071</td>\n",
       "      <td>-0.378975</td>\n",
       "      <td>-0.424863</td>\n",
       "      <td>-0.495467</td>\n",
       "      <td>-0.465294</td>\n",
       "      <td>-0.668326</td>\n",
       "      <td>-0.240808</td>\n",
       "      <td>-0.517083</td>\n",
       "      <td>-0.406692</td>\n",
       "      <td>0.300411</td>\n",
       "      <td>-0.400089</td>\n",
       "      <td>0.284891</td>\n",
       "      <td>-0.342362</td>\n",
       "      <td>-0.137779</td>\n",
       "      <td>-0.631191</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>-0.128003</td>\n",
       "      <td>-0.198710</td>\n",
       "      <td>-0.075384</td>\n",
       "      <td>-0.097648</td>\n",
       "      <td>-0.485263</td>\n",
       "      <td>-0.595111</td>\n",
       "      <td>-0.496723</td>\n",
       "      <td>-0.175718</td>\n",
       "      <td>-0.196086</td>\n",
       "      <td>-0.286914</td>\n",
       "      <td>-0.280693</td>\n",
       "      <td>-0.206552</td>\n",
       "      <td>0.168341</td>\n",
       "      <td>0.322726</td>\n",
       "      <td>-0.382836</td>\n",
       "      <td>-0.223809</td>\n",
       "      <td>-0.277988</td>\n",
       "      <td>-0.253766</td>\n",
       "      <td>0.118273</td>\n",
       "      <td>-0.277574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.058303</td>\n",
       "      <td>-0.365979</td>\n",
       "      <td>-0.565663</td>\n",
       "      <td>-0.171717</td>\n",
       "      <td>-0.551598</td>\n",
       "      <td>-0.357620</td>\n",
       "      <td>0.158941</td>\n",
       "      <td>-0.046497</td>\n",
       "      <td>-0.871112</td>\n",
       "      <td>-0.069697</td>\n",
       "      <td>-0.035745</td>\n",
       "      <td>-0.186854</td>\n",
       "      <td>-0.162032</td>\n",
       "      <td>-0.582020</td>\n",
       "      <td>-0.278005</td>\n",
       "      <td>-0.478323</td>\n",
       "      <td>-0.104313</td>\n",
       "      <td>-0.691665</td>\n",
       "      <td>-0.394297</td>\n",
       "      <td>-0.400157</td>\n",
       "      <td>-0.277395</td>\n",
       "      <td>-0.482791</td>\n",
       "      <td>-0.234716</td>\n",
       "      <td>0.437736</td>\n",
       "      <td>-0.392082</td>\n",
       "      <td>0.333748</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>-0.213267</td>\n",
       "      <td>-0.470527</td>\n",
       "      <td>0.175283</td>\n",
       "      <td>-0.056798</td>\n",
       "      <td>-0.176943</td>\n",
       "      <td>-0.061528</td>\n",
       "      <td>0.102082</td>\n",
       "      <td>-0.266714</td>\n",
       "      <td>-0.437182</td>\n",
       "      <td>-0.441155</td>\n",
       "      <td>0.038610</td>\n",
       "      <td>-0.220798</td>\n",
       "      <td>-0.257072</td>\n",
       "      <td>-0.039743</td>\n",
       "      <td>-0.244916</td>\n",
       "      <td>0.378590</td>\n",
       "      <td>0.383700</td>\n",
       "      <td>-0.270207</td>\n",
       "      <td>-0.151587</td>\n",
       "      <td>-0.066642</td>\n",
       "      <td>-0.143735</td>\n",
       "      <td>0.087526</td>\n",
       "      <td>-0.339020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.233204</td>\n",
       "      <td>-0.297721</td>\n",
       "      <td>-0.627629</td>\n",
       "      <td>-0.059300</td>\n",
       "      <td>-0.644264</td>\n",
       "      <td>-0.272925</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>-0.180071</td>\n",
       "      <td>-1.150598</td>\n",
       "      <td>-0.018256</td>\n",
       "      <td>0.022773</td>\n",
       "      <td>0.027153</td>\n",
       "      <td>-0.318072</td>\n",
       "      <td>-0.439517</td>\n",
       "      <td>-0.372117</td>\n",
       "      <td>-0.473702</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>-0.797097</td>\n",
       "      <td>-0.545798</td>\n",
       "      <td>-0.516350</td>\n",
       "      <td>-0.337099</td>\n",
       "      <td>-0.475602</td>\n",
       "      <td>-0.416355</td>\n",
       "      <td>0.360659</td>\n",
       "      <td>-0.462535</td>\n",
       "      <td>0.052153</td>\n",
       "      <td>-0.416984</td>\n",
       "      <td>-0.334816</td>\n",
       "      <td>-0.329536</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>-0.269844</td>\n",
       "      <td>-0.163587</td>\n",
       "      <td>-0.029979</td>\n",
       "      <td>0.040993</td>\n",
       "      <td>-0.375129</td>\n",
       "      <td>-0.314224</td>\n",
       "      <td>-0.626615</td>\n",
       "      <td>-0.143426</td>\n",
       "      <td>-0.306423</td>\n",
       "      <td>-0.355609</td>\n",
       "      <td>-0.396656</td>\n",
       "      <td>-0.330061</td>\n",
       "      <td>0.317393</td>\n",
       "      <td>0.289593</td>\n",
       "      <td>-0.304699</td>\n",
       "      <td>-0.357932</td>\n",
       "      <td>-0.115106</td>\n",
       "      <td>-0.355575</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>-0.408648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.248857</td>\n",
       "      <td>-0.334185</td>\n",
       "      <td>-0.747993</td>\n",
       "      <td>-0.204458</td>\n",
       "      <td>-0.855434</td>\n",
       "      <td>-0.523904</td>\n",
       "      <td>-0.171296</td>\n",
       "      <td>-0.327118</td>\n",
       "      <td>-1.180107</td>\n",
       "      <td>-0.160041</td>\n",
       "      <td>-0.218263</td>\n",
       "      <td>-0.144482</td>\n",
       "      <td>-0.426617</td>\n",
       "      <td>-0.559686</td>\n",
       "      <td>-0.447109</td>\n",
       "      <td>-0.594312</td>\n",
       "      <td>-0.235571</td>\n",
       "      <td>-0.895917</td>\n",
       "      <td>-0.656339</td>\n",
       "      <td>-0.716629</td>\n",
       "      <td>-0.485110</td>\n",
       "      <td>-0.635559</td>\n",
       "      <td>-0.491881</td>\n",
       "      <td>0.184162</td>\n",
       "      <td>-0.572735</td>\n",
       "      <td>0.037157</td>\n",
       "      <td>-0.510533</td>\n",
       "      <td>-0.449865</td>\n",
       "      <td>-0.608093</td>\n",
       "      <td>-0.166079</td>\n",
       "      <td>-0.326907</td>\n",
       "      <td>-0.185370</td>\n",
       "      <td>-0.182775</td>\n",
       "      <td>-0.076523</td>\n",
       "      <td>-0.526778</td>\n",
       "      <td>-0.355133</td>\n",
       "      <td>-0.621783</td>\n",
       "      <td>-0.255630</td>\n",
       "      <td>-0.442908</td>\n",
       "      <td>-0.226397</td>\n",
       "      <td>-0.431213</td>\n",
       "      <td>-0.524664</td>\n",
       "      <td>0.064248</td>\n",
       "      <td>0.085154</td>\n",
       "      <td>-0.579398</td>\n",
       "      <td>-0.410483</td>\n",
       "      <td>-0.208944</td>\n",
       "      <td>-0.376097</td>\n",
       "      <td>-0.177956</td>\n",
       "      <td>-0.342394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.093952</td>\n",
       "      <td>-0.401348</td>\n",
       "      <td>-0.511480</td>\n",
       "      <td>-0.199117</td>\n",
       "      <td>-0.584999</td>\n",
       "      <td>-0.375725</td>\n",
       "      <td>0.094324</td>\n",
       "      <td>-0.161325</td>\n",
       "      <td>-1.064787</td>\n",
       "      <td>0.045012</td>\n",
       "      <td>-0.191031</td>\n",
       "      <td>-0.092878</td>\n",
       "      <td>-0.176216</td>\n",
       "      <td>-0.513977</td>\n",
       "      <td>-0.293423</td>\n",
       "      <td>-0.346215</td>\n",
       "      <td>-0.014445</td>\n",
       "      <td>-0.622958</td>\n",
       "      <td>-0.440341</td>\n",
       "      <td>-0.525846</td>\n",
       "      <td>-0.356794</td>\n",
       "      <td>-0.271588</td>\n",
       "      <td>-0.439465</td>\n",
       "      <td>0.365313</td>\n",
       "      <td>-0.400121</td>\n",
       "      <td>0.067378</td>\n",
       "      <td>-0.269158</td>\n",
       "      <td>-0.284778</td>\n",
       "      <td>-0.410558</td>\n",
       "      <td>0.063769</td>\n",
       "      <td>-0.072416</td>\n",
       "      <td>0.034866</td>\n",
       "      <td>-0.090505</td>\n",
       "      <td>0.114643</td>\n",
       "      <td>-0.267714</td>\n",
       "      <td>-0.185482</td>\n",
       "      <td>-0.490071</td>\n",
       "      <td>-0.078362</td>\n",
       "      <td>-0.286852</td>\n",
       "      <td>-0.099757</td>\n",
       "      <td>-0.205380</td>\n",
       "      <td>-0.372149</td>\n",
       "      <td>0.236946</td>\n",
       "      <td>0.259790</td>\n",
       "      <td>-0.374144</td>\n",
       "      <td>-0.172638</td>\n",
       "      <td>-0.112593</td>\n",
       "      <td>-0.197375</td>\n",
       "      <td>-0.113204</td>\n",
       "      <td>-0.248433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.119947</td>\n",
       "      <td>-0.343754</td>\n",
       "      <td>-0.617669</td>\n",
       "      <td>-0.138506</td>\n",
       "      <td>-0.511433</td>\n",
       "      <td>-0.202593</td>\n",
       "      <td>0.107486</td>\n",
       "      <td>-0.171895</td>\n",
       "      <td>-1.014368</td>\n",
       "      <td>0.124855</td>\n",
       "      <td>-0.160450</td>\n",
       "      <td>0.062563</td>\n",
       "      <td>-0.292424</td>\n",
       "      <td>-0.393284</td>\n",
       "      <td>-0.177934</td>\n",
       "      <td>-0.272332</td>\n",
       "      <td>-0.035252</td>\n",
       "      <td>-0.598175</td>\n",
       "      <td>-0.553891</td>\n",
       "      <td>-0.457386</td>\n",
       "      <td>-0.368328</td>\n",
       "      <td>-0.211248</td>\n",
       "      <td>-0.378510</td>\n",
       "      <td>0.194517</td>\n",
       "      <td>-0.389961</td>\n",
       "      <td>0.073132</td>\n",
       "      <td>-0.380239</td>\n",
       "      <td>-0.211511</td>\n",
       "      <td>-0.230605</td>\n",
       "      <td>0.121126</td>\n",
       "      <td>-0.010859</td>\n",
       "      <td>0.152335</td>\n",
       "      <td>-0.037542</td>\n",
       "      <td>0.258103</td>\n",
       "      <td>-0.234436</td>\n",
       "      <td>-0.119028</td>\n",
       "      <td>-0.467909</td>\n",
       "      <td>0.050196</td>\n",
       "      <td>-0.364634</td>\n",
       "      <td>-0.152790</td>\n",
       "      <td>-0.299874</td>\n",
       "      <td>-0.381079</td>\n",
       "      <td>0.325032</td>\n",
       "      <td>0.431922</td>\n",
       "      <td>-0.262184</td>\n",
       "      <td>-0.155832</td>\n",
       "      <td>-0.047852</td>\n",
       "      <td>-0.276972</td>\n",
       "      <td>-0.042246</td>\n",
       "      <td>-0.118993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.093150</td>\n",
       "      <td>-0.254877</td>\n",
       "      <td>-0.698188</td>\n",
       "      <td>-0.242192</td>\n",
       "      <td>-0.745568</td>\n",
       "      <td>-0.416388</td>\n",
       "      <td>-0.118242</td>\n",
       "      <td>-0.371322</td>\n",
       "      <td>-1.072381</td>\n",
       "      <td>-0.072901</td>\n",
       "      <td>-0.139292</td>\n",
       "      <td>-0.097723</td>\n",
       "      <td>-0.316012</td>\n",
       "      <td>-0.572853</td>\n",
       "      <td>-0.295231</td>\n",
       "      <td>-0.412721</td>\n",
       "      <td>-0.215055</td>\n",
       "      <td>-0.793909</td>\n",
       "      <td>-0.579305</td>\n",
       "      <td>-0.632328</td>\n",
       "      <td>-0.460615</td>\n",
       "      <td>-0.342051</td>\n",
       "      <td>-0.481747</td>\n",
       "      <td>0.309348</td>\n",
       "      <td>-0.583552</td>\n",
       "      <td>0.133725</td>\n",
       "      <td>-0.410639</td>\n",
       "      <td>-0.403472</td>\n",
       "      <td>-0.400104</td>\n",
       "      <td>0.100304</td>\n",
       "      <td>-0.203570</td>\n",
       "      <td>0.069070</td>\n",
       "      <td>-0.040113</td>\n",
       "      <td>0.152169</td>\n",
       "      <td>-0.208915</td>\n",
       "      <td>-0.189361</td>\n",
       "      <td>-0.549816</td>\n",
       "      <td>-0.216873</td>\n",
       "      <td>-0.539123</td>\n",
       "      <td>-0.266901</td>\n",
       "      <td>-0.309148</td>\n",
       "      <td>-0.355715</td>\n",
       "      <td>0.232469</td>\n",
       "      <td>0.278947</td>\n",
       "      <td>-0.522542</td>\n",
       "      <td>-0.287117</td>\n",
       "      <td>-0.053359</td>\n",
       "      <td>-0.184592</td>\n",
       "      <td>-0.037816</td>\n",
       "      <td>-0.183753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.221684</td>\n",
       "      <td>-0.257151</td>\n",
       "      <td>-0.443545</td>\n",
       "      <td>-0.128777</td>\n",
       "      <td>-0.491406</td>\n",
       "      <td>-0.125168</td>\n",
       "      <td>0.064521</td>\n",
       "      <td>-0.006716</td>\n",
       "      <td>-0.813251</td>\n",
       "      <td>0.133657</td>\n",
       "      <td>-0.062038</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>-0.054493</td>\n",
       "      <td>-0.433926</td>\n",
       "      <td>-0.125769</td>\n",
       "      <td>-0.230832</td>\n",
       "      <td>0.065305</td>\n",
       "      <td>-0.527434</td>\n",
       "      <td>-0.307529</td>\n",
       "      <td>-0.409877</td>\n",
       "      <td>-0.134882</td>\n",
       "      <td>0.041973</td>\n",
       "      <td>-0.270358</td>\n",
       "      <td>0.376254</td>\n",
       "      <td>-0.275744</td>\n",
       "      <td>0.049864</td>\n",
       "      <td>-0.079302</td>\n",
       "      <td>-0.104733</td>\n",
       "      <td>-0.114602</td>\n",
       "      <td>0.329796</td>\n",
       "      <td>-0.076823</td>\n",
       "      <td>0.351718</td>\n",
       "      <td>0.100807</td>\n",
       "      <td>0.397383</td>\n",
       "      <td>-0.154493</td>\n",
       "      <td>-0.010883</td>\n",
       "      <td>-0.352991</td>\n",
       "      <td>0.067412</td>\n",
       "      <td>-0.219556</td>\n",
       "      <td>-0.112376</td>\n",
       "      <td>0.038722</td>\n",
       "      <td>-0.346731</td>\n",
       "      <td>0.511480</td>\n",
       "      <td>0.180097</td>\n",
       "      <td>-0.207570</td>\n",
       "      <td>-0.050917</td>\n",
       "      <td>0.049245</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.057573</td>\n",
       "      <td>-0.105378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.299479</td>\n",
       "      <td>-0.025881</td>\n",
       "      <td>-0.414921</td>\n",
       "      <td>-0.269469</td>\n",
       "      <td>-0.372970</td>\n",
       "      <td>-0.043432</td>\n",
       "      <td>0.087166</td>\n",
       "      <td>-0.049431</td>\n",
       "      <td>-0.703887</td>\n",
       "      <td>0.325597</td>\n",
       "      <td>-0.099760</td>\n",
       "      <td>-0.073830</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>-0.421843</td>\n",
       "      <td>0.219003</td>\n",
       "      <td>-0.138713</td>\n",
       "      <td>0.086654</td>\n",
       "      <td>-0.404976</td>\n",
       "      <td>-0.290044</td>\n",
       "      <td>-0.367531</td>\n",
       "      <td>0.021847</td>\n",
       "      <td>0.038738</td>\n",
       "      <td>-0.159562</td>\n",
       "      <td>0.177280</td>\n",
       "      <td>-0.349064</td>\n",
       "      <td>0.046150</td>\n",
       "      <td>-0.359076</td>\n",
       "      <td>-0.205058</td>\n",
       "      <td>-0.024535</td>\n",
       "      <td>0.313252</td>\n",
       "      <td>0.062871</td>\n",
       "      <td>0.492148</td>\n",
       "      <td>0.201741</td>\n",
       "      <td>0.454150</td>\n",
       "      <td>0.032517</td>\n",
       "      <td>0.211554</td>\n",
       "      <td>-0.120089</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>-0.304272</td>\n",
       "      <td>-0.003808</td>\n",
       "      <td>0.311292</td>\n",
       "      <td>-0.244720</td>\n",
       "      <td>0.345253</td>\n",
       "      <td>0.214391</td>\n",
       "      <td>0.094602</td>\n",
       "      <td>-0.077869</td>\n",
       "      <td>-0.082630</td>\n",
       "      <td>0.073468</td>\n",
       "      <td>-0.121854</td>\n",
       "      <td>-0.016229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.241191</td>\n",
       "      <td>-0.068831</td>\n",
       "      <td>-0.495555</td>\n",
       "      <td>-0.026650</td>\n",
       "      <td>-0.295675</td>\n",
       "      <td>0.079657</td>\n",
       "      <td>0.054626</td>\n",
       "      <td>-0.161373</td>\n",
       "      <td>-0.696140</td>\n",
       "      <td>0.219122</td>\n",
       "      <td>-0.056401</td>\n",
       "      <td>-0.263356</td>\n",
       "      <td>0.026452</td>\n",
       "      <td>-0.397401</td>\n",
       "      <td>0.020473</td>\n",
       "      <td>0.034212</td>\n",
       "      <td>-0.062282</td>\n",
       "      <td>-0.446012</td>\n",
       "      <td>-0.305546</td>\n",
       "      <td>-0.249090</td>\n",
       "      <td>-0.096218</td>\n",
       "      <td>0.028639</td>\n",
       "      <td>-0.112747</td>\n",
       "      <td>0.338608</td>\n",
       "      <td>-0.258084</td>\n",
       "      <td>0.142223</td>\n",
       "      <td>-0.300052</td>\n",
       "      <td>-0.147134</td>\n",
       "      <td>-0.078189</td>\n",
       "      <td>0.386397</td>\n",
       "      <td>-0.179665</td>\n",
       "      <td>0.456874</td>\n",
       "      <td>0.386352</td>\n",
       "      <td>0.384758</td>\n",
       "      <td>0.179822</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>-0.151383</td>\n",
       "      <td>0.097019</td>\n",
       "      <td>-0.286963</td>\n",
       "      <td>-0.120168</td>\n",
       "      <td>0.165053</td>\n",
       "      <td>-0.185007</td>\n",
       "      <td>0.519966</td>\n",
       "      <td>0.321931</td>\n",
       "      <td>-0.138413</td>\n",
       "      <td>-0.137511</td>\n",
       "      <td>-0.066904</td>\n",
       "      <td>0.235733</td>\n",
       "      <td>0.049317</td>\n",
       "      <td>-0.015027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.337732</td>\n",
       "      <td>0.084558</td>\n",
       "      <td>-0.149958</td>\n",
       "      <td>0.033765</td>\n",
       "      <td>-0.202761</td>\n",
       "      <td>0.176888</td>\n",
       "      <td>0.261455</td>\n",
       "      <td>0.092872</td>\n",
       "      <td>-0.556546</td>\n",
       "      <td>0.236991</td>\n",
       "      <td>0.031084</td>\n",
       "      <td>-0.117949</td>\n",
       "      <td>0.158459</td>\n",
       "      <td>-0.367730</td>\n",
       "      <td>0.280027</td>\n",
       "      <td>0.154771</td>\n",
       "      <td>0.147339</td>\n",
       "      <td>-0.205356</td>\n",
       "      <td>-0.036759</td>\n",
       "      <td>-0.047753</td>\n",
       "      <td>0.135499</td>\n",
       "      <td>0.211213</td>\n",
       "      <td>-0.117822</td>\n",
       "      <td>0.309307</td>\n",
       "      <td>-0.158914</td>\n",
       "      <td>0.248157</td>\n",
       "      <td>-0.169085</td>\n",
       "      <td>0.019538</td>\n",
       "      <td>0.049786</td>\n",
       "      <td>0.410954</td>\n",
       "      <td>-0.060121</td>\n",
       "      <td>0.365966</td>\n",
       "      <td>0.426923</td>\n",
       "      <td>0.283083</td>\n",
       "      <td>0.209684</td>\n",
       "      <td>0.135950</td>\n",
       "      <td>-0.002342</td>\n",
       "      <td>0.318931</td>\n",
       "      <td>-0.043615</td>\n",
       "      <td>-0.047313</td>\n",
       "      <td>0.205492</td>\n",
       "      <td>-0.107308</td>\n",
       "      <td>0.526907</td>\n",
       "      <td>0.405029</td>\n",
       "      <td>0.055953</td>\n",
       "      <td>0.136046</td>\n",
       "      <td>0.169276</td>\n",
       "      <td>0.259972</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>0.173399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.283355</td>\n",
       "      <td>0.128282</td>\n",
       "      <td>-0.241447</td>\n",
       "      <td>0.024655</td>\n",
       "      <td>-0.064947</td>\n",
       "      <td>0.091273</td>\n",
       "      <td>0.101926</td>\n",
       "      <td>0.166767</td>\n",
       "      <td>-0.354895</td>\n",
       "      <td>0.267401</td>\n",
       "      <td>0.015954</td>\n",
       "      <td>-0.302673</td>\n",
       "      <td>0.213345</td>\n",
       "      <td>-0.174456</td>\n",
       "      <td>0.348848</td>\n",
       "      <td>0.228108</td>\n",
       "      <td>0.150428</td>\n",
       "      <td>-0.063813</td>\n",
       "      <td>-0.043208</td>\n",
       "      <td>-0.084307</td>\n",
       "      <td>0.184320</td>\n",
       "      <td>0.174617</td>\n",
       "      <td>0.036116</td>\n",
       "      <td>0.260319</td>\n",
       "      <td>-0.157878</td>\n",
       "      <td>0.197778</td>\n",
       "      <td>-0.154091</td>\n",
       "      <td>-0.130581</td>\n",
       "      <td>-0.024947</td>\n",
       "      <td>0.365287</td>\n",
       "      <td>0.221679</td>\n",
       "      <td>0.642724</td>\n",
       "      <td>0.372438</td>\n",
       "      <td>0.349408</td>\n",
       "      <td>0.397217</td>\n",
       "      <td>0.343638</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>0.465856</td>\n",
       "      <td>-0.053840</td>\n",
       "      <td>0.080165</td>\n",
       "      <td>0.348362</td>\n",
       "      <td>-0.158535</td>\n",
       "      <td>0.505134</td>\n",
       "      <td>0.492937</td>\n",
       "      <td>0.066431</td>\n",
       "      <td>0.105676</td>\n",
       "      <td>0.155362</td>\n",
       "      <td>0.285251</td>\n",
       "      <td>0.209752</td>\n",
       "      <td>0.269499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.185705</td>\n",
       "      <td>0.067191</td>\n",
       "      <td>-0.260612</td>\n",
       "      <td>0.084107</td>\n",
       "      <td>-0.014142</td>\n",
       "      <td>0.211832</td>\n",
       "      <td>0.269871</td>\n",
       "      <td>0.050864</td>\n",
       "      <td>-0.424314</td>\n",
       "      <td>0.395322</td>\n",
       "      <td>0.062009</td>\n",
       "      <td>-0.118675</td>\n",
       "      <td>0.177033</td>\n",
       "      <td>-0.160424</td>\n",
       "      <td>0.226826</td>\n",
       "      <td>0.290298</td>\n",
       "      <td>0.105610</td>\n",
       "      <td>-0.205263</td>\n",
       "      <td>0.020716</td>\n",
       "      <td>0.161832</td>\n",
       "      <td>0.118702</td>\n",
       "      <td>0.225087</td>\n",
       "      <td>0.056401</td>\n",
       "      <td>0.306708</td>\n",
       "      <td>-0.082354</td>\n",
       "      <td>0.293728</td>\n",
       "      <td>-0.113810</td>\n",
       "      <td>-0.036196</td>\n",
       "      <td>0.157970</td>\n",
       "      <td>0.380963</td>\n",
       "      <td>0.143721</td>\n",
       "      <td>0.584024</td>\n",
       "      <td>0.420571</td>\n",
       "      <td>0.373094</td>\n",
       "      <td>0.484658</td>\n",
       "      <td>0.305217</td>\n",
       "      <td>0.052367</td>\n",
       "      <td>0.314115</td>\n",
       "      <td>-0.157641</td>\n",
       "      <td>0.102845</td>\n",
       "      <td>0.227820</td>\n",
       "      <td>0.084413</td>\n",
       "      <td>0.605071</td>\n",
       "      <td>0.520939</td>\n",
       "      <td>0.138616</td>\n",
       "      <td>0.062120</td>\n",
       "      <td>0.193460</td>\n",
       "      <td>0.148404</td>\n",
       "      <td>0.200188</td>\n",
       "      <td>0.147639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.092207</td>\n",
       "      <td>0.069459</td>\n",
       "      <td>-0.158306</td>\n",
       "      <td>-0.021449</td>\n",
       "      <td>-0.121075</td>\n",
       "      <td>0.099605</td>\n",
       "      <td>0.024841</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>-0.441962</td>\n",
       "      <td>0.175487</td>\n",
       "      <td>0.083897</td>\n",
       "      <td>-0.169306</td>\n",
       "      <td>0.100601</td>\n",
       "      <td>-0.324354</td>\n",
       "      <td>0.162320</td>\n",
       "      <td>0.100761</td>\n",
       "      <td>-0.087295</td>\n",
       "      <td>-0.064072</td>\n",
       "      <td>-0.090819</td>\n",
       "      <td>0.076418</td>\n",
       "      <td>-0.035717</td>\n",
       "      <td>0.179373</td>\n",
       "      <td>-0.110134</td>\n",
       "      <td>0.165194</td>\n",
       "      <td>-0.106065</td>\n",
       "      <td>0.279456</td>\n",
       "      <td>-0.130768</td>\n",
       "      <td>-0.109952</td>\n",
       "      <td>0.066434</td>\n",
       "      <td>0.279491</td>\n",
       "      <td>-0.023118</td>\n",
       "      <td>0.459728</td>\n",
       "      <td>0.269724</td>\n",
       "      <td>0.107173</td>\n",
       "      <td>0.289330</td>\n",
       "      <td>0.347107</td>\n",
       "      <td>0.128389</td>\n",
       "      <td>0.210550</td>\n",
       "      <td>-0.184585</td>\n",
       "      <td>-0.189992</td>\n",
       "      <td>0.227775</td>\n",
       "      <td>-0.033463</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.061004</td>\n",
       "      <td>0.091690</td>\n",
       "      <td>0.134124</td>\n",
       "      <td>0.176470</td>\n",
       "      <td>0.035072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.239682</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>-0.186858</td>\n",
       "      <td>-0.033404</td>\n",
       "      <td>0.096997</td>\n",
       "      <td>0.189631</td>\n",
       "      <td>0.271441</td>\n",
       "      <td>0.159305</td>\n",
       "      <td>-0.266150</td>\n",
       "      <td>0.213640</td>\n",
       "      <td>0.239561</td>\n",
       "      <td>-0.150573</td>\n",
       "      <td>0.144969</td>\n",
       "      <td>-0.259650</td>\n",
       "      <td>0.315856</td>\n",
       "      <td>0.123701</td>\n",
       "      <td>0.057455</td>\n",
       "      <td>0.064231</td>\n",
       "      <td>-0.033810</td>\n",
       "      <td>0.200677</td>\n",
       "      <td>0.147455</td>\n",
       "      <td>0.287473</td>\n",
       "      <td>0.090814</td>\n",
       "      <td>0.266477</td>\n",
       "      <td>-0.035396</td>\n",
       "      <td>0.255170</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.122286</td>\n",
       "      <td>0.220513</td>\n",
       "      <td>0.430611</td>\n",
       "      <td>0.244335</td>\n",
       "      <td>0.514055</td>\n",
       "      <td>0.314248</td>\n",
       "      <td>0.217314</td>\n",
       "      <td>0.328544</td>\n",
       "      <td>0.410128</td>\n",
       "      <td>0.350625</td>\n",
       "      <td>0.259685</td>\n",
       "      <td>-0.004973</td>\n",
       "      <td>0.118126</td>\n",
       "      <td>0.366862</td>\n",
       "      <td>-0.066923</td>\n",
       "      <td>0.613744</td>\n",
       "      <td>0.541150</td>\n",
       "      <td>0.124177</td>\n",
       "      <td>0.055244</td>\n",
       "      <td>0.095457</td>\n",
       "      <td>0.195924</td>\n",
       "      <td>0.226630</td>\n",
       "      <td>0.096350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.212452</td>\n",
       "      <td>0.028994</td>\n",
       "      <td>-0.008484</td>\n",
       "      <td>-0.006845</td>\n",
       "      <td>0.262018</td>\n",
       "      <td>0.184854</td>\n",
       "      <td>0.271847</td>\n",
       "      <td>0.115913</td>\n",
       "      <td>-0.060793</td>\n",
       "      <td>0.135884</td>\n",
       "      <td>0.207226</td>\n",
       "      <td>0.109689</td>\n",
       "      <td>0.233840</td>\n",
       "      <td>-0.102682</td>\n",
       "      <td>0.375502</td>\n",
       "      <td>0.177606</td>\n",
       "      <td>0.029015</td>\n",
       "      <td>0.120448</td>\n",
       "      <td>0.145122</td>\n",
       "      <td>0.242722</td>\n",
       "      <td>0.246002</td>\n",
       "      <td>0.424176</td>\n",
       "      <td>0.046147</td>\n",
       "      <td>0.081957</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>0.298345</td>\n",
       "      <td>0.024984</td>\n",
       "      <td>0.058484</td>\n",
       "      <td>0.231664</td>\n",
       "      <td>0.394620</td>\n",
       "      <td>0.211846</td>\n",
       "      <td>0.597202</td>\n",
       "      <td>0.415737</td>\n",
       "      <td>0.308853</td>\n",
       "      <td>0.460203</td>\n",
       "      <td>0.457386</td>\n",
       "      <td>0.340760</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>-0.088053</td>\n",
       "      <td>0.213479</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>-0.015575</td>\n",
       "      <td>0.525821</td>\n",
       "      <td>0.441318</td>\n",
       "      <td>0.308818</td>\n",
       "      <td>0.059176</td>\n",
       "      <td>0.147086</td>\n",
       "      <td>0.274574</td>\n",
       "      <td>0.239855</td>\n",
       "      <td>0.042991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.272077</td>\n",
       "      <td>0.183770</td>\n",
       "      <td>0.115216</td>\n",
       "      <td>-0.052327</td>\n",
       "      <td>0.244866</td>\n",
       "      <td>0.318728</td>\n",
       "      <td>0.198468</td>\n",
       "      <td>0.195519</td>\n",
       "      <td>-0.027727</td>\n",
       "      <td>0.067549</td>\n",
       "      <td>0.240249</td>\n",
       "      <td>0.141516</td>\n",
       "      <td>0.235544</td>\n",
       "      <td>-0.037572</td>\n",
       "      <td>0.383390</td>\n",
       "      <td>0.262143</td>\n",
       "      <td>-0.142080</td>\n",
       "      <td>0.186038</td>\n",
       "      <td>0.118690</td>\n",
       "      <td>0.210716</td>\n",
       "      <td>0.314643</td>\n",
       "      <td>0.355979</td>\n",
       "      <td>0.047739</td>\n",
       "      <td>-0.069619</td>\n",
       "      <td>-0.014972</td>\n",
       "      <td>0.323072</td>\n",
       "      <td>-0.062918</td>\n",
       "      <td>-0.005171</td>\n",
       "      <td>0.247076</td>\n",
       "      <td>0.510946</td>\n",
       "      <td>0.096031</td>\n",
       "      <td>0.568160</td>\n",
       "      <td>0.372044</td>\n",
       "      <td>0.362033</td>\n",
       "      <td>0.496261</td>\n",
       "      <td>0.441086</td>\n",
       "      <td>0.264223</td>\n",
       "      <td>0.335482</td>\n",
       "      <td>-0.098146</td>\n",
       "      <td>0.261060</td>\n",
       "      <td>0.412097</td>\n",
       "      <td>0.073054</td>\n",
       "      <td>0.515420</td>\n",
       "      <td>0.357288</td>\n",
       "      <td>0.373923</td>\n",
       "      <td>0.135309</td>\n",
       "      <td>0.162839</td>\n",
       "      <td>0.215694</td>\n",
       "      <td>0.388545</td>\n",
       "      <td>0.213212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.229940</td>\n",
       "      <td>0.153350</td>\n",
       "      <td>0.073676</td>\n",
       "      <td>-0.001591</td>\n",
       "      <td>0.236449</td>\n",
       "      <td>0.388763</td>\n",
       "      <td>0.264150</td>\n",
       "      <td>0.168034</td>\n",
       "      <td>0.041388</td>\n",
       "      <td>0.038507</td>\n",
       "      <td>0.192907</td>\n",
       "      <td>0.160682</td>\n",
       "      <td>0.272291</td>\n",
       "      <td>0.056607</td>\n",
       "      <td>0.484368</td>\n",
       "      <td>0.229158</td>\n",
       "      <td>-0.075726</td>\n",
       "      <td>0.280287</td>\n",
       "      <td>0.128606</td>\n",
       "      <td>0.253850</td>\n",
       "      <td>0.367582</td>\n",
       "      <td>0.430337</td>\n",
       "      <td>0.064957</td>\n",
       "      <td>-0.005062</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>0.157286</td>\n",
       "      <td>-0.035941</td>\n",
       "      <td>0.103056</td>\n",
       "      <td>0.289299</td>\n",
       "      <td>0.392317</td>\n",
       "      <td>0.124410</td>\n",
       "      <td>0.744387</td>\n",
       "      <td>0.338966</td>\n",
       "      <td>0.456089</td>\n",
       "      <td>0.419231</td>\n",
       "      <td>0.340379</td>\n",
       "      <td>0.319811</td>\n",
       "      <td>0.364292</td>\n",
       "      <td>0.040145</td>\n",
       "      <td>0.305408</td>\n",
       "      <td>0.414928</td>\n",
       "      <td>0.038359</td>\n",
       "      <td>0.591661</td>\n",
       "      <td>0.291189</td>\n",
       "      <td>0.182949</td>\n",
       "      <td>0.156419</td>\n",
       "      <td>0.155681</td>\n",
       "      <td>0.331382</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.191701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.208968</td>\n",
       "      <td>0.086676</td>\n",
       "      <td>0.047656</td>\n",
       "      <td>-0.046397</td>\n",
       "      <td>0.260369</td>\n",
       "      <td>0.265992</td>\n",
       "      <td>0.313851</td>\n",
       "      <td>0.304539</td>\n",
       "      <td>0.066747</td>\n",
       "      <td>0.144210</td>\n",
       "      <td>0.134072</td>\n",
       "      <td>0.224165</td>\n",
       "      <td>0.336483</td>\n",
       "      <td>0.103389</td>\n",
       "      <td>0.506623</td>\n",
       "      <td>0.260113</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.383385</td>\n",
       "      <td>0.112884</td>\n",
       "      <td>0.304894</td>\n",
       "      <td>0.462505</td>\n",
       "      <td>0.409074</td>\n",
       "      <td>0.148424</td>\n",
       "      <td>0.019833</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.237264</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>0.259076</td>\n",
       "      <td>0.253604</td>\n",
       "      <td>0.460769</td>\n",
       "      <td>0.163713</td>\n",
       "      <td>0.615613</td>\n",
       "      <td>0.394064</td>\n",
       "      <td>0.452450</td>\n",
       "      <td>0.361065</td>\n",
       "      <td>0.451790</td>\n",
       "      <td>0.289278</td>\n",
       "      <td>0.190578</td>\n",
       "      <td>0.097270</td>\n",
       "      <td>0.321604</td>\n",
       "      <td>0.452046</td>\n",
       "      <td>0.145693</td>\n",
       "      <td>0.459985</td>\n",
       "      <td>0.302819</td>\n",
       "      <td>0.323507</td>\n",
       "      <td>0.111646</td>\n",
       "      <td>0.133428</td>\n",
       "      <td>0.202715</td>\n",
       "      <td>0.295044</td>\n",
       "      <td>0.254788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.237435</td>\n",
       "      <td>0.055339</td>\n",
       "      <td>-0.011992</td>\n",
       "      <td>-0.042440</td>\n",
       "      <td>0.232035</td>\n",
       "      <td>0.223379</td>\n",
       "      <td>0.266863</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.039996</td>\n",
       "      <td>0.094997</td>\n",
       "      <td>0.162328</td>\n",
       "      <td>0.137864</td>\n",
       "      <td>0.216822</td>\n",
       "      <td>0.017387</td>\n",
       "      <td>0.417009</td>\n",
       "      <td>0.304360</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>0.358203</td>\n",
       "      <td>0.129994</td>\n",
       "      <td>0.214830</td>\n",
       "      <td>0.415176</td>\n",
       "      <td>0.341164</td>\n",
       "      <td>0.040399</td>\n",
       "      <td>0.026388</td>\n",
       "      <td>-0.069507</td>\n",
       "      <td>0.255928</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>0.216605</td>\n",
       "      <td>0.148489</td>\n",
       "      <td>0.447625</td>\n",
       "      <td>0.137347</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.269037</td>\n",
       "      <td>0.484370</td>\n",
       "      <td>0.251957</td>\n",
       "      <td>0.421395</td>\n",
       "      <td>0.208098</td>\n",
       "      <td>0.134623</td>\n",
       "      <td>0.026831</td>\n",
       "      <td>0.316499</td>\n",
       "      <td>0.336899</td>\n",
       "      <td>0.132352</td>\n",
       "      <td>0.452461</td>\n",
       "      <td>0.357539</td>\n",
       "      <td>0.219454</td>\n",
       "      <td>0.098929</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.239592</td>\n",
       "      <td>0.317615</td>\n",
       "      <td>0.233233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.244132</td>\n",
       "      <td>0.017398</td>\n",
       "      <td>-0.009038</td>\n",
       "      <td>-0.108043</td>\n",
       "      <td>0.150473</td>\n",
       "      <td>0.271137</td>\n",
       "      <td>0.275452</td>\n",
       "      <td>0.188434</td>\n",
       "      <td>0.141179</td>\n",
       "      <td>0.053046</td>\n",
       "      <td>0.147330</td>\n",
       "      <td>0.170623</td>\n",
       "      <td>0.248383</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.492197</td>\n",
       "      <td>0.245277</td>\n",
       "      <td>0.105691</td>\n",
       "      <td>0.370964</td>\n",
       "      <td>0.133152</td>\n",
       "      <td>0.187532</td>\n",
       "      <td>0.442611</td>\n",
       "      <td>0.322607</td>\n",
       "      <td>0.067965</td>\n",
       "      <td>0.032642</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>0.158856</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.263993</td>\n",
       "      <td>0.105154</td>\n",
       "      <td>0.480220</td>\n",
       "      <td>0.232260</td>\n",
       "      <td>0.538695</td>\n",
       "      <td>0.389636</td>\n",
       "      <td>0.363560</td>\n",
       "      <td>0.362057</td>\n",
       "      <td>0.407438</td>\n",
       "      <td>0.229459</td>\n",
       "      <td>0.198096</td>\n",
       "      <td>0.120689</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.395746</td>\n",
       "      <td>0.049767</td>\n",
       "      <td>0.459271</td>\n",
       "      <td>0.351551</td>\n",
       "      <td>0.158860</td>\n",
       "      <td>0.169331</td>\n",
       "      <td>0.109532</td>\n",
       "      <td>0.315321</td>\n",
       "      <td>0.392553</td>\n",
       "      <td>0.314569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.118393</td>\n",
       "      <td>0.066472</td>\n",
       "      <td>-0.085083</td>\n",
       "      <td>-0.038057</td>\n",
       "      <td>0.170126</td>\n",
       "      <td>0.361744</td>\n",
       "      <td>0.328254</td>\n",
       "      <td>0.196131</td>\n",
       "      <td>0.125258</td>\n",
       "      <td>0.135561</td>\n",
       "      <td>0.135682</td>\n",
       "      <td>0.134484</td>\n",
       "      <td>0.295801</td>\n",
       "      <td>0.130443</td>\n",
       "      <td>0.399116</td>\n",
       "      <td>0.283122</td>\n",
       "      <td>0.047819</td>\n",
       "      <td>0.269629</td>\n",
       "      <td>0.060521</td>\n",
       "      <td>0.195798</td>\n",
       "      <td>0.375945</td>\n",
       "      <td>0.379026</td>\n",
       "      <td>0.033139</td>\n",
       "      <td>0.125646</td>\n",
       "      <td>0.070971</td>\n",
       "      <td>0.206696</td>\n",
       "      <td>0.109154</td>\n",
       "      <td>0.235349</td>\n",
       "      <td>0.188731</td>\n",
       "      <td>0.489340</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>0.471282</td>\n",
       "      <td>0.273236</td>\n",
       "      <td>0.257971</td>\n",
       "      <td>0.386658</td>\n",
       "      <td>0.431168</td>\n",
       "      <td>0.103530</td>\n",
       "      <td>0.216883</td>\n",
       "      <td>0.088554</td>\n",
       "      <td>0.380187</td>\n",
       "      <td>0.355356</td>\n",
       "      <td>0.110359</td>\n",
       "      <td>0.398311</td>\n",
       "      <td>0.337611</td>\n",
       "      <td>0.189862</td>\n",
       "      <td>0.163930</td>\n",
       "      <td>0.090570</td>\n",
       "      <td>0.320674</td>\n",
       "      <td>0.350196</td>\n",
       "      <td>0.263606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.112445</td>\n",
       "      <td>0.071174</td>\n",
       "      <td>-0.069540</td>\n",
       "      <td>-0.035583</td>\n",
       "      <td>0.173278</td>\n",
       "      <td>0.334832</td>\n",
       "      <td>0.305024</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.082485</td>\n",
       "      <td>0.114683</td>\n",
       "      <td>0.150533</td>\n",
       "      <td>0.127184</td>\n",
       "      <td>0.260715</td>\n",
       "      <td>0.119747</td>\n",
       "      <td>0.433899</td>\n",
       "      <td>0.211382</td>\n",
       "      <td>0.028118</td>\n",
       "      <td>0.246711</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.184720</td>\n",
       "      <td>0.370142</td>\n",
       "      <td>0.329382</td>\n",
       "      <td>0.092618</td>\n",
       "      <td>0.105124</td>\n",
       "      <td>0.041289</td>\n",
       "      <td>0.205625</td>\n",
       "      <td>0.095944</td>\n",
       "      <td>0.186710</td>\n",
       "      <td>0.166407</td>\n",
       "      <td>0.498658</td>\n",
       "      <td>0.165218</td>\n",
       "      <td>0.448243</td>\n",
       "      <td>0.192344</td>\n",
       "      <td>0.286764</td>\n",
       "      <td>0.373461</td>\n",
       "      <td>0.420693</td>\n",
       "      <td>0.081491</td>\n",
       "      <td>0.200712</td>\n",
       "      <td>0.062363</td>\n",
       "      <td>0.380636</td>\n",
       "      <td>0.357319</td>\n",
       "      <td>0.085180</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.322706</td>\n",
       "      <td>0.130184</td>\n",
       "      <td>0.138095</td>\n",
       "      <td>0.085868</td>\n",
       "      <td>0.333378</td>\n",
       "      <td>0.295501</td>\n",
       "      <td>0.237679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.110832</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>-0.026704</td>\n",
       "      <td>-0.044224</td>\n",
       "      <td>0.169486</td>\n",
       "      <td>0.335513</td>\n",
       "      <td>0.325394</td>\n",
       "      <td>0.149996</td>\n",
       "      <td>0.129051</td>\n",
       "      <td>0.079284</td>\n",
       "      <td>0.133319</td>\n",
       "      <td>0.103259</td>\n",
       "      <td>0.223445</td>\n",
       "      <td>0.114011</td>\n",
       "      <td>0.424805</td>\n",
       "      <td>0.167258</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.231628</td>\n",
       "      <td>-0.004985</td>\n",
       "      <td>0.153718</td>\n",
       "      <td>0.364236</td>\n",
       "      <td>0.303576</td>\n",
       "      <td>0.105697</td>\n",
       "      <td>0.137746</td>\n",
       "      <td>0.097640</td>\n",
       "      <td>0.208945</td>\n",
       "      <td>0.057657</td>\n",
       "      <td>0.165451</td>\n",
       "      <td>0.197670</td>\n",
       "      <td>0.471248</td>\n",
       "      <td>0.139592</td>\n",
       "      <td>0.408264</td>\n",
       "      <td>0.249281</td>\n",
       "      <td>0.219508</td>\n",
       "      <td>0.354515</td>\n",
       "      <td>0.433607</td>\n",
       "      <td>0.134113</td>\n",
       "      <td>0.145181</td>\n",
       "      <td>0.089435</td>\n",
       "      <td>0.383921</td>\n",
       "      <td>0.352445</td>\n",
       "      <td>0.055227</td>\n",
       "      <td>0.375311</td>\n",
       "      <td>0.330913</td>\n",
       "      <td>0.124402</td>\n",
       "      <td>0.146491</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>0.332657</td>\n",
       "      <td>0.309353</td>\n",
       "      <td>0.249582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.010096</td>\n",
       "      <td>-0.090371</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.141285</td>\n",
       "      <td>0.306524</td>\n",
       "      <td>0.317829</td>\n",
       "      <td>0.106359</td>\n",
       "      <td>0.117060</td>\n",
       "      <td>0.150110</td>\n",
       "      <td>0.116383</td>\n",
       "      <td>0.106592</td>\n",
       "      <td>0.216880</td>\n",
       "      <td>0.073806</td>\n",
       "      <td>0.408572</td>\n",
       "      <td>0.148984</td>\n",
       "      <td>-0.037699</td>\n",
       "      <td>0.223690</td>\n",
       "      <td>-0.049333</td>\n",
       "      <td>0.147138</td>\n",
       "      <td>0.319742</td>\n",
       "      <td>0.293748</td>\n",
       "      <td>0.113360</td>\n",
       "      <td>0.057237</td>\n",
       "      <td>0.061708</td>\n",
       "      <td>0.173601</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>0.171886</td>\n",
       "      <td>0.182193</td>\n",
       "      <td>0.452540</td>\n",
       "      <td>0.133759</td>\n",
       "      <td>0.412593</td>\n",
       "      <td>0.239884</td>\n",
       "      <td>0.220689</td>\n",
       "      <td>0.313186</td>\n",
       "      <td>0.418158</td>\n",
       "      <td>0.148771</td>\n",
       "      <td>0.199931</td>\n",
       "      <td>0.043461</td>\n",
       "      <td>0.390295</td>\n",
       "      <td>0.324970</td>\n",
       "      <td>0.032385</td>\n",
       "      <td>0.379635</td>\n",
       "      <td>0.275494</td>\n",
       "      <td>0.121216</td>\n",
       "      <td>0.149566</td>\n",
       "      <td>0.090764</td>\n",
       "      <td>0.315061</td>\n",
       "      <td>0.292397</td>\n",
       "      <td>0.227926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.121130</td>\n",
       "      <td>0.086170</td>\n",
       "      <td>0.051572</td>\n",
       "      <td>0.014885</td>\n",
       "      <td>0.176143</td>\n",
       "      <td>0.304544</td>\n",
       "      <td>0.328401</td>\n",
       "      <td>0.093039</td>\n",
       "      <td>0.172392</td>\n",
       "      <td>0.116871</td>\n",
       "      <td>0.189424</td>\n",
       "      <td>0.140577</td>\n",
       "      <td>0.237462</td>\n",
       "      <td>0.082102</td>\n",
       "      <td>0.411423</td>\n",
       "      <td>0.179017</td>\n",
       "      <td>-0.066061</td>\n",
       "      <td>0.278528</td>\n",
       "      <td>-0.021790</td>\n",
       "      <td>0.250669</td>\n",
       "      <td>0.336252</td>\n",
       "      <td>0.284208</td>\n",
       "      <td>0.050255</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.081830</td>\n",
       "      <td>0.169413</td>\n",
       "      <td>0.043488</td>\n",
       "      <td>0.172752</td>\n",
       "      <td>0.239376</td>\n",
       "      <td>0.504079</td>\n",
       "      <td>0.080412</td>\n",
       "      <td>0.411569</td>\n",
       "      <td>0.244873</td>\n",
       "      <td>0.169905</td>\n",
       "      <td>0.327182</td>\n",
       "      <td>0.334231</td>\n",
       "      <td>0.182687</td>\n",
       "      <td>0.194583</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.399819</td>\n",
       "      <td>0.368820</td>\n",
       "      <td>0.113439</td>\n",
       "      <td>0.342897</td>\n",
       "      <td>0.242929</td>\n",
       "      <td>0.205391</td>\n",
       "      <td>0.238798</td>\n",
       "      <td>0.091846</td>\n",
       "      <td>0.385289</td>\n",
       "      <td>0.277086</td>\n",
       "      <td>0.233666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.077376</td>\n",
       "      <td>0.057850</td>\n",
       "      <td>0.042899</td>\n",
       "      <td>-0.039426</td>\n",
       "      <td>0.195169</td>\n",
       "      <td>0.279856</td>\n",
       "      <td>0.246526</td>\n",
       "      <td>0.129622</td>\n",
       "      <td>0.145211</td>\n",
       "      <td>0.057704</td>\n",
       "      <td>0.213794</td>\n",
       "      <td>0.074806</td>\n",
       "      <td>0.236637</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.340918</td>\n",
       "      <td>0.147206</td>\n",
       "      <td>-0.105339</td>\n",
       "      <td>0.247464</td>\n",
       "      <td>-0.018838</td>\n",
       "      <td>0.177978</td>\n",
       "      <td>0.330272</td>\n",
       "      <td>0.230687</td>\n",
       "      <td>0.048758</td>\n",
       "      <td>0.022660</td>\n",
       "      <td>0.023692</td>\n",
       "      <td>0.136932</td>\n",
       "      <td>-0.043261</td>\n",
       "      <td>0.115359</td>\n",
       "      <td>0.177633</td>\n",
       "      <td>0.494236</td>\n",
       "      <td>0.052394</td>\n",
       "      <td>0.430148</td>\n",
       "      <td>0.229147</td>\n",
       "      <td>0.168884</td>\n",
       "      <td>0.285890</td>\n",
       "      <td>0.263396</td>\n",
       "      <td>0.242414</td>\n",
       "      <td>0.127577</td>\n",
       "      <td>0.059169</td>\n",
       "      <td>0.420136</td>\n",
       "      <td>0.324292</td>\n",
       "      <td>0.148288</td>\n",
       "      <td>0.304514</td>\n",
       "      <td>0.144105</td>\n",
       "      <td>0.150762</td>\n",
       "      <td>0.172026</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>0.358612</td>\n",
       "      <td>0.182199</td>\n",
       "      <td>0.124255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.079092</td>\n",
       "      <td>0.066502</td>\n",
       "      <td>0.041553</td>\n",
       "      <td>-0.025986</td>\n",
       "      <td>0.167237</td>\n",
       "      <td>0.188677</td>\n",
       "      <td>0.216455</td>\n",
       "      <td>0.116040</td>\n",
       "      <td>0.151626</td>\n",
       "      <td>-0.032688</td>\n",
       "      <td>0.116451</td>\n",
       "      <td>0.065548</td>\n",
       "      <td>0.216217</td>\n",
       "      <td>0.043726</td>\n",
       "      <td>0.381771</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>-0.025495</td>\n",
       "      <td>0.173611</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.171467</td>\n",
       "      <td>0.345834</td>\n",
       "      <td>0.201395</td>\n",
       "      <td>0.044126</td>\n",
       "      <td>-0.014237</td>\n",
       "      <td>-0.003892</td>\n",
       "      <td>0.200308</td>\n",
       "      <td>-0.033159</td>\n",
       "      <td>0.142090</td>\n",
       "      <td>0.092513</td>\n",
       "      <td>0.507334</td>\n",
       "      <td>0.110768</td>\n",
       "      <td>0.370528</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.171383</td>\n",
       "      <td>0.293245</td>\n",
       "      <td>0.186796</td>\n",
       "      <td>0.263650</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>0.079609</td>\n",
       "      <td>0.395107</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.098621</td>\n",
       "      <td>0.239575</td>\n",
       "      <td>0.175225</td>\n",
       "      <td>0.200428</td>\n",
       "      <td>0.142512</td>\n",
       "      <td>0.101472</td>\n",
       "      <td>0.367649</td>\n",
       "      <td>0.222477</td>\n",
       "      <td>0.084796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.118458</td>\n",
       "      <td>0.147674</td>\n",
       "      <td>0.026512</td>\n",
       "      <td>-0.028662</td>\n",
       "      <td>0.193007</td>\n",
       "      <td>0.168648</td>\n",
       "      <td>0.216027</td>\n",
       "      <td>0.125948</td>\n",
       "      <td>0.168217</td>\n",
       "      <td>-0.019208</td>\n",
       "      <td>0.116808</td>\n",
       "      <td>0.099276</td>\n",
       "      <td>0.293212</td>\n",
       "      <td>0.072510</td>\n",
       "      <td>0.304324</td>\n",
       "      <td>0.176478</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.266013</td>\n",
       "      <td>0.030060</td>\n",
       "      <td>0.213260</td>\n",
       "      <td>0.269361</td>\n",
       "      <td>0.249993</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>0.013662</td>\n",
       "      <td>0.038497</td>\n",
       "      <td>0.233475</td>\n",
       "      <td>0.016759</td>\n",
       "      <td>0.167357</td>\n",
       "      <td>0.067169</td>\n",
       "      <td>0.434095</td>\n",
       "      <td>0.086706</td>\n",
       "      <td>0.381107</td>\n",
       "      <td>0.277393</td>\n",
       "      <td>0.230720</td>\n",
       "      <td>0.308187</td>\n",
       "      <td>0.281288</td>\n",
       "      <td>0.317997</td>\n",
       "      <td>0.033508</td>\n",
       "      <td>0.160698</td>\n",
       "      <td>0.382458</td>\n",
       "      <td>0.314506</td>\n",
       "      <td>0.100389</td>\n",
       "      <td>0.249284</td>\n",
       "      <td>0.190628</td>\n",
       "      <td>0.179180</td>\n",
       "      <td>0.155891</td>\n",
       "      <td>0.105653</td>\n",
       "      <td>0.396334</td>\n",
       "      <td>0.204329</td>\n",
       "      <td>0.106827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.108690</td>\n",
       "      <td>0.099256</td>\n",
       "      <td>-0.006159</td>\n",
       "      <td>-0.015199</td>\n",
       "      <td>0.186492</td>\n",
       "      <td>0.232423</td>\n",
       "      <td>0.215168</td>\n",
       "      <td>0.081099</td>\n",
       "      <td>0.185889</td>\n",
       "      <td>-0.068452</td>\n",
       "      <td>0.104821</td>\n",
       "      <td>0.107632</td>\n",
       "      <td>0.305360</td>\n",
       "      <td>0.107356</td>\n",
       "      <td>0.391568</td>\n",
       "      <td>0.136449</td>\n",
       "      <td>0.031318</td>\n",
       "      <td>0.305214</td>\n",
       "      <td>0.054801</td>\n",
       "      <td>0.264640</td>\n",
       "      <td>0.290637</td>\n",
       "      <td>0.221696</td>\n",
       "      <td>-0.006247</td>\n",
       "      <td>-0.017184</td>\n",
       "      <td>-0.015764</td>\n",
       "      <td>0.113879</td>\n",
       "      <td>0.029433</td>\n",
       "      <td>0.245329</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.471773</td>\n",
       "      <td>0.117414</td>\n",
       "      <td>0.366033</td>\n",
       "      <td>0.171087</td>\n",
       "      <td>0.196903</td>\n",
       "      <td>0.321292</td>\n",
       "      <td>0.177392</td>\n",
       "      <td>0.309079</td>\n",
       "      <td>0.063994</td>\n",
       "      <td>0.113432</td>\n",
       "      <td>0.421381</td>\n",
       "      <td>0.304008</td>\n",
       "      <td>0.103211</td>\n",
       "      <td>0.220820</td>\n",
       "      <td>0.122105</td>\n",
       "      <td>0.111107</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>0.165300</td>\n",
       "      <td>0.365275</td>\n",
       "      <td>0.154413</td>\n",
       "      <td>0.130489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.026312</td>\n",
       "      <td>0.067750</td>\n",
       "      <td>-0.002671</td>\n",
       "      <td>-0.057931</td>\n",
       "      <td>0.259651</td>\n",
       "      <td>0.239921</td>\n",
       "      <td>0.168358</td>\n",
       "      <td>0.075303</td>\n",
       "      <td>0.168857</td>\n",
       "      <td>-0.012798</td>\n",
       "      <td>0.050117</td>\n",
       "      <td>0.123670</td>\n",
       "      <td>0.257548</td>\n",
       "      <td>0.204139</td>\n",
       "      <td>0.346479</td>\n",
       "      <td>0.056906</td>\n",
       "      <td>0.142350</td>\n",
       "      <td>0.301902</td>\n",
       "      <td>0.073265</td>\n",
       "      <td>0.166516</td>\n",
       "      <td>0.284892</td>\n",
       "      <td>0.196866</td>\n",
       "      <td>0.081641</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.105355</td>\n",
       "      <td>0.107942</td>\n",
       "      <td>0.254527</td>\n",
       "      <td>0.052013</td>\n",
       "      <td>0.458768</td>\n",
       "      <td>0.131481</td>\n",
       "      <td>0.323521</td>\n",
       "      <td>0.212170</td>\n",
       "      <td>0.174793</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.213773</td>\n",
       "      <td>0.259620</td>\n",
       "      <td>0.063328</td>\n",
       "      <td>0.160012</td>\n",
       "      <td>0.434600</td>\n",
       "      <td>0.332082</td>\n",
       "      <td>0.144982</td>\n",
       "      <td>0.236338</td>\n",
       "      <td>0.165760</td>\n",
       "      <td>0.132539</td>\n",
       "      <td>0.129653</td>\n",
       "      <td>0.070452</td>\n",
       "      <td>0.361894</td>\n",
       "      <td>0.088078</td>\n",
       "      <td>0.158419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.091878</td>\n",
       "      <td>0.028262</td>\n",
       "      <td>0.024051</td>\n",
       "      <td>-0.008254</td>\n",
       "      <td>0.249992</td>\n",
       "      <td>0.275069</td>\n",
       "      <td>0.197814</td>\n",
       "      <td>0.122857</td>\n",
       "      <td>0.117712</td>\n",
       "      <td>0.055132</td>\n",
       "      <td>0.046964</td>\n",
       "      <td>0.192510</td>\n",
       "      <td>0.395373</td>\n",
       "      <td>0.180430</td>\n",
       "      <td>0.355474</td>\n",
       "      <td>0.132615</td>\n",
       "      <td>0.260949</td>\n",
       "      <td>0.295228</td>\n",
       "      <td>0.157305</td>\n",
       "      <td>0.173153</td>\n",
       "      <td>0.377902</td>\n",
       "      <td>0.285773</td>\n",
       "      <td>0.060179</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>0.054936</td>\n",
       "      <td>0.252552</td>\n",
       "      <td>0.188929</td>\n",
       "      <td>0.245828</td>\n",
       "      <td>0.090475</td>\n",
       "      <td>0.504120</td>\n",
       "      <td>0.231210</td>\n",
       "      <td>0.315257</td>\n",
       "      <td>0.327689</td>\n",
       "      <td>0.254919</td>\n",
       "      <td>0.310461</td>\n",
       "      <td>0.249123</td>\n",
       "      <td>0.299194</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>0.171107</td>\n",
       "      <td>0.526446</td>\n",
       "      <td>0.335213</td>\n",
       "      <td>0.122867</td>\n",
       "      <td>0.240305</td>\n",
       "      <td>0.295851</td>\n",
       "      <td>0.114652</td>\n",
       "      <td>0.090671</td>\n",
       "      <td>0.133932</td>\n",
       "      <td>0.372435</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.171288</td>\n",
       "      <td>0.040411</td>\n",
       "      <td>0.120935</td>\n",
       "      <td>0.076483</td>\n",
       "      <td>0.306322</td>\n",
       "      <td>0.306045</td>\n",
       "      <td>0.299105</td>\n",
       "      <td>0.232276</td>\n",
       "      <td>0.192978</td>\n",
       "      <td>0.079203</td>\n",
       "      <td>0.141386</td>\n",
       "      <td>0.267995</td>\n",
       "      <td>0.485828</td>\n",
       "      <td>0.283842</td>\n",
       "      <td>0.432719</td>\n",
       "      <td>0.140901</td>\n",
       "      <td>0.261151</td>\n",
       "      <td>0.279842</td>\n",
       "      <td>0.188940</td>\n",
       "      <td>0.263056</td>\n",
       "      <td>0.384571</td>\n",
       "      <td>0.375572</td>\n",
       "      <td>0.154031</td>\n",
       "      <td>0.124358</td>\n",
       "      <td>0.178543</td>\n",
       "      <td>0.310131</td>\n",
       "      <td>0.235696</td>\n",
       "      <td>0.382203</td>\n",
       "      <td>0.158414</td>\n",
       "      <td>0.535149</td>\n",
       "      <td>0.291585</td>\n",
       "      <td>0.300139</td>\n",
       "      <td>0.306936</td>\n",
       "      <td>0.233615</td>\n",
       "      <td>0.387824</td>\n",
       "      <td>0.336902</td>\n",
       "      <td>0.365228</td>\n",
       "      <td>0.288760</td>\n",
       "      <td>0.162496</td>\n",
       "      <td>0.557444</td>\n",
       "      <td>0.334231</td>\n",
       "      <td>0.171958</td>\n",
       "      <td>0.290277</td>\n",
       "      <td>0.320856</td>\n",
       "      <td>0.050322</td>\n",
       "      <td>0.217549</td>\n",
       "      <td>0.172532</td>\n",
       "      <td>0.398218</td>\n",
       "      <td>0.285946</td>\n",
       "      <td>0.359922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.154015</td>\n",
       "      <td>0.075607</td>\n",
       "      <td>0.102427</td>\n",
       "      <td>0.032202</td>\n",
       "      <td>0.307978</td>\n",
       "      <td>0.425528</td>\n",
       "      <td>0.393017</td>\n",
       "      <td>0.181757</td>\n",
       "      <td>0.214637</td>\n",
       "      <td>0.236302</td>\n",
       "      <td>0.187417</td>\n",
       "      <td>0.292921</td>\n",
       "      <td>0.434479</td>\n",
       "      <td>0.284318</td>\n",
       "      <td>0.460856</td>\n",
       "      <td>0.168763</td>\n",
       "      <td>0.262524</td>\n",
       "      <td>0.357582</td>\n",
       "      <td>0.131950</td>\n",
       "      <td>0.210581</td>\n",
       "      <td>0.380608</td>\n",
       "      <td>0.370433</td>\n",
       "      <td>0.157731</td>\n",
       "      <td>0.126444</td>\n",
       "      <td>0.137863</td>\n",
       "      <td>0.308762</td>\n",
       "      <td>0.245547</td>\n",
       "      <td>0.336693</td>\n",
       "      <td>0.256226</td>\n",
       "      <td>0.528512</td>\n",
       "      <td>0.310872</td>\n",
       "      <td>0.361774</td>\n",
       "      <td>0.278536</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.353642</td>\n",
       "      <td>0.416935</td>\n",
       "      <td>0.340497</td>\n",
       "      <td>0.447963</td>\n",
       "      <td>0.150187</td>\n",
       "      <td>0.563931</td>\n",
       "      <td>0.342123</td>\n",
       "      <td>0.221887</td>\n",
       "      <td>0.347931</td>\n",
       "      <td>0.364419</td>\n",
       "      <td>0.165338</td>\n",
       "      <td>0.237702</td>\n",
       "      <td>0.297385</td>\n",
       "      <td>0.350518</td>\n",
       "      <td>0.254859</td>\n",
       "      <td>0.399992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.187899</td>\n",
       "      <td>0.089427</td>\n",
       "      <td>0.123973</td>\n",
       "      <td>0.152481</td>\n",
       "      <td>0.357232</td>\n",
       "      <td>0.494137</td>\n",
       "      <td>0.406453</td>\n",
       "      <td>0.239350</td>\n",
       "      <td>0.287791</td>\n",
       "      <td>0.346295</td>\n",
       "      <td>0.344147</td>\n",
       "      <td>0.363749</td>\n",
       "      <td>0.429845</td>\n",
       "      <td>0.306157</td>\n",
       "      <td>0.535291</td>\n",
       "      <td>0.175332</td>\n",
       "      <td>0.191405</td>\n",
       "      <td>0.385754</td>\n",
       "      <td>0.167129</td>\n",
       "      <td>0.231705</td>\n",
       "      <td>0.516689</td>\n",
       "      <td>0.341186</td>\n",
       "      <td>0.238077</td>\n",
       "      <td>0.130733</td>\n",
       "      <td>0.200018</td>\n",
       "      <td>0.335982</td>\n",
       "      <td>0.253505</td>\n",
       "      <td>0.394433</td>\n",
       "      <td>0.265456</td>\n",
       "      <td>0.549314</td>\n",
       "      <td>0.291106</td>\n",
       "      <td>0.418792</td>\n",
       "      <td>0.236342</td>\n",
       "      <td>0.261263</td>\n",
       "      <td>0.301466</td>\n",
       "      <td>0.430224</td>\n",
       "      <td>0.303516</td>\n",
       "      <td>0.397720</td>\n",
       "      <td>0.146011</td>\n",
       "      <td>0.596045</td>\n",
       "      <td>0.487866</td>\n",
       "      <td>0.302082</td>\n",
       "      <td>0.327899</td>\n",
       "      <td>0.399695</td>\n",
       "      <td>0.158884</td>\n",
       "      <td>0.228272</td>\n",
       "      <td>0.356598</td>\n",
       "      <td>0.441077</td>\n",
       "      <td>0.355779</td>\n",
       "      <td>0.362212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.209309</td>\n",
       "      <td>0.051752</td>\n",
       "      <td>0.206793</td>\n",
       "      <td>0.122946</td>\n",
       "      <td>0.289489</td>\n",
       "      <td>0.430624</td>\n",
       "      <td>0.411857</td>\n",
       "      <td>0.306197</td>\n",
       "      <td>0.304576</td>\n",
       "      <td>0.289548</td>\n",
       "      <td>0.261257</td>\n",
       "      <td>0.361785</td>\n",
       "      <td>0.370141</td>\n",
       "      <td>0.229574</td>\n",
       "      <td>0.380801</td>\n",
       "      <td>0.196846</td>\n",
       "      <td>0.174951</td>\n",
       "      <td>0.369359</td>\n",
       "      <td>0.116365</td>\n",
       "      <td>0.141429</td>\n",
       "      <td>0.433157</td>\n",
       "      <td>0.408958</td>\n",
       "      <td>0.331366</td>\n",
       "      <td>0.174192</td>\n",
       "      <td>0.282703</td>\n",
       "      <td>0.327964</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.279315</td>\n",
       "      <td>0.335115</td>\n",
       "      <td>0.463313</td>\n",
       "      <td>0.197650</td>\n",
       "      <td>0.309958</td>\n",
       "      <td>0.299800</td>\n",
       "      <td>0.277595</td>\n",
       "      <td>0.225826</td>\n",
       "      <td>0.388211</td>\n",
       "      <td>0.286810</td>\n",
       "      <td>0.370077</td>\n",
       "      <td>0.131925</td>\n",
       "      <td>0.558233</td>\n",
       "      <td>0.440850</td>\n",
       "      <td>0.308253</td>\n",
       "      <td>0.314409</td>\n",
       "      <td>0.445771</td>\n",
       "      <td>0.205412</td>\n",
       "      <td>0.291074</td>\n",
       "      <td>0.298172</td>\n",
       "      <td>0.421801</td>\n",
       "      <td>0.406623</td>\n",
       "      <td>0.316919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.133118</td>\n",
       "      <td>-0.011669</td>\n",
       "      <td>0.208242</td>\n",
       "      <td>0.214479</td>\n",
       "      <td>0.276153</td>\n",
       "      <td>0.356256</td>\n",
       "      <td>0.394918</td>\n",
       "      <td>0.226345</td>\n",
       "      <td>0.327706</td>\n",
       "      <td>0.213627</td>\n",
       "      <td>0.288251</td>\n",
       "      <td>0.260669</td>\n",
       "      <td>0.364902</td>\n",
       "      <td>0.176811</td>\n",
       "      <td>0.360618</td>\n",
       "      <td>0.170794</td>\n",
       "      <td>0.122981</td>\n",
       "      <td>0.269434</td>\n",
       "      <td>0.039005</td>\n",
       "      <td>0.136582</td>\n",
       "      <td>0.389441</td>\n",
       "      <td>0.290888</td>\n",
       "      <td>0.290677</td>\n",
       "      <td>0.082627</td>\n",
       "      <td>0.233947</td>\n",
       "      <td>0.287268</td>\n",
       "      <td>0.215439</td>\n",
       "      <td>0.210495</td>\n",
       "      <td>0.300379</td>\n",
       "      <td>0.410943</td>\n",
       "      <td>0.287322</td>\n",
       "      <td>0.255416</td>\n",
       "      <td>0.227572</td>\n",
       "      <td>0.250735</td>\n",
       "      <td>0.199928</td>\n",
       "      <td>0.347175</td>\n",
       "      <td>0.299826</td>\n",
       "      <td>0.290260</td>\n",
       "      <td>0.113288</td>\n",
       "      <td>0.587581</td>\n",
       "      <td>0.354855</td>\n",
       "      <td>0.230133</td>\n",
       "      <td>0.195467</td>\n",
       "      <td>0.440810</td>\n",
       "      <td>0.183517</td>\n",
       "      <td>0.270408</td>\n",
       "      <td>0.326170</td>\n",
       "      <td>0.382697</td>\n",
       "      <td>0.411252</td>\n",
       "      <td>0.278949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.150503</td>\n",
       "      <td>0.094728</td>\n",
       "      <td>0.172332</td>\n",
       "      <td>0.263880</td>\n",
       "      <td>0.278361</td>\n",
       "      <td>0.335092</td>\n",
       "      <td>0.420163</td>\n",
       "      <td>0.261674</td>\n",
       "      <td>0.326497</td>\n",
       "      <td>0.225491</td>\n",
       "      <td>0.314413</td>\n",
       "      <td>0.294526</td>\n",
       "      <td>0.362024</td>\n",
       "      <td>0.212999</td>\n",
       "      <td>0.366234</td>\n",
       "      <td>0.201379</td>\n",
       "      <td>0.122230</td>\n",
       "      <td>0.372495</td>\n",
       "      <td>0.063357</td>\n",
       "      <td>0.183368</td>\n",
       "      <td>0.295628</td>\n",
       "      <td>0.250712</td>\n",
       "      <td>0.460041</td>\n",
       "      <td>0.149862</td>\n",
       "      <td>0.227898</td>\n",
       "      <td>0.323962</td>\n",
       "      <td>0.158701</td>\n",
       "      <td>0.215710</td>\n",
       "      <td>0.273064</td>\n",
       "      <td>0.442086</td>\n",
       "      <td>0.329525</td>\n",
       "      <td>0.345776</td>\n",
       "      <td>0.211775</td>\n",
       "      <td>0.279763</td>\n",
       "      <td>0.215876</td>\n",
       "      <td>0.376295</td>\n",
       "      <td>0.280615</td>\n",
       "      <td>0.288543</td>\n",
       "      <td>0.144858</td>\n",
       "      <td>0.630674</td>\n",
       "      <td>0.332793</td>\n",
       "      <td>0.269440</td>\n",
       "      <td>0.262164</td>\n",
       "      <td>0.459170</td>\n",
       "      <td>0.245837</td>\n",
       "      <td>0.211193</td>\n",
       "      <td>0.406526</td>\n",
       "      <td>0.381470</td>\n",
       "      <td>0.439900</td>\n",
       "      <td>0.330482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-0.002531</td>\n",
       "      <td>0.121276</td>\n",
       "      <td>0.054148</td>\n",
       "      <td>0.280607</td>\n",
       "      <td>0.106176</td>\n",
       "      <td>0.263749</td>\n",
       "      <td>0.372157</td>\n",
       "      <td>0.239144</td>\n",
       "      <td>0.214807</td>\n",
       "      <td>0.234057</td>\n",
       "      <td>0.225468</td>\n",
       "      <td>0.333460</td>\n",
       "      <td>0.251943</td>\n",
       "      <td>0.226732</td>\n",
       "      <td>0.392620</td>\n",
       "      <td>0.125993</td>\n",
       "      <td>0.145961</td>\n",
       "      <td>0.332198</td>\n",
       "      <td>0.054221</td>\n",
       "      <td>0.100158</td>\n",
       "      <td>0.261788</td>\n",
       "      <td>0.145112</td>\n",
       "      <td>0.394244</td>\n",
       "      <td>0.108885</td>\n",
       "      <td>0.186248</td>\n",
       "      <td>0.247509</td>\n",
       "      <td>0.165225</td>\n",
       "      <td>0.242332</td>\n",
       "      <td>0.174949</td>\n",
       "      <td>0.350452</td>\n",
       "      <td>0.222351</td>\n",
       "      <td>0.238772</td>\n",
       "      <td>0.202846</td>\n",
       "      <td>0.278031</td>\n",
       "      <td>0.108695</td>\n",
       "      <td>0.285174</td>\n",
       "      <td>0.223685</td>\n",
       "      <td>0.200029</td>\n",
       "      <td>0.144796</td>\n",
       "      <td>0.521038</td>\n",
       "      <td>0.295552</td>\n",
       "      <td>0.199654</td>\n",
       "      <td>0.191035</td>\n",
       "      <td>0.469922</td>\n",
       "      <td>0.213282</td>\n",
       "      <td>0.166313</td>\n",
       "      <td>0.382094</td>\n",
       "      <td>0.367091</td>\n",
       "      <td>0.418988</td>\n",
       "      <td>0.278142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.021983</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>-0.071096</td>\n",
       "      <td>0.254715</td>\n",
       "      <td>0.097273</td>\n",
       "      <td>0.186482</td>\n",
       "      <td>0.264510</td>\n",
       "      <td>0.224768</td>\n",
       "      <td>0.144749</td>\n",
       "      <td>0.271956</td>\n",
       "      <td>0.166504</td>\n",
       "      <td>0.295199</td>\n",
       "      <td>0.161507</td>\n",
       "      <td>0.190426</td>\n",
       "      <td>0.328642</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.093698</td>\n",
       "      <td>0.286002</td>\n",
       "      <td>-0.042589</td>\n",
       "      <td>0.090785</td>\n",
       "      <td>0.224669</td>\n",
       "      <td>0.033179</td>\n",
       "      <td>0.349375</td>\n",
       "      <td>0.185575</td>\n",
       "      <td>0.115958</td>\n",
       "      <td>0.201773</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.129568</td>\n",
       "      <td>0.140505</td>\n",
       "      <td>0.300043</td>\n",
       "      <td>0.264338</td>\n",
       "      <td>0.242334</td>\n",
       "      <td>0.155369</td>\n",
       "      <td>0.134148</td>\n",
       "      <td>0.061888</td>\n",
       "      <td>0.238945</td>\n",
       "      <td>0.171509</td>\n",
       "      <td>0.140265</td>\n",
       "      <td>0.127287</td>\n",
       "      <td>0.442055</td>\n",
       "      <td>0.222594</td>\n",
       "      <td>0.202178</td>\n",
       "      <td>0.149365</td>\n",
       "      <td>0.437307</td>\n",
       "      <td>0.107946</td>\n",
       "      <td>0.189552</td>\n",
       "      <td>0.362703</td>\n",
       "      <td>0.287359</td>\n",
       "      <td>0.313995</td>\n",
       "      <td>0.250811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.033865</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>-0.033778</td>\n",
       "      <td>0.256992</td>\n",
       "      <td>0.106336</td>\n",
       "      <td>0.117153</td>\n",
       "      <td>0.368631</td>\n",
       "      <td>0.236423</td>\n",
       "      <td>0.099360</td>\n",
       "      <td>0.249822</td>\n",
       "      <td>0.167338</td>\n",
       "      <td>0.273093</td>\n",
       "      <td>0.236997</td>\n",
       "      <td>0.120677</td>\n",
       "      <td>0.276351</td>\n",
       "      <td>0.075609</td>\n",
       "      <td>0.174477</td>\n",
       "      <td>0.203336</td>\n",
       "      <td>-0.042460</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.196690</td>\n",
       "      <td>-0.029529</td>\n",
       "      <td>0.255395</td>\n",
       "      <td>0.225215</td>\n",
       "      <td>0.088886</td>\n",
       "      <td>0.264878</td>\n",
       "      <td>0.073793</td>\n",
       "      <td>0.134167</td>\n",
       "      <td>0.149490</td>\n",
       "      <td>0.257772</td>\n",
       "      <td>0.308963</td>\n",
       "      <td>0.177982</td>\n",
       "      <td>0.183224</td>\n",
       "      <td>0.179977</td>\n",
       "      <td>0.084643</td>\n",
       "      <td>0.194117</td>\n",
       "      <td>0.243351</td>\n",
       "      <td>0.106597</td>\n",
       "      <td>0.072277</td>\n",
       "      <td>0.494721</td>\n",
       "      <td>0.160748</td>\n",
       "      <td>0.185416</td>\n",
       "      <td>0.188051</td>\n",
       "      <td>0.421227</td>\n",
       "      <td>0.087421</td>\n",
       "      <td>0.180820</td>\n",
       "      <td>0.300380</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.262940</td>\n",
       "      <td>0.249680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.026289</td>\n",
       "      <td>-0.022548</td>\n",
       "      <td>-0.106799</td>\n",
       "      <td>0.168658</td>\n",
       "      <td>0.077554</td>\n",
       "      <td>-0.000632</td>\n",
       "      <td>0.169330</td>\n",
       "      <td>0.206034</td>\n",
       "      <td>-0.002725</td>\n",
       "      <td>0.117606</td>\n",
       "      <td>0.124846</td>\n",
       "      <td>0.257664</td>\n",
       "      <td>0.091419</td>\n",
       "      <td>0.037722</td>\n",
       "      <td>0.246602</td>\n",
       "      <td>-0.058531</td>\n",
       "      <td>0.128115</td>\n",
       "      <td>0.160145</td>\n",
       "      <td>-0.131508</td>\n",
       "      <td>-0.037176</td>\n",
       "      <td>0.181015</td>\n",
       "      <td>-0.125469</td>\n",
       "      <td>0.207267</td>\n",
       "      <td>0.104794</td>\n",
       "      <td>-0.037282</td>\n",
       "      <td>0.240670</td>\n",
       "      <td>-0.030373</td>\n",
       "      <td>0.068005</td>\n",
       "      <td>-0.002488</td>\n",
       "      <td>0.222583</td>\n",
       "      <td>0.283989</td>\n",
       "      <td>0.086833</td>\n",
       "      <td>0.137723</td>\n",
       "      <td>0.138646</td>\n",
       "      <td>0.074169</td>\n",
       "      <td>0.131306</td>\n",
       "      <td>0.219903</td>\n",
       "      <td>0.053484</td>\n",
       "      <td>0.140162</td>\n",
       "      <td>0.342467</td>\n",
       "      <td>0.063399</td>\n",
       "      <td>0.102892</td>\n",
       "      <td>0.127435</td>\n",
       "      <td>0.304167</td>\n",
       "      <td>-0.004300</td>\n",
       "      <td>0.072074</td>\n",
       "      <td>0.323523</td>\n",
       "      <td>0.207387</td>\n",
       "      <td>0.223379</td>\n",
       "      <td>0.213712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.023880</td>\n",
       "      <td>0.081796</td>\n",
       "      <td>-0.185402</td>\n",
       "      <td>0.116585</td>\n",
       "      <td>-0.003554</td>\n",
       "      <td>0.050576</td>\n",
       "      <td>0.171311</td>\n",
       "      <td>0.200667</td>\n",
       "      <td>-0.025147</td>\n",
       "      <td>0.147270</td>\n",
       "      <td>0.128180</td>\n",
       "      <td>0.262923</td>\n",
       "      <td>0.051957</td>\n",
       "      <td>-0.037389</td>\n",
       "      <td>0.224305</td>\n",
       "      <td>-0.109834</td>\n",
       "      <td>0.138318</td>\n",
       "      <td>0.075062</td>\n",
       "      <td>-0.161301</td>\n",
       "      <td>-0.118933</td>\n",
       "      <td>0.079499</td>\n",
       "      <td>-0.086999</td>\n",
       "      <td>0.209478</td>\n",
       "      <td>0.145357</td>\n",
       "      <td>-0.047605</td>\n",
       "      <td>0.257967</td>\n",
       "      <td>-0.033157</td>\n",
       "      <td>0.057639</td>\n",
       "      <td>0.018631</td>\n",
       "      <td>0.218843</td>\n",
       "      <td>0.157408</td>\n",
       "      <td>0.057508</td>\n",
       "      <td>0.023253</td>\n",
       "      <td>0.073618</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.194284</td>\n",
       "      <td>0.108746</td>\n",
       "      <td>0.090615</td>\n",
       "      <td>0.147209</td>\n",
       "      <td>0.290271</td>\n",
       "      <td>0.029376</td>\n",
       "      <td>0.115819</td>\n",
       "      <td>0.168009</td>\n",
       "      <td>0.341543</td>\n",
       "      <td>0.029361</td>\n",
       "      <td>0.094539</td>\n",
       "      <td>0.313866</td>\n",
       "      <td>0.223267</td>\n",
       "      <td>0.250968</td>\n",
       "      <td>0.105096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.068259</td>\n",
       "      <td>0.073943</td>\n",
       "      <td>-0.063131</td>\n",
       "      <td>0.183850</td>\n",
       "      <td>0.118494</td>\n",
       "      <td>0.144145</td>\n",
       "      <td>0.312818</td>\n",
       "      <td>0.315135</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.200504</td>\n",
       "      <td>0.164189</td>\n",
       "      <td>0.360917</td>\n",
       "      <td>0.125662</td>\n",
       "      <td>0.117169</td>\n",
       "      <td>0.246564</td>\n",
       "      <td>0.019497</td>\n",
       "      <td>0.148266</td>\n",
       "      <td>0.226875</td>\n",
       "      <td>-0.065951</td>\n",
       "      <td>0.067944</td>\n",
       "      <td>0.203365</td>\n",
       "      <td>0.019354</td>\n",
       "      <td>0.254911</td>\n",
       "      <td>0.239617</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>0.341655</td>\n",
       "      <td>0.051687</td>\n",
       "      <td>0.103961</td>\n",
       "      <td>0.128481</td>\n",
       "      <td>0.256487</td>\n",
       "      <td>0.262444</td>\n",
       "      <td>0.214216</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.164780</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.336669</td>\n",
       "      <td>0.119875</td>\n",
       "      <td>0.164258</td>\n",
       "      <td>0.189784</td>\n",
       "      <td>0.342112</td>\n",
       "      <td>0.087548</td>\n",
       "      <td>0.180645</td>\n",
       "      <td>0.249203</td>\n",
       "      <td>0.409597</td>\n",
       "      <td>0.054733</td>\n",
       "      <td>0.200423</td>\n",
       "      <td>0.418050</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.321840</td>\n",
       "      <td>0.215147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.051134</td>\n",
       "      <td>0.111172</td>\n",
       "      <td>-0.054856</td>\n",
       "      <td>0.078304</td>\n",
       "      <td>0.135942</td>\n",
       "      <td>0.118119</td>\n",
       "      <td>0.313867</td>\n",
       "      <td>0.308086</td>\n",
       "      <td>-0.012693</td>\n",
       "      <td>0.146533</td>\n",
       "      <td>0.172051</td>\n",
       "      <td>0.361804</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>0.073463</td>\n",
       "      <td>0.292342</td>\n",
       "      <td>0.041935</td>\n",
       "      <td>0.210255</td>\n",
       "      <td>0.239872</td>\n",
       "      <td>-0.119767</td>\n",
       "      <td>0.023541</td>\n",
       "      <td>0.235662</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.281216</td>\n",
       "      <td>0.213239</td>\n",
       "      <td>0.118544</td>\n",
       "      <td>0.404570</td>\n",
       "      <td>-0.043176</td>\n",
       "      <td>0.124941</td>\n",
       "      <td>0.116404</td>\n",
       "      <td>0.263123</td>\n",
       "      <td>0.246480</td>\n",
       "      <td>0.210592</td>\n",
       "      <td>0.068523</td>\n",
       "      <td>0.176474</td>\n",
       "      <td>0.038214</td>\n",
       "      <td>0.305004</td>\n",
       "      <td>0.173971</td>\n",
       "      <td>0.230083</td>\n",
       "      <td>0.180036</td>\n",
       "      <td>0.395705</td>\n",
       "      <td>0.094982</td>\n",
       "      <td>0.132554</td>\n",
       "      <td>0.267557</td>\n",
       "      <td>0.405589</td>\n",
       "      <td>0.060526</td>\n",
       "      <td>0.156964</td>\n",
       "      <td>0.400036</td>\n",
       "      <td>0.307537</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>0.259276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.121676</td>\n",
       "      <td>0.180153</td>\n",
       "      <td>-0.056253</td>\n",
       "      <td>0.140799</td>\n",
       "      <td>0.119376</td>\n",
       "      <td>0.192166</td>\n",
       "      <td>0.382296</td>\n",
       "      <td>0.329788</td>\n",
       "      <td>0.024349</td>\n",
       "      <td>0.181619</td>\n",
       "      <td>0.196882</td>\n",
       "      <td>0.373459</td>\n",
       "      <td>0.124085</td>\n",
       "      <td>0.166430</td>\n",
       "      <td>0.277997</td>\n",
       "      <td>0.043119</td>\n",
       "      <td>0.220648</td>\n",
       "      <td>0.204421</td>\n",
       "      <td>-0.105685</td>\n",
       "      <td>0.037251</td>\n",
       "      <td>0.216162</td>\n",
       "      <td>-0.022723</td>\n",
       "      <td>0.271292</td>\n",
       "      <td>0.247559</td>\n",
       "      <td>0.107527</td>\n",
       "      <td>0.374333</td>\n",
       "      <td>0.029015</td>\n",
       "      <td>0.163585</td>\n",
       "      <td>0.096278</td>\n",
       "      <td>0.350617</td>\n",
       "      <td>0.363182</td>\n",
       "      <td>0.229370</td>\n",
       "      <td>0.093261</td>\n",
       "      <td>0.133573</td>\n",
       "      <td>0.063852</td>\n",
       "      <td>0.277432</td>\n",
       "      <td>0.157316</td>\n",
       "      <td>0.230695</td>\n",
       "      <td>0.266239</td>\n",
       "      <td>0.479107</td>\n",
       "      <td>0.133082</td>\n",
       "      <td>0.159430</td>\n",
       "      <td>0.302525</td>\n",
       "      <td>0.470409</td>\n",
       "      <td>0.054221</td>\n",
       "      <td>0.205163</td>\n",
       "      <td>0.486732</td>\n",
       "      <td>0.371827</td>\n",
       "      <td>0.348605</td>\n",
       "      <td>0.306989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.261501</td>\n",
       "      <td>0.209623</td>\n",
       "      <td>-0.020533</td>\n",
       "      <td>0.187423</td>\n",
       "      <td>0.120617</td>\n",
       "      <td>0.233983</td>\n",
       "      <td>0.420320</td>\n",
       "      <td>0.407405</td>\n",
       "      <td>0.040060</td>\n",
       "      <td>0.275832</td>\n",
       "      <td>0.209819</td>\n",
       "      <td>0.477809</td>\n",
       "      <td>0.213916</td>\n",
       "      <td>0.239012</td>\n",
       "      <td>0.358995</td>\n",
       "      <td>0.057843</td>\n",
       "      <td>0.269562</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.069818</td>\n",
       "      <td>0.114976</td>\n",
       "      <td>0.161174</td>\n",
       "      <td>0.147619</td>\n",
       "      <td>0.422885</td>\n",
       "      <td>0.207396</td>\n",
       "      <td>0.146352</td>\n",
       "      <td>0.533854</td>\n",
       "      <td>0.100411</td>\n",
       "      <td>0.262730</td>\n",
       "      <td>0.150257</td>\n",
       "      <td>0.390128</td>\n",
       "      <td>0.442671</td>\n",
       "      <td>0.266943</td>\n",
       "      <td>0.234756</td>\n",
       "      <td>0.246949</td>\n",
       "      <td>0.187679</td>\n",
       "      <td>0.440953</td>\n",
       "      <td>0.263325</td>\n",
       "      <td>0.313323</td>\n",
       "      <td>0.342350</td>\n",
       "      <td>0.593628</td>\n",
       "      <td>0.254613</td>\n",
       "      <td>0.202466</td>\n",
       "      <td>0.324053</td>\n",
       "      <td>0.551838</td>\n",
       "      <td>0.177812</td>\n",
       "      <td>0.307054</td>\n",
       "      <td>0.570551</td>\n",
       "      <td>0.412120</td>\n",
       "      <td>0.477947</td>\n",
       "      <td>0.423327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.126617</td>\n",
       "      <td>0.112898</td>\n",
       "      <td>-0.134353</td>\n",
       "      <td>0.194511</td>\n",
       "      <td>0.118138</td>\n",
       "      <td>0.211480</td>\n",
       "      <td>0.354434</td>\n",
       "      <td>0.415182</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>0.253663</td>\n",
       "      <td>0.250597</td>\n",
       "      <td>0.439696</td>\n",
       "      <td>0.188176</td>\n",
       "      <td>0.177375</td>\n",
       "      <td>0.408374</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>0.230863</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.015781</td>\n",
       "      <td>0.102055</td>\n",
       "      <td>0.179922</td>\n",
       "      <td>0.152159</td>\n",
       "      <td>0.297564</td>\n",
       "      <td>0.239999</td>\n",
       "      <td>0.152014</td>\n",
       "      <td>0.473269</td>\n",
       "      <td>0.051872</td>\n",
       "      <td>0.236091</td>\n",
       "      <td>0.135018</td>\n",
       "      <td>0.355663</td>\n",
       "      <td>0.437818</td>\n",
       "      <td>0.304368</td>\n",
       "      <td>0.187621</td>\n",
       "      <td>0.209235</td>\n",
       "      <td>0.127028</td>\n",
       "      <td>0.454831</td>\n",
       "      <td>0.314650</td>\n",
       "      <td>0.238989</td>\n",
       "      <td>0.297532</td>\n",
       "      <td>0.583372</td>\n",
       "      <td>0.162772</td>\n",
       "      <td>0.269670</td>\n",
       "      <td>0.279823</td>\n",
       "      <td>0.579756</td>\n",
       "      <td>0.123660</td>\n",
       "      <td>0.234813</td>\n",
       "      <td>0.516528</td>\n",
       "      <td>0.477458</td>\n",
       "      <td>0.457738</td>\n",
       "      <td>0.410230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.115669</td>\n",
       "      <td>0.095581</td>\n",
       "      <td>-0.186018</td>\n",
       "      <td>0.171120</td>\n",
       "      <td>0.178077</td>\n",
       "      <td>0.162684</td>\n",
       "      <td>0.376077</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.016078</td>\n",
       "      <td>0.183161</td>\n",
       "      <td>0.338651</td>\n",
       "      <td>0.400229</td>\n",
       "      <td>0.158054</td>\n",
       "      <td>0.160862</td>\n",
       "      <td>0.345718</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>0.260063</td>\n",
       "      <td>0.340603</td>\n",
       "      <td>-0.003565</td>\n",
       "      <td>0.007383</td>\n",
       "      <td>0.216943</td>\n",
       "      <td>0.089185</td>\n",
       "      <td>0.290593</td>\n",
       "      <td>0.218347</td>\n",
       "      <td>0.066858</td>\n",
       "      <td>0.390655</td>\n",
       "      <td>0.048444</td>\n",
       "      <td>0.266986</td>\n",
       "      <td>0.196182</td>\n",
       "      <td>0.308119</td>\n",
       "      <td>0.524469</td>\n",
       "      <td>0.241770</td>\n",
       "      <td>0.139985</td>\n",
       "      <td>0.238607</td>\n",
       "      <td>0.099209</td>\n",
       "      <td>0.392879</td>\n",
       "      <td>0.288608</td>\n",
       "      <td>0.247603</td>\n",
       "      <td>0.327748</td>\n",
       "      <td>0.647989</td>\n",
       "      <td>0.104407</td>\n",
       "      <td>0.204441</td>\n",
       "      <td>0.285627</td>\n",
       "      <td>0.566049</td>\n",
       "      <td>0.147020</td>\n",
       "      <td>0.244477</td>\n",
       "      <td>0.515074</td>\n",
       "      <td>0.439262</td>\n",
       "      <td>0.349563</td>\n",
       "      <td>0.406612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.038328</td>\n",
       "      <td>0.045418</td>\n",
       "      <td>-0.165224</td>\n",
       "      <td>0.182389</td>\n",
       "      <td>0.154289</td>\n",
       "      <td>0.119844</td>\n",
       "      <td>0.298279</td>\n",
       "      <td>0.299123</td>\n",
       "      <td>-0.106252</td>\n",
       "      <td>0.163446</td>\n",
       "      <td>0.287102</td>\n",
       "      <td>0.308370</td>\n",
       "      <td>0.106916</td>\n",
       "      <td>0.090034</td>\n",
       "      <td>0.340154</td>\n",
       "      <td>-0.039969</td>\n",
       "      <td>0.136596</td>\n",
       "      <td>0.341631</td>\n",
       "      <td>-0.170410</td>\n",
       "      <td>-0.084060</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.083343</td>\n",
       "      <td>0.225649</td>\n",
       "      <td>0.239273</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.396628</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>0.262457</td>\n",
       "      <td>0.090530</td>\n",
       "      <td>0.306694</td>\n",
       "      <td>0.415797</td>\n",
       "      <td>0.182399</td>\n",
       "      <td>0.214067</td>\n",
       "      <td>0.182271</td>\n",
       "      <td>0.079623</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.162925</td>\n",
       "      <td>0.284192</td>\n",
       "      <td>0.210192</td>\n",
       "      <td>0.685010</td>\n",
       "      <td>0.156286</td>\n",
       "      <td>0.127775</td>\n",
       "      <td>0.148779</td>\n",
       "      <td>0.494828</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.223620</td>\n",
       "      <td>0.456602</td>\n",
       "      <td>0.440597</td>\n",
       "      <td>0.398329</td>\n",
       "      <td>0.347064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.000049</td>\n",
       "      <td>-0.087980</td>\n",
       "      <td>-0.249652</td>\n",
       "      <td>0.107834</td>\n",
       "      <td>0.067670</td>\n",
       "      <td>0.024569</td>\n",
       "      <td>0.231282</td>\n",
       "      <td>0.280085</td>\n",
       "      <td>-0.216353</td>\n",
       "      <td>0.105581</td>\n",
       "      <td>0.270153</td>\n",
       "      <td>0.276174</td>\n",
       "      <td>0.057206</td>\n",
       "      <td>-0.003538</td>\n",
       "      <td>0.247633</td>\n",
       "      <td>-0.193673</td>\n",
       "      <td>-0.012859</td>\n",
       "      <td>0.194574</td>\n",
       "      <td>-0.186651</td>\n",
       "      <td>-0.218310</td>\n",
       "      <td>0.029517</td>\n",
       "      <td>-0.032846</td>\n",
       "      <td>0.192564</td>\n",
       "      <td>0.183968</td>\n",
       "      <td>-0.130574</td>\n",
       "      <td>0.329455</td>\n",
       "      <td>-0.225589</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>0.046650</td>\n",
       "      <td>0.241180</td>\n",
       "      <td>0.316007</td>\n",
       "      <td>0.158407</td>\n",
       "      <td>0.128242</td>\n",
       "      <td>0.179664</td>\n",
       "      <td>-0.030965</td>\n",
       "      <td>0.137689</td>\n",
       "      <td>0.117759</td>\n",
       "      <td>0.239213</td>\n",
       "      <td>0.109727</td>\n",
       "      <td>0.535766</td>\n",
       "      <td>0.041367</td>\n",
       "      <td>0.161521</td>\n",
       "      <td>0.171382</td>\n",
       "      <td>0.516808</td>\n",
       "      <td>0.014412</td>\n",
       "      <td>0.043070</td>\n",
       "      <td>0.495604</td>\n",
       "      <td>0.329570</td>\n",
       "      <td>0.336816</td>\n",
       "      <td>0.294753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.074688</td>\n",
       "      <td>-0.237860</td>\n",
       "      <td>-0.241578</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.052596</td>\n",
       "      <td>-0.040789</td>\n",
       "      <td>0.184230</td>\n",
       "      <td>0.185114</td>\n",
       "      <td>-0.232827</td>\n",
       "      <td>-0.055294</td>\n",
       "      <td>0.208907</td>\n",
       "      <td>0.194934</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>-0.012432</td>\n",
       "      <td>0.153190</td>\n",
       "      <td>-0.302165</td>\n",
       "      <td>-0.001414</td>\n",
       "      <td>0.207016</td>\n",
       "      <td>-0.135902</td>\n",
       "      <td>-0.286887</td>\n",
       "      <td>0.080874</td>\n",
       "      <td>-0.023585</td>\n",
       "      <td>0.090958</td>\n",
       "      <td>0.172126</td>\n",
       "      <td>-0.190911</td>\n",
       "      <td>0.330125</td>\n",
       "      <td>-0.188968</td>\n",
       "      <td>0.096930</td>\n",
       "      <td>-0.071116</td>\n",
       "      <td>0.230175</td>\n",
       "      <td>0.316966</td>\n",
       "      <td>0.135409</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.181828</td>\n",
       "      <td>-0.144101</td>\n",
       "      <td>0.057542</td>\n",
       "      <td>0.088797</td>\n",
       "      <td>-0.008297</td>\n",
       "      <td>0.097756</td>\n",
       "      <td>0.490016</td>\n",
       "      <td>-0.064452</td>\n",
       "      <td>0.028102</td>\n",
       "      <td>-0.037702</td>\n",
       "      <td>0.396132</td>\n",
       "      <td>0.012434</td>\n",
       "      <td>0.054706</td>\n",
       "      <td>0.326202</td>\n",
       "      <td>0.209781</td>\n",
       "      <td>0.323230</td>\n",
       "      <td>0.149619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-0.065862</td>\n",
       "      <td>-0.282193</td>\n",
       "      <td>-0.335128</td>\n",
       "      <td>-0.067223</td>\n",
       "      <td>0.111335</td>\n",
       "      <td>0.039531</td>\n",
       "      <td>0.294426</td>\n",
       "      <td>0.228230</td>\n",
       "      <td>-0.126687</td>\n",
       "      <td>0.017197</td>\n",
       "      <td>0.180796</td>\n",
       "      <td>0.222381</td>\n",
       "      <td>0.069607</td>\n",
       "      <td>-0.029327</td>\n",
       "      <td>0.227664</td>\n",
       "      <td>-0.300895</td>\n",
       "      <td>0.015381</td>\n",
       "      <td>0.212895</td>\n",
       "      <td>-0.116654</td>\n",
       "      <td>-0.225244</td>\n",
       "      <td>0.050365</td>\n",
       "      <td>0.022652</td>\n",
       "      <td>0.079209</td>\n",
       "      <td>0.272709</td>\n",
       "      <td>-0.143354</td>\n",
       "      <td>0.257423</td>\n",
       "      <td>-0.253761</td>\n",
       "      <td>0.179367</td>\n",
       "      <td>-0.004948</td>\n",
       "      <td>0.254156</td>\n",
       "      <td>0.459136</td>\n",
       "      <td>0.245930</td>\n",
       "      <td>0.062210</td>\n",
       "      <td>0.290411</td>\n",
       "      <td>-0.051059</td>\n",
       "      <td>0.155376</td>\n",
       "      <td>0.081191</td>\n",
       "      <td>0.111885</td>\n",
       "      <td>0.055379</td>\n",
       "      <td>0.612643</td>\n",
       "      <td>0.047436</td>\n",
       "      <td>0.071143</td>\n",
       "      <td>-0.017917</td>\n",
       "      <td>0.526589</td>\n",
       "      <td>0.048834</td>\n",
       "      <td>0.049331</td>\n",
       "      <td>0.306036</td>\n",
       "      <td>0.321707</td>\n",
       "      <td>0.326683</td>\n",
       "      <td>0.165981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-0.076830</td>\n",
       "      <td>-0.130516</td>\n",
       "      <td>-0.320829</td>\n",
       "      <td>-0.017380</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.069318</td>\n",
       "      <td>0.312470</td>\n",
       "      <td>0.134519</td>\n",
       "      <td>-0.135219</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>0.192897</td>\n",
       "      <td>0.290739</td>\n",
       "      <td>-0.011786</td>\n",
       "      <td>-0.032248</td>\n",
       "      <td>0.224480</td>\n",
       "      <td>-0.283836</td>\n",
       "      <td>0.033439</td>\n",
       "      <td>0.132340</td>\n",
       "      <td>-0.131370</td>\n",
       "      <td>-0.214970</td>\n",
       "      <td>0.088088</td>\n",
       "      <td>-0.022401</td>\n",
       "      <td>0.046903</td>\n",
       "      <td>0.260029</td>\n",
       "      <td>-0.174534</td>\n",
       "      <td>0.192489</td>\n",
       "      <td>-0.310312</td>\n",
       "      <td>0.266621</td>\n",
       "      <td>-0.056839</td>\n",
       "      <td>0.304380</td>\n",
       "      <td>0.433753</td>\n",
       "      <td>0.223684</td>\n",
       "      <td>-0.026599</td>\n",
       "      <td>0.347986</td>\n",
       "      <td>-0.099427</td>\n",
       "      <td>0.093606</td>\n",
       "      <td>-0.018608</td>\n",
       "      <td>0.129297</td>\n",
       "      <td>0.053738</td>\n",
       "      <td>0.669140</td>\n",
       "      <td>0.030576</td>\n",
       "      <td>0.098062</td>\n",
       "      <td>-0.040896</td>\n",
       "      <td>0.525648</td>\n",
       "      <td>0.137194</td>\n",
       "      <td>-0.028719</td>\n",
       "      <td>0.502395</td>\n",
       "      <td>0.376029</td>\n",
       "      <td>0.401021</td>\n",
       "      <td>0.214729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.063256</td>\n",
       "      <td>-0.114401</td>\n",
       "      <td>-0.266884</td>\n",
       "      <td>-0.004511</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>0.138579</td>\n",
       "      <td>0.332169</td>\n",
       "      <td>0.232928</td>\n",
       "      <td>-0.086077</td>\n",
       "      <td>0.110410</td>\n",
       "      <td>0.221553</td>\n",
       "      <td>0.294135</td>\n",
       "      <td>-0.023490</td>\n",
       "      <td>0.082489</td>\n",
       "      <td>0.198593</td>\n",
       "      <td>-0.256112</td>\n",
       "      <td>0.086844</td>\n",
       "      <td>0.214365</td>\n",
       "      <td>-0.167833</td>\n",
       "      <td>-0.203541</td>\n",
       "      <td>0.117047</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.093922</td>\n",
       "      <td>0.338975</td>\n",
       "      <td>-0.170080</td>\n",
       "      <td>0.329439</td>\n",
       "      <td>-0.333262</td>\n",
       "      <td>0.289695</td>\n",
       "      <td>0.066933</td>\n",
       "      <td>0.361100</td>\n",
       "      <td>0.375435</td>\n",
       "      <td>0.268118</td>\n",
       "      <td>-0.011477</td>\n",
       "      <td>0.386209</td>\n",
       "      <td>-0.087392</td>\n",
       "      <td>0.154548</td>\n",
       "      <td>-0.048739</td>\n",
       "      <td>0.183692</td>\n",
       "      <td>0.108284</td>\n",
       "      <td>0.686909</td>\n",
       "      <td>0.120299</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>-0.006110</td>\n",
       "      <td>0.630140</td>\n",
       "      <td>-0.033322</td>\n",
       "      <td>0.070278</td>\n",
       "      <td>0.547994</td>\n",
       "      <td>0.474078</td>\n",
       "      <td>0.501910</td>\n",
       "      <td>0.262495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.129363</td>\n",
       "      <td>-0.118152</td>\n",
       "      <td>-0.184310</td>\n",
       "      <td>0.044556</td>\n",
       "      <td>0.298683</td>\n",
       "      <td>0.315979</td>\n",
       "      <td>0.562805</td>\n",
       "      <td>0.452498</td>\n",
       "      <td>0.057792</td>\n",
       "      <td>0.298391</td>\n",
       "      <td>0.236111</td>\n",
       "      <td>0.456461</td>\n",
       "      <td>0.181523</td>\n",
       "      <td>0.260428</td>\n",
       "      <td>0.416620</td>\n",
       "      <td>-0.062598</td>\n",
       "      <td>0.305420</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.069247</td>\n",
       "      <td>0.007621</td>\n",
       "      <td>0.448820</td>\n",
       "      <td>0.282278</td>\n",
       "      <td>0.137065</td>\n",
       "      <td>0.308975</td>\n",
       "      <td>-0.003428</td>\n",
       "      <td>0.383065</td>\n",
       "      <td>-0.059154</td>\n",
       "      <td>0.443320</td>\n",
       "      <td>0.342347</td>\n",
       "      <td>0.527526</td>\n",
       "      <td>0.583632</td>\n",
       "      <td>0.386762</td>\n",
       "      <td>0.063460</td>\n",
       "      <td>0.597127</td>\n",
       "      <td>0.026536</td>\n",
       "      <td>0.491686</td>\n",
       "      <td>0.227154</td>\n",
       "      <td>0.359230</td>\n",
       "      <td>0.263846</td>\n",
       "      <td>0.826286</td>\n",
       "      <td>0.169168</td>\n",
       "      <td>0.149575</td>\n",
       "      <td>0.161518</td>\n",
       "      <td>0.787915</td>\n",
       "      <td>0.035719</td>\n",
       "      <td>0.187524</td>\n",
       "      <td>0.740466</td>\n",
       "      <td>0.563273</td>\n",
       "      <td>0.624715</td>\n",
       "      <td>0.476326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.251120</td>\n",
       "      <td>-0.009689</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>0.175504</td>\n",
       "      <td>0.363160</td>\n",
       "      <td>0.471729</td>\n",
       "      <td>0.666759</td>\n",
       "      <td>0.444359</td>\n",
       "      <td>0.252108</td>\n",
       "      <td>0.299098</td>\n",
       "      <td>0.298665</td>\n",
       "      <td>0.558421</td>\n",
       "      <td>0.147990</td>\n",
       "      <td>0.469864</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>0.104035</td>\n",
       "      <td>0.352197</td>\n",
       "      <td>0.488056</td>\n",
       "      <td>0.198769</td>\n",
       "      <td>0.103764</td>\n",
       "      <td>0.575307</td>\n",
       "      <td>0.512826</td>\n",
       "      <td>0.294995</td>\n",
       "      <td>0.282081</td>\n",
       "      <td>0.186450</td>\n",
       "      <td>0.474745</td>\n",
       "      <td>-0.068999</td>\n",
       "      <td>0.735142</td>\n",
       "      <td>0.387640</td>\n",
       "      <td>0.689479</td>\n",
       "      <td>0.719612</td>\n",
       "      <td>0.544675</td>\n",
       "      <td>0.216488</td>\n",
       "      <td>0.607238</td>\n",
       "      <td>0.229327</td>\n",
       "      <td>0.652452</td>\n",
       "      <td>0.275465</td>\n",
       "      <td>0.418086</td>\n",
       "      <td>0.351705</td>\n",
       "      <td>0.962605</td>\n",
       "      <td>0.159046</td>\n",
       "      <td>0.160367</td>\n",
       "      <td>0.109876</td>\n",
       "      <td>0.757280</td>\n",
       "      <td>0.175538</td>\n",
       "      <td>0.383550</td>\n",
       "      <td>0.710439</td>\n",
       "      <td>0.728924</td>\n",
       "      <td>0.703565</td>\n",
       "      <td>0.549702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.427792</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>0.145848</td>\n",
       "      <td>0.225138</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.605141</td>\n",
       "      <td>0.819142</td>\n",
       "      <td>0.377721</td>\n",
       "      <td>0.397509</td>\n",
       "      <td>0.455313</td>\n",
       "      <td>0.452775</td>\n",
       "      <td>0.487407</td>\n",
       "      <td>0.257942</td>\n",
       "      <td>0.517118</td>\n",
       "      <td>0.654881</td>\n",
       "      <td>0.174017</td>\n",
       "      <td>0.378032</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>0.162722</td>\n",
       "      <td>0.230643</td>\n",
       "      <td>0.584960</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.314550</td>\n",
       "      <td>0.303369</td>\n",
       "      <td>0.222916</td>\n",
       "      <td>0.559837</td>\n",
       "      <td>-0.011303</td>\n",
       "      <td>0.790401</td>\n",
       "      <td>0.587333</td>\n",
       "      <td>0.796219</td>\n",
       "      <td>0.644682</td>\n",
       "      <td>0.468712</td>\n",
       "      <td>0.268359</td>\n",
       "      <td>0.691825</td>\n",
       "      <td>0.361905</td>\n",
       "      <td>0.774292</td>\n",
       "      <td>0.445634</td>\n",
       "      <td>0.595381</td>\n",
       "      <td>0.407728</td>\n",
       "      <td>1.004600</td>\n",
       "      <td>0.267915</td>\n",
       "      <td>0.274232</td>\n",
       "      <td>0.323047</td>\n",
       "      <td>0.990006</td>\n",
       "      <td>0.135232</td>\n",
       "      <td>0.433452</td>\n",
       "      <td>0.936919</td>\n",
       "      <td>0.776300</td>\n",
       "      <td>0.927966</td>\n",
       "      <td>0.688747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.432496</td>\n",
       "      <td>-0.049455</td>\n",
       "      <td>0.259924</td>\n",
       "      <td>0.264217</td>\n",
       "      <td>0.428149</td>\n",
       "      <td>0.773973</td>\n",
       "      <td>0.948736</td>\n",
       "      <td>0.489221</td>\n",
       "      <td>0.383428</td>\n",
       "      <td>0.523475</td>\n",
       "      <td>0.589762</td>\n",
       "      <td>0.618416</td>\n",
       "      <td>0.170393</td>\n",
       "      <td>0.568347</td>\n",
       "      <td>0.719403</td>\n",
       "      <td>0.237492</td>\n",
       "      <td>0.342650</td>\n",
       "      <td>0.674513</td>\n",
       "      <td>0.251111</td>\n",
       "      <td>0.235644</td>\n",
       "      <td>0.708350</td>\n",
       "      <td>0.538092</td>\n",
       "      <td>0.386183</td>\n",
       "      <td>0.325228</td>\n",
       "      <td>0.235533</td>\n",
       "      <td>0.591923</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.857094</td>\n",
       "      <td>0.701115</td>\n",
       "      <td>0.879994</td>\n",
       "      <td>0.677179</td>\n",
       "      <td>0.640274</td>\n",
       "      <td>0.279345</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.297550</td>\n",
       "      <td>0.708833</td>\n",
       "      <td>0.515985</td>\n",
       "      <td>0.520283</td>\n",
       "      <td>0.427728</td>\n",
       "      <td>0.968420</td>\n",
       "      <td>0.261640</td>\n",
       "      <td>0.301907</td>\n",
       "      <td>0.384475</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>0.233392</td>\n",
       "      <td>0.546356</td>\n",
       "      <td>1.029085</td>\n",
       "      <td>0.732486</td>\n",
       "      <td>1.018149</td>\n",
       "      <td>0.672520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.645435</td>\n",
       "      <td>0.027889</td>\n",
       "      <td>0.299346</td>\n",
       "      <td>0.185867</td>\n",
       "      <td>0.577934</td>\n",
       "      <td>0.683297</td>\n",
       "      <td>0.948945</td>\n",
       "      <td>0.729909</td>\n",
       "      <td>0.468352</td>\n",
       "      <td>0.650926</td>\n",
       "      <td>0.535800</td>\n",
       "      <td>0.550536</td>\n",
       "      <td>0.343096</td>\n",
       "      <td>0.547598</td>\n",
       "      <td>0.666145</td>\n",
       "      <td>0.326516</td>\n",
       "      <td>0.338305</td>\n",
       "      <td>0.636876</td>\n",
       "      <td>0.425427</td>\n",
       "      <td>0.179918</td>\n",
       "      <td>0.725300</td>\n",
       "      <td>0.569004</td>\n",
       "      <td>0.522818</td>\n",
       "      <td>0.399519</td>\n",
       "      <td>0.236081</td>\n",
       "      <td>0.759188</td>\n",
       "      <td>0.173672</td>\n",
       "      <td>0.719584</td>\n",
       "      <td>0.763612</td>\n",
       "      <td>0.918375</td>\n",
       "      <td>0.642244</td>\n",
       "      <td>0.640246</td>\n",
       "      <td>0.412624</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.503092</td>\n",
       "      <td>0.830205</td>\n",
       "      <td>0.499130</td>\n",
       "      <td>0.653146</td>\n",
       "      <td>0.460253</td>\n",
       "      <td>0.958566</td>\n",
       "      <td>0.441767</td>\n",
       "      <td>0.315008</td>\n",
       "      <td>0.434391</td>\n",
       "      <td>1.038088</td>\n",
       "      <td>0.273456</td>\n",
       "      <td>0.623992</td>\n",
       "      <td>0.926662</td>\n",
       "      <td>0.698786</td>\n",
       "      <td>1.092783</td>\n",
       "      <td>0.727346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.731511</td>\n",
       "      <td>0.027617</td>\n",
       "      <td>0.334726</td>\n",
       "      <td>0.419937</td>\n",
       "      <td>0.617568</td>\n",
       "      <td>0.886158</td>\n",
       "      <td>1.030034</td>\n",
       "      <td>0.852172</td>\n",
       "      <td>0.552298</td>\n",
       "      <td>0.539232</td>\n",
       "      <td>0.698426</td>\n",
       "      <td>0.655720</td>\n",
       "      <td>0.443543</td>\n",
       "      <td>0.650264</td>\n",
       "      <td>0.884753</td>\n",
       "      <td>0.494539</td>\n",
       "      <td>0.291224</td>\n",
       "      <td>0.658520</td>\n",
       "      <td>0.614026</td>\n",
       "      <td>0.355676</td>\n",
       "      <td>0.785687</td>\n",
       "      <td>0.703598</td>\n",
       "      <td>0.453851</td>\n",
       "      <td>0.410535</td>\n",
       "      <td>0.368355</td>\n",
       "      <td>0.761181</td>\n",
       "      <td>0.256161</td>\n",
       "      <td>0.762041</td>\n",
       "      <td>0.816562</td>\n",
       "      <td>1.005298</td>\n",
       "      <td>0.765106</td>\n",
       "      <td>0.818629</td>\n",
       "      <td>0.512736</td>\n",
       "      <td>0.825357</td>\n",
       "      <td>0.710951</td>\n",
       "      <td>0.759335</td>\n",
       "      <td>0.611559</td>\n",
       "      <td>0.574051</td>\n",
       "      <td>0.510731</td>\n",
       "      <td>0.986930</td>\n",
       "      <td>0.528847</td>\n",
       "      <td>0.471746</td>\n",
       "      <td>0.420347</td>\n",
       "      <td>1.011146</td>\n",
       "      <td>0.419572</td>\n",
       "      <td>0.584572</td>\n",
       "      <td>0.964626</td>\n",
       "      <td>0.811801</td>\n",
       "      <td>1.093010</td>\n",
       "      <td>0.647061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.653323</td>\n",
       "      <td>0.155283</td>\n",
       "      <td>0.340502</td>\n",
       "      <td>0.347349</td>\n",
       "      <td>0.493239</td>\n",
       "      <td>0.742252</td>\n",
       "      <td>0.871831</td>\n",
       "      <td>0.716868</td>\n",
       "      <td>0.518277</td>\n",
       "      <td>0.504939</td>\n",
       "      <td>0.648966</td>\n",
       "      <td>0.503269</td>\n",
       "      <td>0.475469</td>\n",
       "      <td>0.489889</td>\n",
       "      <td>0.795440</td>\n",
       "      <td>0.394902</td>\n",
       "      <td>0.188715</td>\n",
       "      <td>0.634860</td>\n",
       "      <td>0.441845</td>\n",
       "      <td>0.181569</td>\n",
       "      <td>0.554260</td>\n",
       "      <td>0.440779</td>\n",
       "      <td>0.441820</td>\n",
       "      <td>0.358041</td>\n",
       "      <td>0.237754</td>\n",
       "      <td>0.692157</td>\n",
       "      <td>0.080627</td>\n",
       "      <td>0.730315</td>\n",
       "      <td>0.673089</td>\n",
       "      <td>0.890134</td>\n",
       "      <td>0.605834</td>\n",
       "      <td>0.718989</td>\n",
       "      <td>0.328779</td>\n",
       "      <td>0.645234</td>\n",
       "      <td>0.546608</td>\n",
       "      <td>0.700410</td>\n",
       "      <td>0.466780</td>\n",
       "      <td>0.560387</td>\n",
       "      <td>0.446124</td>\n",
       "      <td>0.855859</td>\n",
       "      <td>0.486068</td>\n",
       "      <td>0.369748</td>\n",
       "      <td>0.338829</td>\n",
       "      <td>0.866177</td>\n",
       "      <td>0.424892</td>\n",
       "      <td>0.546112</td>\n",
       "      <td>0.808299</td>\n",
       "      <td>0.777177</td>\n",
       "      <td>1.015281</td>\n",
       "      <td>0.613944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.540177</td>\n",
       "      <td>0.127168</td>\n",
       "      <td>0.177339</td>\n",
       "      <td>0.329594</td>\n",
       "      <td>0.510804</td>\n",
       "      <td>0.645280</td>\n",
       "      <td>0.860413</td>\n",
       "      <td>0.768017</td>\n",
       "      <td>0.454190</td>\n",
       "      <td>0.431523</td>\n",
       "      <td>0.573306</td>\n",
       "      <td>0.507160</td>\n",
       "      <td>0.354401</td>\n",
       "      <td>0.415357</td>\n",
       "      <td>0.758171</td>\n",
       "      <td>0.376423</td>\n",
       "      <td>0.244202</td>\n",
       "      <td>0.615304</td>\n",
       "      <td>0.453764</td>\n",
       "      <td>0.240648</td>\n",
       "      <td>0.551837</td>\n",
       "      <td>0.392100</td>\n",
       "      <td>0.376327</td>\n",
       "      <td>0.416131</td>\n",
       "      <td>0.223059</td>\n",
       "      <td>0.701385</td>\n",
       "      <td>0.195049</td>\n",
       "      <td>0.590684</td>\n",
       "      <td>0.620224</td>\n",
       "      <td>0.852377</td>\n",
       "      <td>0.554346</td>\n",
       "      <td>0.628327</td>\n",
       "      <td>0.319027</td>\n",
       "      <td>0.649689</td>\n",
       "      <td>0.404341</td>\n",
       "      <td>0.628599</td>\n",
       "      <td>0.430781</td>\n",
       "      <td>0.436330</td>\n",
       "      <td>0.509544</td>\n",
       "      <td>0.770945</td>\n",
       "      <td>0.426720</td>\n",
       "      <td>0.376018</td>\n",
       "      <td>0.298030</td>\n",
       "      <td>0.840045</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.506241</td>\n",
       "      <td>0.829947</td>\n",
       "      <td>0.684722</td>\n",
       "      <td>0.937854</td>\n",
       "      <td>0.541729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.550843</td>\n",
       "      <td>0.169514</td>\n",
       "      <td>0.178027</td>\n",
       "      <td>0.361779</td>\n",
       "      <td>0.571700</td>\n",
       "      <td>0.634739</td>\n",
       "      <td>0.791566</td>\n",
       "      <td>0.844083</td>\n",
       "      <td>0.377910</td>\n",
       "      <td>0.453375</td>\n",
       "      <td>0.562732</td>\n",
       "      <td>0.627387</td>\n",
       "      <td>0.446985</td>\n",
       "      <td>0.523615</td>\n",
       "      <td>0.736818</td>\n",
       "      <td>0.313616</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>0.610211</td>\n",
       "      <td>0.470719</td>\n",
       "      <td>0.290408</td>\n",
       "      <td>0.583737</td>\n",
       "      <td>0.417487</td>\n",
       "      <td>0.410611</td>\n",
       "      <td>0.315682</td>\n",
       "      <td>0.312024</td>\n",
       "      <td>0.620656</td>\n",
       "      <td>0.139548</td>\n",
       "      <td>0.657768</td>\n",
       "      <td>0.525459</td>\n",
       "      <td>0.838796</td>\n",
       "      <td>0.564115</td>\n",
       "      <td>0.715795</td>\n",
       "      <td>0.385804</td>\n",
       "      <td>0.613085</td>\n",
       "      <td>0.387778</td>\n",
       "      <td>0.567778</td>\n",
       "      <td>0.379748</td>\n",
       "      <td>0.476731</td>\n",
       "      <td>0.458707</td>\n",
       "      <td>0.830171</td>\n",
       "      <td>0.366391</td>\n",
       "      <td>0.409321</td>\n",
       "      <td>0.350690</td>\n",
       "      <td>0.823635</td>\n",
       "      <td>0.417902</td>\n",
       "      <td>0.633355</td>\n",
       "      <td>0.758615</td>\n",
       "      <td>0.739372</td>\n",
       "      <td>0.859858</td>\n",
       "      <td>0.502252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.450493</td>\n",
       "      <td>0.205030</td>\n",
       "      <td>0.163388</td>\n",
       "      <td>0.379862</td>\n",
       "      <td>0.590442</td>\n",
       "      <td>0.527619</td>\n",
       "      <td>0.763699</td>\n",
       "      <td>0.828596</td>\n",
       "      <td>0.468224</td>\n",
       "      <td>0.307312</td>\n",
       "      <td>0.537819</td>\n",
       "      <td>0.608547</td>\n",
       "      <td>0.425488</td>\n",
       "      <td>0.435829</td>\n",
       "      <td>0.552461</td>\n",
       "      <td>0.311971</td>\n",
       "      <td>0.232068</td>\n",
       "      <td>0.539785</td>\n",
       "      <td>0.442470</td>\n",
       "      <td>0.350903</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>0.325753</td>\n",
       "      <td>0.225126</td>\n",
       "      <td>0.299862</td>\n",
       "      <td>0.225362</td>\n",
       "      <td>0.801622</td>\n",
       "      <td>0.175663</td>\n",
       "      <td>0.635923</td>\n",
       "      <td>0.479006</td>\n",
       "      <td>0.774473</td>\n",
       "      <td>0.495971</td>\n",
       "      <td>0.602479</td>\n",
       "      <td>0.346684</td>\n",
       "      <td>0.530464</td>\n",
       "      <td>0.455898</td>\n",
       "      <td>0.495429</td>\n",
       "      <td>0.329238</td>\n",
       "      <td>0.389939</td>\n",
       "      <td>0.416809</td>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.264276</td>\n",
       "      <td>0.380364</td>\n",
       "      <td>0.294030</td>\n",
       "      <td>0.803909</td>\n",
       "      <td>0.324134</td>\n",
       "      <td>0.550633</td>\n",
       "      <td>0.671626</td>\n",
       "      <td>0.649428</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.445027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.410042</td>\n",
       "      <td>0.134144</td>\n",
       "      <td>0.191325</td>\n",
       "      <td>0.445950</td>\n",
       "      <td>0.498748</td>\n",
       "      <td>0.582979</td>\n",
       "      <td>0.725865</td>\n",
       "      <td>0.585391</td>\n",
       "      <td>0.408426</td>\n",
       "      <td>0.198118</td>\n",
       "      <td>0.583074</td>\n",
       "      <td>0.598683</td>\n",
       "      <td>0.415132</td>\n",
       "      <td>0.452948</td>\n",
       "      <td>0.611850</td>\n",
       "      <td>0.181933</td>\n",
       "      <td>0.348222</td>\n",
       "      <td>0.590861</td>\n",
       "      <td>0.355012</td>\n",
       "      <td>0.410044</td>\n",
       "      <td>0.521039</td>\n",
       "      <td>0.382488</td>\n",
       "      <td>0.233841</td>\n",
       "      <td>0.114435</td>\n",
       "      <td>0.179769</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.732390</td>\n",
       "      <td>0.454586</td>\n",
       "      <td>0.725862</td>\n",
       "      <td>0.565967</td>\n",
       "      <td>0.564794</td>\n",
       "      <td>0.266289</td>\n",
       "      <td>0.537763</td>\n",
       "      <td>0.344605</td>\n",
       "      <td>0.437050</td>\n",
       "      <td>0.339358</td>\n",
       "      <td>0.380534</td>\n",
       "      <td>0.484948</td>\n",
       "      <td>0.800331</td>\n",
       "      <td>0.317920</td>\n",
       "      <td>0.318146</td>\n",
       "      <td>0.307008</td>\n",
       "      <td>0.763605</td>\n",
       "      <td>0.259671</td>\n",
       "      <td>0.524743</td>\n",
       "      <td>0.720530</td>\n",
       "      <td>0.693355</td>\n",
       "      <td>0.771372</td>\n",
       "      <td>0.402620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.355135</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>0.168009</td>\n",
       "      <td>0.254453</td>\n",
       "      <td>0.444263</td>\n",
       "      <td>0.520952</td>\n",
       "      <td>0.650190</td>\n",
       "      <td>0.638950</td>\n",
       "      <td>0.393521</td>\n",
       "      <td>0.196680</td>\n",
       "      <td>0.509478</td>\n",
       "      <td>0.582740</td>\n",
       "      <td>0.323506</td>\n",
       "      <td>0.428957</td>\n",
       "      <td>0.502316</td>\n",
       "      <td>0.116351</td>\n",
       "      <td>0.383532</td>\n",
       "      <td>0.525823</td>\n",
       "      <td>0.323461</td>\n",
       "      <td>0.282386</td>\n",
       "      <td>0.511636</td>\n",
       "      <td>0.441292</td>\n",
       "      <td>0.195092</td>\n",
       "      <td>0.206934</td>\n",
       "      <td>0.174265</td>\n",
       "      <td>0.636971</td>\n",
       "      <td>0.203826</td>\n",
       "      <td>0.786574</td>\n",
       "      <td>0.473486</td>\n",
       "      <td>0.696212</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>0.434208</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.389791</td>\n",
       "      <td>0.310553</td>\n",
       "      <td>0.501191</td>\n",
       "      <td>0.239298</td>\n",
       "      <td>0.302096</td>\n",
       "      <td>0.398948</td>\n",
       "      <td>0.741906</td>\n",
       "      <td>0.164693</td>\n",
       "      <td>0.266430</td>\n",
       "      <td>0.206162</td>\n",
       "      <td>0.716022</td>\n",
       "      <td>0.216543</td>\n",
       "      <td>0.432954</td>\n",
       "      <td>0.675316</td>\n",
       "      <td>0.591173</td>\n",
       "      <td>0.757972</td>\n",
       "      <td>0.457521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.371799</td>\n",
       "      <td>0.078531</td>\n",
       "      <td>0.056648</td>\n",
       "      <td>0.319930</td>\n",
       "      <td>0.449228</td>\n",
       "      <td>0.506252</td>\n",
       "      <td>0.672351</td>\n",
       "      <td>0.626087</td>\n",
       "      <td>0.336397</td>\n",
       "      <td>0.227441</td>\n",
       "      <td>0.466806</td>\n",
       "      <td>0.536561</td>\n",
       "      <td>0.222848</td>\n",
       "      <td>0.445115</td>\n",
       "      <td>0.461410</td>\n",
       "      <td>0.142464</td>\n",
       "      <td>0.396865</td>\n",
       "      <td>0.416947</td>\n",
       "      <td>0.317448</td>\n",
       "      <td>0.214240</td>\n",
       "      <td>0.468953</td>\n",
       "      <td>0.371018</td>\n",
       "      <td>0.269659</td>\n",
       "      <td>0.246433</td>\n",
       "      <td>0.188632</td>\n",
       "      <td>0.537165</td>\n",
       "      <td>0.277833</td>\n",
       "      <td>0.690402</td>\n",
       "      <td>0.411047</td>\n",
       "      <td>0.639858</td>\n",
       "      <td>0.446176</td>\n",
       "      <td>0.427221</td>\n",
       "      <td>0.246992</td>\n",
       "      <td>0.475032</td>\n",
       "      <td>0.283260</td>\n",
       "      <td>0.488303</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>0.267703</td>\n",
       "      <td>0.434198</td>\n",
       "      <td>0.799074</td>\n",
       "      <td>0.120420</td>\n",
       "      <td>0.291477</td>\n",
       "      <td>0.264606</td>\n",
       "      <td>0.761676</td>\n",
       "      <td>0.247811</td>\n",
       "      <td>0.426517</td>\n",
       "      <td>0.680524</td>\n",
       "      <td>0.561686</td>\n",
       "      <td>0.770253</td>\n",
       "      <td>0.413503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.148628</td>\n",
       "      <td>0.111801</td>\n",
       "      <td>0.302135</td>\n",
       "      <td>0.391321</td>\n",
       "      <td>0.557881</td>\n",
       "      <td>0.712781</td>\n",
       "      <td>0.620094</td>\n",
       "      <td>0.355353</td>\n",
       "      <td>0.322753</td>\n",
       "      <td>0.451941</td>\n",
       "      <td>0.489417</td>\n",
       "      <td>0.310851</td>\n",
       "      <td>0.452212</td>\n",
       "      <td>0.469516</td>\n",
       "      <td>0.190634</td>\n",
       "      <td>0.304952</td>\n",
       "      <td>0.409768</td>\n",
       "      <td>0.332938</td>\n",
       "      <td>0.230797</td>\n",
       "      <td>0.463954</td>\n",
       "      <td>0.461467</td>\n",
       "      <td>0.218030</td>\n",
       "      <td>0.271698</td>\n",
       "      <td>0.211097</td>\n",
       "      <td>0.602373</td>\n",
       "      <td>0.241022</td>\n",
       "      <td>0.675270</td>\n",
       "      <td>0.501252</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.445015</td>\n",
       "      <td>0.476123</td>\n",
       "      <td>0.215444</td>\n",
       "      <td>0.409835</td>\n",
       "      <td>0.397858</td>\n",
       "      <td>0.458661</td>\n",
       "      <td>0.101124</td>\n",
       "      <td>0.355529</td>\n",
       "      <td>0.376020</td>\n",
       "      <td>0.732055</td>\n",
       "      <td>0.149704</td>\n",
       "      <td>0.275623</td>\n",
       "      <td>0.240235</td>\n",
       "      <td>0.800615</td>\n",
       "      <td>0.259055</td>\n",
       "      <td>0.474554</td>\n",
       "      <td>0.635406</td>\n",
       "      <td>0.607779</td>\n",
       "      <td>0.737868</td>\n",
       "      <td>0.424015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.440235</td>\n",
       "      <td>0.134752</td>\n",
       "      <td>0.160970</td>\n",
       "      <td>0.266348</td>\n",
       "      <td>0.461098</td>\n",
       "      <td>0.613223</td>\n",
       "      <td>0.779891</td>\n",
       "      <td>0.583693</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>0.299508</td>\n",
       "      <td>0.417287</td>\n",
       "      <td>0.468878</td>\n",
       "      <td>0.283189</td>\n",
       "      <td>0.449302</td>\n",
       "      <td>0.530198</td>\n",
       "      <td>0.253528</td>\n",
       "      <td>0.354477</td>\n",
       "      <td>0.492180</td>\n",
       "      <td>0.345396</td>\n",
       "      <td>0.248476</td>\n",
       "      <td>0.449737</td>\n",
       "      <td>0.406320</td>\n",
       "      <td>0.294870</td>\n",
       "      <td>0.259616</td>\n",
       "      <td>0.237245</td>\n",
       "      <td>0.616881</td>\n",
       "      <td>0.231912</td>\n",
       "      <td>0.671559</td>\n",
       "      <td>0.440173</td>\n",
       "      <td>0.698625</td>\n",
       "      <td>0.486705</td>\n",
       "      <td>0.469019</td>\n",
       "      <td>0.174193</td>\n",
       "      <td>0.467478</td>\n",
       "      <td>0.334513</td>\n",
       "      <td>0.524454</td>\n",
       "      <td>0.188625</td>\n",
       "      <td>0.352918</td>\n",
       "      <td>0.428654</td>\n",
       "      <td>0.711913</td>\n",
       "      <td>0.216036</td>\n",
       "      <td>0.277792</td>\n",
       "      <td>0.245780</td>\n",
       "      <td>0.787603</td>\n",
       "      <td>0.254591</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>0.656272</td>\n",
       "      <td>0.579869</td>\n",
       "      <td>0.755292</td>\n",
       "      <td>0.518833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.375384</td>\n",
       "      <td>0.134247</td>\n",
       "      <td>0.064683</td>\n",
       "      <td>0.237875</td>\n",
       "      <td>0.333110</td>\n",
       "      <td>0.555581</td>\n",
       "      <td>0.675226</td>\n",
       "      <td>0.502286</td>\n",
       "      <td>0.301345</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>0.391856</td>\n",
       "      <td>0.466215</td>\n",
       "      <td>0.245626</td>\n",
       "      <td>0.328557</td>\n",
       "      <td>0.618325</td>\n",
       "      <td>0.141313</td>\n",
       "      <td>0.283012</td>\n",
       "      <td>0.408491</td>\n",
       "      <td>0.255798</td>\n",
       "      <td>0.150438</td>\n",
       "      <td>0.464946</td>\n",
       "      <td>0.393988</td>\n",
       "      <td>0.309444</td>\n",
       "      <td>0.318603</td>\n",
       "      <td>0.176249</td>\n",
       "      <td>0.622346</td>\n",
       "      <td>0.088207</td>\n",
       "      <td>0.594046</td>\n",
       "      <td>0.413437</td>\n",
       "      <td>0.694443</td>\n",
       "      <td>0.536697</td>\n",
       "      <td>0.451170</td>\n",
       "      <td>0.129794</td>\n",
       "      <td>0.355564</td>\n",
       "      <td>0.358540</td>\n",
       "      <td>0.485911</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>0.329572</td>\n",
       "      <td>0.352682</td>\n",
       "      <td>0.680823</td>\n",
       "      <td>0.214842</td>\n",
       "      <td>0.290159</td>\n",
       "      <td>0.194525</td>\n",
       "      <td>0.725700</td>\n",
       "      <td>0.197261</td>\n",
       "      <td>0.500395</td>\n",
       "      <td>0.694344</td>\n",
       "      <td>0.632177</td>\n",
       "      <td>0.775630</td>\n",
       "      <td>0.449919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.352291</td>\n",
       "      <td>0.177269</td>\n",
       "      <td>0.033638</td>\n",
       "      <td>0.218599</td>\n",
       "      <td>0.352150</td>\n",
       "      <td>0.484300</td>\n",
       "      <td>0.663605</td>\n",
       "      <td>0.580379</td>\n",
       "      <td>0.300572</td>\n",
       "      <td>0.299785</td>\n",
       "      <td>0.341885</td>\n",
       "      <td>0.416513</td>\n",
       "      <td>0.236834</td>\n",
       "      <td>0.317504</td>\n",
       "      <td>0.501193</td>\n",
       "      <td>0.143010</td>\n",
       "      <td>0.279859</td>\n",
       "      <td>0.315758</td>\n",
       "      <td>0.240825</td>\n",
       "      <td>0.109455</td>\n",
       "      <td>0.429027</td>\n",
       "      <td>0.350963</td>\n",
       "      <td>0.348782</td>\n",
       "      <td>0.370016</td>\n",
       "      <td>0.153112</td>\n",
       "      <td>0.555334</td>\n",
       "      <td>0.118780</td>\n",
       "      <td>0.481442</td>\n",
       "      <td>0.422012</td>\n",
       "      <td>0.700601</td>\n",
       "      <td>0.452701</td>\n",
       "      <td>0.400520</td>\n",
       "      <td>0.218185</td>\n",
       "      <td>0.291692</td>\n",
       "      <td>0.330662</td>\n",
       "      <td>0.498740</td>\n",
       "      <td>0.076782</td>\n",
       "      <td>0.299411</td>\n",
       "      <td>0.271141</td>\n",
       "      <td>0.709878</td>\n",
       "      <td>0.265979</td>\n",
       "      <td>0.287702</td>\n",
       "      <td>0.207082</td>\n",
       "      <td>0.726032</td>\n",
       "      <td>0.245248</td>\n",
       "      <td>0.522224</td>\n",
       "      <td>0.644992</td>\n",
       "      <td>0.560725</td>\n",
       "      <td>0.723855</td>\n",
       "      <td>0.487993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.212316</td>\n",
       "      <td>0.183916</td>\n",
       "      <td>0.010849</td>\n",
       "      <td>0.200531</td>\n",
       "      <td>0.354037</td>\n",
       "      <td>0.476189</td>\n",
       "      <td>0.539305</td>\n",
       "      <td>0.462062</td>\n",
       "      <td>0.209154</td>\n",
       "      <td>0.269202</td>\n",
       "      <td>0.341964</td>\n",
       "      <td>0.391065</td>\n",
       "      <td>0.192925</td>\n",
       "      <td>0.217464</td>\n",
       "      <td>0.464096</td>\n",
       "      <td>0.064293</td>\n",
       "      <td>0.176050</td>\n",
       "      <td>0.303656</td>\n",
       "      <td>0.136063</td>\n",
       "      <td>0.111042</td>\n",
       "      <td>0.389124</td>\n",
       "      <td>0.237506</td>\n",
       "      <td>0.250391</td>\n",
       "      <td>0.259349</td>\n",
       "      <td>0.049693</td>\n",
       "      <td>0.455441</td>\n",
       "      <td>-0.060549</td>\n",
       "      <td>0.371199</td>\n",
       "      <td>0.416701</td>\n",
       "      <td>0.562688</td>\n",
       "      <td>0.364592</td>\n",
       "      <td>0.359092</td>\n",
       "      <td>0.164912</td>\n",
       "      <td>0.314417</td>\n",
       "      <td>0.268178</td>\n",
       "      <td>0.416097</td>\n",
       "      <td>0.074257</td>\n",
       "      <td>0.331707</td>\n",
       "      <td>0.239158</td>\n",
       "      <td>0.675755</td>\n",
       "      <td>0.212378</td>\n",
       "      <td>0.223534</td>\n",
       "      <td>0.162234</td>\n",
       "      <td>0.642820</td>\n",
       "      <td>0.239308</td>\n",
       "      <td>0.419174</td>\n",
       "      <td>0.563699</td>\n",
       "      <td>0.554169</td>\n",
       "      <td>0.617220</td>\n",
       "      <td>0.334042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.050777</td>\n",
       "      <td>0.074348</td>\n",
       "      <td>-0.181897</td>\n",
       "      <td>0.126385</td>\n",
       "      <td>0.200468</td>\n",
       "      <td>0.324676</td>\n",
       "      <td>0.418355</td>\n",
       "      <td>0.348062</td>\n",
       "      <td>0.095623</td>\n",
       "      <td>0.189524</td>\n",
       "      <td>0.293168</td>\n",
       "      <td>0.209746</td>\n",
       "      <td>0.072617</td>\n",
       "      <td>0.125952</td>\n",
       "      <td>0.372574</td>\n",
       "      <td>-0.032602</td>\n",
       "      <td>0.074431</td>\n",
       "      <td>0.152314</td>\n",
       "      <td>0.050750</td>\n",
       "      <td>-0.047935</td>\n",
       "      <td>0.229171</td>\n",
       "      <td>0.051508</td>\n",
       "      <td>0.203651</td>\n",
       "      <td>0.255447</td>\n",
       "      <td>-0.073614</td>\n",
       "      <td>0.380030</td>\n",
       "      <td>-0.152123</td>\n",
       "      <td>0.250304</td>\n",
       "      <td>0.240008</td>\n",
       "      <td>0.474700</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.229442</td>\n",
       "      <td>0.071875</td>\n",
       "      <td>0.247848</td>\n",
       "      <td>0.173238</td>\n",
       "      <td>0.309547</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.240642</td>\n",
       "      <td>0.192954</td>\n",
       "      <td>0.561260</td>\n",
       "      <td>0.081849</td>\n",
       "      <td>0.126164</td>\n",
       "      <td>0.168853</td>\n",
       "      <td>0.567697</td>\n",
       "      <td>0.111853</td>\n",
       "      <td>0.218152</td>\n",
       "      <td>0.441338</td>\n",
       "      <td>0.422142</td>\n",
       "      <td>0.487484</td>\n",
       "      <td>0.243624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.011865</td>\n",
       "      <td>0.062157</td>\n",
       "      <td>-0.226055</td>\n",
       "      <td>0.158684</td>\n",
       "      <td>0.136097</td>\n",
       "      <td>0.269875</td>\n",
       "      <td>0.441153</td>\n",
       "      <td>0.291157</td>\n",
       "      <td>0.087147</td>\n",
       "      <td>0.153955</td>\n",
       "      <td>0.319744</td>\n",
       "      <td>0.307323</td>\n",
       "      <td>-0.046223</td>\n",
       "      <td>0.185424</td>\n",
       "      <td>0.399050</td>\n",
       "      <td>-0.069682</td>\n",
       "      <td>0.098887</td>\n",
       "      <td>0.146587</td>\n",
       "      <td>0.079765</td>\n",
       "      <td>-0.057666</td>\n",
       "      <td>0.214238</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.192028</td>\n",
       "      <td>0.285711</td>\n",
       "      <td>-0.020737</td>\n",
       "      <td>0.354523</td>\n",
       "      <td>-0.060765</td>\n",
       "      <td>0.291472</td>\n",
       "      <td>0.224325</td>\n",
       "      <td>0.462363</td>\n",
       "      <td>0.316547</td>\n",
       "      <td>0.194261</td>\n",
       "      <td>0.070102</td>\n",
       "      <td>0.216808</td>\n",
       "      <td>0.197053</td>\n",
       "      <td>0.297638</td>\n",
       "      <td>-0.024240</td>\n",
       "      <td>0.143186</td>\n",
       "      <td>0.256078</td>\n",
       "      <td>0.457041</td>\n",
       "      <td>0.123057</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>0.165559</td>\n",
       "      <td>0.567223</td>\n",
       "      <td>0.124337</td>\n",
       "      <td>0.181877</td>\n",
       "      <td>0.460207</td>\n",
       "      <td>0.390053</td>\n",
       "      <td>0.588141</td>\n",
       "      <td>0.222799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.054278</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>-0.256227</td>\n",
       "      <td>0.078062</td>\n",
       "      <td>0.075380</td>\n",
       "      <td>0.228836</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>0.354360</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>0.199520</td>\n",
       "      <td>0.305659</td>\n",
       "      <td>0.344864</td>\n",
       "      <td>-0.068835</td>\n",
       "      <td>0.077109</td>\n",
       "      <td>0.402443</td>\n",
       "      <td>-0.086878</td>\n",
       "      <td>-0.074477</td>\n",
       "      <td>0.176115</td>\n",
       "      <td>-0.023592</td>\n",
       "      <td>-0.068868</td>\n",
       "      <td>0.171690</td>\n",
       "      <td>0.092163</td>\n",
       "      <td>0.118130</td>\n",
       "      <td>0.272827</td>\n",
       "      <td>-0.031728</td>\n",
       "      <td>0.370537</td>\n",
       "      <td>-0.147595</td>\n",
       "      <td>0.174414</td>\n",
       "      <td>0.189858</td>\n",
       "      <td>0.355007</td>\n",
       "      <td>0.280133</td>\n",
       "      <td>0.214297</td>\n",
       "      <td>0.050383</td>\n",
       "      <td>0.162015</td>\n",
       "      <td>0.147456</td>\n",
       "      <td>0.365207</td>\n",
       "      <td>0.016919</td>\n",
       "      <td>0.174602</td>\n",
       "      <td>0.251988</td>\n",
       "      <td>0.360759</td>\n",
       "      <td>0.056107</td>\n",
       "      <td>0.044573</td>\n",
       "      <td>0.157755</td>\n",
       "      <td>0.524977</td>\n",
       "      <td>-0.009340</td>\n",
       "      <td>0.141392</td>\n",
       "      <td>0.395773</td>\n",
       "      <td>0.337668</td>\n",
       "      <td>0.590919</td>\n",
       "      <td>0.209613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.041047</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>-0.278156</td>\n",
       "      <td>0.019467</td>\n",
       "      <td>0.119749</td>\n",
       "      <td>0.162504</td>\n",
       "      <td>0.420302</td>\n",
       "      <td>0.405568</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>0.181122</td>\n",
       "      <td>0.292486</td>\n",
       "      <td>0.252121</td>\n",
       "      <td>-0.031053</td>\n",
       "      <td>0.120854</td>\n",
       "      <td>0.387814</td>\n",
       "      <td>-0.072154</td>\n",
       "      <td>-0.017399</td>\n",
       "      <td>0.117944</td>\n",
       "      <td>-0.051100</td>\n",
       "      <td>-0.099568</td>\n",
       "      <td>0.169706</td>\n",
       "      <td>-0.044548</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>0.291133</td>\n",
       "      <td>-0.044849</td>\n",
       "      <td>0.227723</td>\n",
       "      <td>-0.201317</td>\n",
       "      <td>0.109313</td>\n",
       "      <td>0.171828</td>\n",
       "      <td>0.386234</td>\n",
       "      <td>0.273952</td>\n",
       "      <td>0.203528</td>\n",
       "      <td>0.023796</td>\n",
       "      <td>0.155604</td>\n",
       "      <td>0.177317</td>\n",
       "      <td>0.316193</td>\n",
       "      <td>0.026790</td>\n",
       "      <td>0.155601</td>\n",
       "      <td>0.232943</td>\n",
       "      <td>0.393921</td>\n",
       "      <td>0.030396</td>\n",
       "      <td>0.086588</td>\n",
       "      <td>0.147113</td>\n",
       "      <td>0.500501</td>\n",
       "      <td>0.008648</td>\n",
       "      <td>0.041157</td>\n",
       "      <td>0.319795</td>\n",
       "      <td>0.329312</td>\n",
       "      <td>0.568579</td>\n",
       "      <td>0.225634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.059629</td>\n",
       "      <td>0.043723</td>\n",
       "      <td>-0.471178</td>\n",
       "      <td>0.044962</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>0.150542</td>\n",
       "      <td>0.304952</td>\n",
       "      <td>0.323823</td>\n",
       "      <td>-0.080780</td>\n",
       "      <td>0.089348</td>\n",
       "      <td>0.210250</td>\n",
       "      <td>0.294519</td>\n",
       "      <td>-0.227811</td>\n",
       "      <td>0.083205</td>\n",
       "      <td>0.296290</td>\n",
       "      <td>-0.059819</td>\n",
       "      <td>-0.020285</td>\n",
       "      <td>0.074707</td>\n",
       "      <td>-0.173353</td>\n",
       "      <td>-0.141329</td>\n",
       "      <td>0.091311</td>\n",
       "      <td>-0.086186</td>\n",
       "      <td>0.098764</td>\n",
       "      <td>0.292036</td>\n",
       "      <td>-0.082429</td>\n",
       "      <td>0.312240</td>\n",
       "      <td>-0.231258</td>\n",
       "      <td>0.038634</td>\n",
       "      <td>0.071270</td>\n",
       "      <td>0.287992</td>\n",
       "      <td>0.267050</td>\n",
       "      <td>0.189311</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.161658</td>\n",
       "      <td>0.157351</td>\n",
       "      <td>0.255592</td>\n",
       "      <td>-0.093921</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.270332</td>\n",
       "      <td>0.210935</td>\n",
       "      <td>-0.057574</td>\n",
       "      <td>-0.012216</td>\n",
       "      <td>0.221432</td>\n",
       "      <td>0.405606</td>\n",
       "      <td>-0.022907</td>\n",
       "      <td>0.071924</td>\n",
       "      <td>0.339529</td>\n",
       "      <td>0.226669</td>\n",
       "      <td>0.536224</td>\n",
       "      <td>0.214722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.043697</td>\n",
       "      <td>0.109260</td>\n",
       "      <td>-0.449822</td>\n",
       "      <td>-0.072803</td>\n",
       "      <td>-0.063742</td>\n",
       "      <td>0.159645</td>\n",
       "      <td>0.313794</td>\n",
       "      <td>0.383455</td>\n",
       "      <td>-0.121095</td>\n",
       "      <td>0.125035</td>\n",
       "      <td>0.235514</td>\n",
       "      <td>0.356154</td>\n",
       "      <td>-0.197161</td>\n",
       "      <td>0.020281</td>\n",
       "      <td>0.301711</td>\n",
       "      <td>-0.032721</td>\n",
       "      <td>-0.098900</td>\n",
       "      <td>0.093370</td>\n",
       "      <td>-0.310110</td>\n",
       "      <td>-0.093888</td>\n",
       "      <td>0.106394</td>\n",
       "      <td>-0.142988</td>\n",
       "      <td>-0.009513</td>\n",
       "      <td>0.318447</td>\n",
       "      <td>-0.137208</td>\n",
       "      <td>0.338985</td>\n",
       "      <td>-0.307182</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>0.055862</td>\n",
       "      <td>0.310512</td>\n",
       "      <td>0.200196</td>\n",
       "      <td>0.263520</td>\n",
       "      <td>-0.007282</td>\n",
       "      <td>0.108980</td>\n",
       "      <td>0.076196</td>\n",
       "      <td>0.321808</td>\n",
       "      <td>-0.106703</td>\n",
       "      <td>0.120518</td>\n",
       "      <td>0.272473</td>\n",
       "      <td>0.271469</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>-0.032903</td>\n",
       "      <td>0.181681</td>\n",
       "      <td>0.333695</td>\n",
       "      <td>-0.038551</td>\n",
       "      <td>0.128170</td>\n",
       "      <td>0.385173</td>\n",
       "      <td>0.302241</td>\n",
       "      <td>0.480900</td>\n",
       "      <td>0.216345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.090776</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>-0.363128</td>\n",
       "      <td>0.017907</td>\n",
       "      <td>0.106449</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.376933</td>\n",
       "      <td>0.515313</td>\n",
       "      <td>0.117376</td>\n",
       "      <td>0.143870</td>\n",
       "      <td>0.249972</td>\n",
       "      <td>0.346916</td>\n",
       "      <td>-0.172421</td>\n",
       "      <td>0.079740</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.033850</td>\n",
       "      <td>-0.132233</td>\n",
       "      <td>0.375060</td>\n",
       "      <td>-0.216929</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>0.188875</td>\n",
       "      <td>0.024965</td>\n",
       "      <td>-0.190352</td>\n",
       "      <td>0.201151</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.544686</td>\n",
       "      <td>-0.206904</td>\n",
       "      <td>0.225361</td>\n",
       "      <td>0.085276</td>\n",
       "      <td>0.446104</td>\n",
       "      <td>0.091031</td>\n",
       "      <td>0.302508</td>\n",
       "      <td>-0.043087</td>\n",
       "      <td>0.133643</td>\n",
       "      <td>0.064855</td>\n",
       "      <td>0.443285</td>\n",
       "      <td>-0.139177</td>\n",
       "      <td>-0.060163</td>\n",
       "      <td>0.330560</td>\n",
       "      <td>0.410834</td>\n",
       "      <td>0.103810</td>\n",
       "      <td>-0.106102</td>\n",
       "      <td>0.133906</td>\n",
       "      <td>0.202660</td>\n",
       "      <td>-0.050767</td>\n",
       "      <td>0.128843</td>\n",
       "      <td>0.367465</td>\n",
       "      <td>0.299734</td>\n",
       "      <td>0.501948</td>\n",
       "      <td>0.172506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.105912</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>-0.475569</td>\n",
       "      <td>-0.176435</td>\n",
       "      <td>0.243234</td>\n",
       "      <td>-0.025413</td>\n",
       "      <td>0.142753</td>\n",
       "      <td>0.247872</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0.266356</td>\n",
       "      <td>0.170271</td>\n",
       "      <td>0.359759</td>\n",
       "      <td>-0.332601</td>\n",
       "      <td>0.161123</td>\n",
       "      <td>0.470010</td>\n",
       "      <td>0.084470</td>\n",
       "      <td>-0.024247</td>\n",
       "      <td>0.352142</td>\n",
       "      <td>-0.202780</td>\n",
       "      <td>-0.085382</td>\n",
       "      <td>0.340767</td>\n",
       "      <td>-0.027275</td>\n",
       "      <td>-0.182386</td>\n",
       "      <td>-0.010679</td>\n",
       "      <td>-0.230168</td>\n",
       "      <td>0.625192</td>\n",
       "      <td>-0.144453</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.112632</td>\n",
       "      <td>0.416698</td>\n",
       "      <td>0.115231</td>\n",
       "      <td>0.337159</td>\n",
       "      <td>-0.236209</td>\n",
       "      <td>0.197708</td>\n",
       "      <td>-0.113051</td>\n",
       "      <td>0.276426</td>\n",
       "      <td>-0.049549</td>\n",
       "      <td>0.024321</td>\n",
       "      <td>0.287705</td>\n",
       "      <td>0.518452</td>\n",
       "      <td>0.206914</td>\n",
       "      <td>-0.026250</td>\n",
       "      <td>0.175636</td>\n",
       "      <td>0.208941</td>\n",
       "      <td>-0.126529</td>\n",
       "      <td>-0.121008</td>\n",
       "      <td>0.402500</td>\n",
       "      <td>0.230546</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>0.042312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.032943</td>\n",
       "      <td>-0.063721</td>\n",
       "      <td>-0.507996</td>\n",
       "      <td>-0.055573</td>\n",
       "      <td>0.024760</td>\n",
       "      <td>-0.189479</td>\n",
       "      <td>0.151669</td>\n",
       "      <td>0.190592</td>\n",
       "      <td>0.213512</td>\n",
       "      <td>0.101837</td>\n",
       "      <td>0.183858</td>\n",
       "      <td>0.169553</td>\n",
       "      <td>-0.185534</td>\n",
       "      <td>0.162440</td>\n",
       "      <td>0.320189</td>\n",
       "      <td>0.096207</td>\n",
       "      <td>-0.029831</td>\n",
       "      <td>0.290575</td>\n",
       "      <td>-0.152706</td>\n",
       "      <td>-0.196288</td>\n",
       "      <td>0.436943</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>-0.261586</td>\n",
       "      <td>0.119033</td>\n",
       "      <td>-0.276747</td>\n",
       "      <td>0.524200</td>\n",
       "      <td>-0.055541</td>\n",
       "      <td>0.174991</td>\n",
       "      <td>-0.074451</td>\n",
       "      <td>0.541599</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>0.242740</td>\n",
       "      <td>-0.401293</td>\n",
       "      <td>0.267086</td>\n",
       "      <td>-0.058245</td>\n",
       "      <td>0.198074</td>\n",
       "      <td>-0.311093</td>\n",
       "      <td>-0.106978</td>\n",
       "      <td>0.271346</td>\n",
       "      <td>0.446020</td>\n",
       "      <td>0.158273</td>\n",
       "      <td>-0.367698</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.194983</td>\n",
       "      <td>-0.126364</td>\n",
       "      <td>-0.132619</td>\n",
       "      <td>0.444136</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>0.421028</td>\n",
       "      <td>0.051965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.230056</td>\n",
       "      <td>-0.106300</td>\n",
       "      <td>-0.605046</td>\n",
       "      <td>-0.229202</td>\n",
       "      <td>-0.250253</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.162587</td>\n",
       "      <td>0.120182</td>\n",
       "      <td>0.081261</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.081847</td>\n",
       "      <td>0.212915</td>\n",
       "      <td>-0.205681</td>\n",
       "      <td>0.051942</td>\n",
       "      <td>0.191335</td>\n",
       "      <td>-0.126508</td>\n",
       "      <td>0.184524</td>\n",
       "      <td>0.207141</td>\n",
       "      <td>-0.265420</td>\n",
       "      <td>-0.307064</td>\n",
       "      <td>0.333149</td>\n",
       "      <td>-0.036032</td>\n",
       "      <td>-0.053872</td>\n",
       "      <td>0.146751</td>\n",
       "      <td>-0.362828</td>\n",
       "      <td>0.534544</td>\n",
       "      <td>-0.165869</td>\n",
       "      <td>0.077566</td>\n",
       "      <td>-0.244372</td>\n",
       "      <td>0.472507</td>\n",
       "      <td>-0.053651</td>\n",
       "      <td>-0.056730</td>\n",
       "      <td>-0.345577</td>\n",
       "      <td>0.316835</td>\n",
       "      <td>0.035797</td>\n",
       "      <td>0.177404</td>\n",
       "      <td>-0.275494</td>\n",
       "      <td>-0.162467</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.427603</td>\n",
       "      <td>-0.066818</td>\n",
       "      <td>-0.514406</td>\n",
       "      <td>0.125824</td>\n",
       "      <td>0.116657</td>\n",
       "      <td>-0.333242</td>\n",
       "      <td>-0.068800</td>\n",
       "      <td>0.486677</td>\n",
       "      <td>0.377819</td>\n",
       "      <td>0.608305</td>\n",
       "      <td>0.006897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>-0.143011</td>\n",
       "      <td>0.010427</td>\n",
       "      <td>-0.861107</td>\n",
       "      <td>-0.254331</td>\n",
       "      <td>-0.161759</td>\n",
       "      <td>0.214745</td>\n",
       "      <td>0.178630</td>\n",
       "      <td>0.125751</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.019563</td>\n",
       "      <td>-0.050050</td>\n",
       "      <td>0.041839</td>\n",
       "      <td>-0.106710</td>\n",
       "      <td>0.073896</td>\n",
       "      <td>0.575488</td>\n",
       "      <td>-0.258363</td>\n",
       "      <td>0.182165</td>\n",
       "      <td>0.037481</td>\n",
       "      <td>-0.230483</td>\n",
       "      <td>-0.271915</td>\n",
       "      <td>0.319029</td>\n",
       "      <td>-0.065951</td>\n",
       "      <td>-0.388609</td>\n",
       "      <td>-0.047571</td>\n",
       "      <td>-0.454932</td>\n",
       "      <td>0.603498</td>\n",
       "      <td>-0.086522</td>\n",
       "      <td>0.277680</td>\n",
       "      <td>-0.157003</td>\n",
       "      <td>0.544600</td>\n",
       "      <td>-0.108947</td>\n",
       "      <td>0.022642</td>\n",
       "      <td>-0.700718</td>\n",
       "      <td>0.213722</td>\n",
       "      <td>0.042545</td>\n",
       "      <td>0.251403</td>\n",
       "      <td>-0.210076</td>\n",
       "      <td>-0.234225</td>\n",
       "      <td>0.468969</td>\n",
       "      <td>0.561245</td>\n",
       "      <td>-0.038268</td>\n",
       "      <td>-0.483473</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.102490</td>\n",
       "      <td>-0.416520</td>\n",
       "      <td>-0.122304</td>\n",
       "      <td>0.231484</td>\n",
       "      <td>0.441285</td>\n",
       "      <td>0.611524</td>\n",
       "      <td>-0.067771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-0.006256</td>\n",
       "      <td>-0.103728</td>\n",
       "      <td>-0.998415</td>\n",
       "      <td>-0.195316</td>\n",
       "      <td>-0.228807</td>\n",
       "      <td>0.161459</td>\n",
       "      <td>0.152784</td>\n",
       "      <td>-0.006901</td>\n",
       "      <td>0.124758</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>-0.194107</td>\n",
       "      <td>-0.115874</td>\n",
       "      <td>-0.047685</td>\n",
       "      <td>0.072811</td>\n",
       "      <td>0.608588</td>\n",
       "      <td>-0.238325</td>\n",
       "      <td>0.105529</td>\n",
       "      <td>0.069604</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>-0.353805</td>\n",
       "      <td>0.298706</td>\n",
       "      <td>-0.190259</td>\n",
       "      <td>-0.233252</td>\n",
       "      <td>-0.203463</td>\n",
       "      <td>-0.656325</td>\n",
       "      <td>0.519796</td>\n",
       "      <td>0.065549</td>\n",
       "      <td>0.320221</td>\n",
       "      <td>-0.208204</td>\n",
       "      <td>0.516745</td>\n",
       "      <td>-0.025849</td>\n",
       "      <td>-0.095242</td>\n",
       "      <td>-0.731635</td>\n",
       "      <td>0.249239</td>\n",
       "      <td>0.118760</td>\n",
       "      <td>-0.046350</td>\n",
       "      <td>-0.416500</td>\n",
       "      <td>-0.037427</td>\n",
       "      <td>0.396160</td>\n",
       "      <td>0.605872</td>\n",
       "      <td>0.133646</td>\n",
       "      <td>-0.361435</td>\n",
       "      <td>0.140897</td>\n",
       "      <td>0.028180</td>\n",
       "      <td>-0.331623</td>\n",
       "      <td>0.061601</td>\n",
       "      <td>0.136862</td>\n",
       "      <td>0.152212</td>\n",
       "      <td>0.321760</td>\n",
       "      <td>-0.179830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-0.031460</td>\n",
       "      <td>-0.260787</td>\n",
       "      <td>-0.559287</td>\n",
       "      <td>-0.137322</td>\n",
       "      <td>-0.178411</td>\n",
       "      <td>0.274208</td>\n",
       "      <td>0.168569</td>\n",
       "      <td>0.076340</td>\n",
       "      <td>0.105762</td>\n",
       "      <td>-0.049116</td>\n",
       "      <td>0.103312</td>\n",
       "      <td>-0.053807</td>\n",
       "      <td>0.178113</td>\n",
       "      <td>-0.049179</td>\n",
       "      <td>0.721278</td>\n",
       "      <td>-0.340353</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>-0.012463</td>\n",
       "      <td>-0.168979</td>\n",
       "      <td>-0.521436</td>\n",
       "      <td>0.542542</td>\n",
       "      <td>-0.049288</td>\n",
       "      <td>-0.151794</td>\n",
       "      <td>-0.268851</td>\n",
       "      <td>-0.529287</td>\n",
       "      <td>0.354372</td>\n",
       "      <td>0.194280</td>\n",
       "      <td>0.293981</td>\n",
       "      <td>-0.179790</td>\n",
       "      <td>0.393622</td>\n",
       "      <td>-0.284805</td>\n",
       "      <td>-0.019740</td>\n",
       "      <td>-0.652995</td>\n",
       "      <td>0.192709</td>\n",
       "      <td>0.225770</td>\n",
       "      <td>-0.039570</td>\n",
       "      <td>-0.189487</td>\n",
       "      <td>0.182260</td>\n",
       "      <td>0.352576</td>\n",
       "      <td>0.474021</td>\n",
       "      <td>0.333918</td>\n",
       "      <td>-0.219099</td>\n",
       "      <td>0.039660</td>\n",
       "      <td>0.115842</td>\n",
       "      <td>-0.444859</td>\n",
       "      <td>0.085213</td>\n",
       "      <td>0.174879</td>\n",
       "      <td>0.371092</td>\n",
       "      <td>0.489644</td>\n",
       "      <td>-0.120232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.084128</td>\n",
       "      <td>-0.335501</td>\n",
       "      <td>-0.604485</td>\n",
       "      <td>-0.124787</td>\n",
       "      <td>-0.133445</td>\n",
       "      <td>0.331794</td>\n",
       "      <td>0.105614</td>\n",
       "      <td>0.091405</td>\n",
       "      <td>0.196956</td>\n",
       "      <td>-0.193518</td>\n",
       "      <td>0.261353</td>\n",
       "      <td>-0.157694</td>\n",
       "      <td>0.194749</td>\n",
       "      <td>-0.138098</td>\n",
       "      <td>0.464695</td>\n",
       "      <td>-0.431526</td>\n",
       "      <td>-0.124109</td>\n",
       "      <td>-0.021795</td>\n",
       "      <td>-0.278921</td>\n",
       "      <td>-0.602953</td>\n",
       "      <td>0.229912</td>\n",
       "      <td>-0.444776</td>\n",
       "      <td>-0.123518</td>\n",
       "      <td>-0.183836</td>\n",
       "      <td>-0.574667</td>\n",
       "      <td>0.415130</td>\n",
       "      <td>0.138655</td>\n",
       "      <td>0.366891</td>\n",
       "      <td>-0.053656</td>\n",
       "      <td>0.297031</td>\n",
       "      <td>-0.085684</td>\n",
       "      <td>-0.086127</td>\n",
       "      <td>-0.756597</td>\n",
       "      <td>-0.042751</td>\n",
       "      <td>-0.019225</td>\n",
       "      <td>-0.088461</td>\n",
       "      <td>-0.031695</td>\n",
       "      <td>-0.117137</td>\n",
       "      <td>0.365448</td>\n",
       "      <td>0.332235</td>\n",
       "      <td>-0.019133</td>\n",
       "      <td>0.195405</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>0.241389</td>\n",
       "      <td>-0.368135</td>\n",
       "      <td>-0.140788</td>\n",
       "      <td>-0.052181</td>\n",
       "      <td>0.243826</td>\n",
       "      <td>0.377674</td>\n",
       "      <td>-0.309708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-0.095682</td>\n",
       "      <td>-0.417488</td>\n",
       "      <td>-0.691892</td>\n",
       "      <td>-0.139024</td>\n",
       "      <td>0.026213</td>\n",
       "      <td>0.425503</td>\n",
       "      <td>0.028687</td>\n",
       "      <td>0.043396</td>\n",
       "      <td>0.055553</td>\n",
       "      <td>-0.282512</td>\n",
       "      <td>0.147766</td>\n",
       "      <td>-0.240160</td>\n",
       "      <td>0.256720</td>\n",
       "      <td>-0.427631</td>\n",
       "      <td>0.616692</td>\n",
       "      <td>-0.484862</td>\n",
       "      <td>-0.230161</td>\n",
       "      <td>0.032591</td>\n",
       "      <td>-0.224364</td>\n",
       "      <td>-0.586135</td>\n",
       "      <td>-0.023670</td>\n",
       "      <td>-0.386664</td>\n",
       "      <td>-0.020201</td>\n",
       "      <td>-0.340898</td>\n",
       "      <td>-0.658010</td>\n",
       "      <td>0.762235</td>\n",
       "      <td>0.013345</td>\n",
       "      <td>0.303080</td>\n",
       "      <td>-0.052895</td>\n",
       "      <td>0.287575</td>\n",
       "      <td>0.036543</td>\n",
       "      <td>-0.445590</td>\n",
       "      <td>-0.813945</td>\n",
       "      <td>-0.085499</td>\n",
       "      <td>-0.245741</td>\n",
       "      <td>-0.021320</td>\n",
       "      <td>-0.191700</td>\n",
       "      <td>-0.052647</td>\n",
       "      <td>0.394315</td>\n",
       "      <td>0.365636</td>\n",
       "      <td>-0.044337</td>\n",
       "      <td>0.039991</td>\n",
       "      <td>-0.450840</td>\n",
       "      <td>0.296177</td>\n",
       "      <td>-0.232529</td>\n",
       "      <td>-0.237388</td>\n",
       "      <td>-0.224103</td>\n",
       "      <td>0.367801</td>\n",
       "      <td>0.413194</td>\n",
       "      <td>-0.258929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-0.200797</td>\n",
       "      <td>-0.536283</td>\n",
       "      <td>-0.628329</td>\n",
       "      <td>-0.119022</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.524026</td>\n",
       "      <td>0.097524</td>\n",
       "      <td>0.199408</td>\n",
       "      <td>0.054746</td>\n",
       "      <td>-0.232358</td>\n",
       "      <td>0.343331</td>\n",
       "      <td>-0.002036</td>\n",
       "      <td>0.227223</td>\n",
       "      <td>-0.516567</td>\n",
       "      <td>0.468056</td>\n",
       "      <td>-0.458783</td>\n",
       "      <td>-0.239627</td>\n",
       "      <td>0.299717</td>\n",
       "      <td>-0.140644</td>\n",
       "      <td>-0.363761</td>\n",
       "      <td>-0.012720</td>\n",
       "      <td>-0.326641</td>\n",
       "      <td>0.082434</td>\n",
       "      <td>-0.234553</td>\n",
       "      <td>-0.616362</td>\n",
       "      <td>0.614326</td>\n",
       "      <td>0.210649</td>\n",
       "      <td>0.357517</td>\n",
       "      <td>-0.023697</td>\n",
       "      <td>0.256378</td>\n",
       "      <td>0.086838</td>\n",
       "      <td>-0.230365</td>\n",
       "      <td>-0.686484</td>\n",
       "      <td>-0.232435</td>\n",
       "      <td>-0.110533</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>-0.333180</td>\n",
       "      <td>0.090505</td>\n",
       "      <td>0.355061</td>\n",
       "      <td>0.512118</td>\n",
       "      <td>-0.055713</td>\n",
       "      <td>0.341199</td>\n",
       "      <td>-0.398345</td>\n",
       "      <td>0.702751</td>\n",
       "      <td>-0.173656</td>\n",
       "      <td>-0.217061</td>\n",
       "      <td>0.026488</td>\n",
       "      <td>0.281158</td>\n",
       "      <td>0.398930</td>\n",
       "      <td>-0.257243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-0.296055</td>\n",
       "      <td>-0.298226</td>\n",
       "      <td>-0.904540</td>\n",
       "      <td>-0.231394</td>\n",
       "      <td>0.148490</td>\n",
       "      <td>0.488239</td>\n",
       "      <td>-0.013178</td>\n",
       "      <td>0.197644</td>\n",
       "      <td>0.059067</td>\n",
       "      <td>-0.156554</td>\n",
       "      <td>0.211850</td>\n",
       "      <td>0.042462</td>\n",
       "      <td>0.065064</td>\n",
       "      <td>-0.361115</td>\n",
       "      <td>0.332055</td>\n",
       "      <td>-0.521644</td>\n",
       "      <td>-0.145104</td>\n",
       "      <td>0.098012</td>\n",
       "      <td>-0.080606</td>\n",
       "      <td>-0.474197</td>\n",
       "      <td>-0.144435</td>\n",
       "      <td>-0.266437</td>\n",
       "      <td>0.125179</td>\n",
       "      <td>-0.228199</td>\n",
       "      <td>-0.427602</td>\n",
       "      <td>0.520241</td>\n",
       "      <td>0.121872</td>\n",
       "      <td>0.456544</td>\n",
       "      <td>0.021385</td>\n",
       "      <td>0.134513</td>\n",
       "      <td>0.159049</td>\n",
       "      <td>-0.312396</td>\n",
       "      <td>-0.714217</td>\n",
       "      <td>-0.312767</td>\n",
       "      <td>-0.391434</td>\n",
       "      <td>0.031446</td>\n",
       "      <td>-0.427699</td>\n",
       "      <td>0.145654</td>\n",
       "      <td>0.237173</td>\n",
       "      <td>0.509993</td>\n",
       "      <td>-0.125646</td>\n",
       "      <td>-0.009774</td>\n",
       "      <td>-0.194873</td>\n",
       "      <td>0.560392</td>\n",
       "      <td>-0.219471</td>\n",
       "      <td>-0.364147</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>0.213372</td>\n",
       "      <td>0.497666</td>\n",
       "      <td>-0.396594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-0.407144</td>\n",
       "      <td>-0.506276</td>\n",
       "      <td>-0.926600</td>\n",
       "      <td>-0.270373</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>0.250637</td>\n",
       "      <td>0.063079</td>\n",
       "      <td>0.045365</td>\n",
       "      <td>-0.330692</td>\n",
       "      <td>0.051531</td>\n",
       "      <td>-0.050101</td>\n",
       "      <td>0.051361</td>\n",
       "      <td>-0.139920</td>\n",
       "      <td>-0.228524</td>\n",
       "      <td>0.046876</td>\n",
       "      <td>-0.520904</td>\n",
       "      <td>-0.225409</td>\n",
       "      <td>-0.044308</td>\n",
       "      <td>-0.265053</td>\n",
       "      <td>-0.655629</td>\n",
       "      <td>-0.004615</td>\n",
       "      <td>-0.488368</td>\n",
       "      <td>-0.101059</td>\n",
       "      <td>-0.002840</td>\n",
       "      <td>-0.600729</td>\n",
       "      <td>0.418729</td>\n",
       "      <td>-0.024273</td>\n",
       "      <td>0.155786</td>\n",
       "      <td>-0.069071</td>\n",
       "      <td>-0.118625</td>\n",
       "      <td>0.173190</td>\n",
       "      <td>-0.550500</td>\n",
       "      <td>-0.704629</td>\n",
       "      <td>-0.443806</td>\n",
       "      <td>-0.412356</td>\n",
       "      <td>-0.014157</td>\n",
       "      <td>-0.518234</td>\n",
       "      <td>-0.167985</td>\n",
       "      <td>0.112004</td>\n",
       "      <td>0.150521</td>\n",
       "      <td>-0.226835</td>\n",
       "      <td>-0.060699</td>\n",
       "      <td>-0.297972</td>\n",
       "      <td>0.541164</td>\n",
       "      <td>-0.393991</td>\n",
       "      <td>-0.378160</td>\n",
       "      <td>0.133846</td>\n",
       "      <td>0.250690</td>\n",
       "      <td>0.459112</td>\n",
       "      <td>-0.385848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-0.473407</td>\n",
       "      <td>-0.493203</td>\n",
       "      <td>-1.032583</td>\n",
       "      <td>-0.407980</td>\n",
       "      <td>-0.006201</td>\n",
       "      <td>0.264895</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>0.121520</td>\n",
       "      <td>-0.299160</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>-0.235790</td>\n",
       "      <td>-0.058078</td>\n",
       "      <td>-0.046172</td>\n",
       "      <td>-0.354483</td>\n",
       "      <td>-0.032015</td>\n",
       "      <td>-0.639005</td>\n",
       "      <td>-0.206611</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>-0.345981</td>\n",
       "      <td>-0.762888</td>\n",
       "      <td>-0.116998</td>\n",
       "      <td>-0.577974</td>\n",
       "      <td>-0.278375</td>\n",
       "      <td>-0.029444</td>\n",
       "      <td>-0.612127</td>\n",
       "      <td>0.378086</td>\n",
       "      <td>-0.156501</td>\n",
       "      <td>0.148460</td>\n",
       "      <td>-0.126244</td>\n",
       "      <td>-0.270806</td>\n",
       "      <td>0.139653</td>\n",
       "      <td>-0.554679</td>\n",
       "      <td>-0.727666</td>\n",
       "      <td>-0.627501</td>\n",
       "      <td>-0.564904</td>\n",
       "      <td>0.073504</td>\n",
       "      <td>-0.373302</td>\n",
       "      <td>-0.284249</td>\n",
       "      <td>0.232145</td>\n",
       "      <td>-0.026649</td>\n",
       "      <td>-0.336666</td>\n",
       "      <td>-0.278033</td>\n",
       "      <td>-0.343210</td>\n",
       "      <td>0.353283</td>\n",
       "      <td>-0.414424</td>\n",
       "      <td>-0.530677</td>\n",
       "      <td>-0.116641</td>\n",
       "      <td>0.128181</td>\n",
       "      <td>0.485628</td>\n",
       "      <td>-0.508580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-0.357368</td>\n",
       "      <td>-0.455566</td>\n",
       "      <td>-1.082246</td>\n",
       "      <td>-0.423261</td>\n",
       "      <td>0.036216</td>\n",
       "      <td>0.242148</td>\n",
       "      <td>0.081271</td>\n",
       "      <td>0.119610</td>\n",
       "      <td>-0.343998</td>\n",
       "      <td>0.049478</td>\n",
       "      <td>-0.264148</td>\n",
       "      <td>0.024313</td>\n",
       "      <td>-0.182029</td>\n",
       "      <td>-0.388488</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>-0.602391</td>\n",
       "      <td>-0.133452</td>\n",
       "      <td>0.097764</td>\n",
       "      <td>-0.383680</td>\n",
       "      <td>-0.637301</td>\n",
       "      <td>0.038735</td>\n",
       "      <td>-0.576708</td>\n",
       "      <td>-0.224380</td>\n",
       "      <td>-0.047668</td>\n",
       "      <td>-0.734744</td>\n",
       "      <td>0.402004</td>\n",
       "      <td>-0.149891</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>-0.131635</td>\n",
       "      <td>-0.339942</td>\n",
       "      <td>0.243946</td>\n",
       "      <td>-0.669929</td>\n",
       "      <td>-0.655053</td>\n",
       "      <td>-0.519376</td>\n",
       "      <td>-0.625792</td>\n",
       "      <td>0.067903</td>\n",
       "      <td>-0.419841</td>\n",
       "      <td>-0.349145</td>\n",
       "      <td>0.267589</td>\n",
       "      <td>-0.070433</td>\n",
       "      <td>-0.405777</td>\n",
       "      <td>-0.323521</td>\n",
       "      <td>-0.291451</td>\n",
       "      <td>0.359641</td>\n",
       "      <td>-0.354754</td>\n",
       "      <td>-0.572186</td>\n",
       "      <td>-0.115395</td>\n",
       "      <td>0.053713</td>\n",
       "      <td>0.525728</td>\n",
       "      <td>-0.455838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.358538</td>\n",
       "      <td>-0.384976</td>\n",
       "      <td>-0.998727</td>\n",
       "      <td>-0.362298</td>\n",
       "      <td>0.039698</td>\n",
       "      <td>0.220972</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>0.003732</td>\n",
       "      <td>-0.354246</td>\n",
       "      <td>-0.047236</td>\n",
       "      <td>-0.109261</td>\n",
       "      <td>0.029531</td>\n",
       "      <td>-0.273708</td>\n",
       "      <td>-0.274871</td>\n",
       "      <td>-0.129552</td>\n",
       "      <td>-0.578049</td>\n",
       "      <td>-0.137655</td>\n",
       "      <td>-0.195747</td>\n",
       "      <td>-0.371047</td>\n",
       "      <td>-0.774954</td>\n",
       "      <td>0.070769</td>\n",
       "      <td>-0.702428</td>\n",
       "      <td>-0.171751</td>\n",
       "      <td>-0.082291</td>\n",
       "      <td>-0.778365</td>\n",
       "      <td>0.407445</td>\n",
       "      <td>-0.117659</td>\n",
       "      <td>0.154086</td>\n",
       "      <td>-0.171460</td>\n",
       "      <td>-0.407437</td>\n",
       "      <td>0.076026</td>\n",
       "      <td>-0.576082</td>\n",
       "      <td>-0.582552</td>\n",
       "      <td>-0.577036</td>\n",
       "      <td>-0.679779</td>\n",
       "      <td>0.044525</td>\n",
       "      <td>-0.638243</td>\n",
       "      <td>-0.328388</td>\n",
       "      <td>0.260935</td>\n",
       "      <td>-0.078059</td>\n",
       "      <td>-0.540825</td>\n",
       "      <td>-0.336686</td>\n",
       "      <td>-0.159033</td>\n",
       "      <td>0.321065</td>\n",
       "      <td>-0.312229</td>\n",
       "      <td>-0.562511</td>\n",
       "      <td>-0.114711</td>\n",
       "      <td>0.018710</td>\n",
       "      <td>0.435935</td>\n",
       "      <td>-0.630411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-0.355641</td>\n",
       "      <td>-0.386211</td>\n",
       "      <td>-0.908888</td>\n",
       "      <td>-0.363824</td>\n",
       "      <td>-0.051279</td>\n",
       "      <td>0.116043</td>\n",
       "      <td>0.069190</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>-0.413427</td>\n",
       "      <td>-0.092029</td>\n",
       "      <td>-0.085912</td>\n",
       "      <td>0.066186</td>\n",
       "      <td>-0.337785</td>\n",
       "      <td>-0.266735</td>\n",
       "      <td>-0.191787</td>\n",
       "      <td>-0.618790</td>\n",
       "      <td>-0.187768</td>\n",
       "      <td>-0.203289</td>\n",
       "      <td>-0.335110</td>\n",
       "      <td>-0.737838</td>\n",
       "      <td>0.103255</td>\n",
       "      <td>-0.763943</td>\n",
       "      <td>-0.266002</td>\n",
       "      <td>-0.223304</td>\n",
       "      <td>-0.791731</td>\n",
       "      <td>0.539270</td>\n",
       "      <td>-0.160443</td>\n",
       "      <td>0.087258</td>\n",
       "      <td>-0.304937</td>\n",
       "      <td>-0.486210</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>-0.597420</td>\n",
       "      <td>-0.690070</td>\n",
       "      <td>-0.499602</td>\n",
       "      <td>-0.787291</td>\n",
       "      <td>0.028274</td>\n",
       "      <td>-0.695797</td>\n",
       "      <td>-0.342201</td>\n",
       "      <td>0.280080</td>\n",
       "      <td>-0.006830</td>\n",
       "      <td>-0.597909</td>\n",
       "      <td>-0.454566</td>\n",
       "      <td>-0.214784</td>\n",
       "      <td>0.302136</td>\n",
       "      <td>-0.333198</td>\n",
       "      <td>-0.632531</td>\n",
       "      <td>-0.038848</td>\n",
       "      <td>-0.014516</td>\n",
       "      <td>0.406933</td>\n",
       "      <td>-0.575018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-0.461110</td>\n",
       "      <td>-0.527689</td>\n",
       "      <td>-0.982047</td>\n",
       "      <td>-0.232629</td>\n",
       "      <td>-0.108000</td>\n",
       "      <td>0.093951</td>\n",
       "      <td>0.030405</td>\n",
       "      <td>-0.019029</td>\n",
       "      <td>-0.568640</td>\n",
       "      <td>-0.133166</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.064632</td>\n",
       "      <td>-0.369495</td>\n",
       "      <td>-0.296756</td>\n",
       "      <td>-0.100821</td>\n",
       "      <td>-0.619203</td>\n",
       "      <td>-0.204114</td>\n",
       "      <td>-0.109604</td>\n",
       "      <td>-0.364762</td>\n",
       "      <td>-0.873383</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>-0.755307</td>\n",
       "      <td>-0.266991</td>\n",
       "      <td>-0.158804</td>\n",
       "      <td>-0.676095</td>\n",
       "      <td>0.587626</td>\n",
       "      <td>-0.070131</td>\n",
       "      <td>0.202960</td>\n",
       "      <td>-0.251829</td>\n",
       "      <td>-0.548908</td>\n",
       "      <td>0.118721</td>\n",
       "      <td>-0.658860</td>\n",
       "      <td>-0.845005</td>\n",
       "      <td>-0.527439</td>\n",
       "      <td>-0.820606</td>\n",
       "      <td>0.093894</td>\n",
       "      <td>-0.613468</td>\n",
       "      <td>-0.302810</td>\n",
       "      <td>0.313496</td>\n",
       "      <td>0.038458</td>\n",
       "      <td>-0.600131</td>\n",
       "      <td>-0.393005</td>\n",
       "      <td>-0.155445</td>\n",
       "      <td>0.410641</td>\n",
       "      <td>-0.516826</td>\n",
       "      <td>-0.566514</td>\n",
       "      <td>-0.003146</td>\n",
       "      <td>0.102523</td>\n",
       "      <td>0.554587</td>\n",
       "      <td>-0.448823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-0.394979</td>\n",
       "      <td>-0.654648</td>\n",
       "      <td>-1.200779</td>\n",
       "      <td>-0.245519</td>\n",
       "      <td>-0.114103</td>\n",
       "      <td>0.026339</td>\n",
       "      <td>0.073910</td>\n",
       "      <td>0.088317</td>\n",
       "      <td>-0.607866</td>\n",
       "      <td>-0.095426</td>\n",
       "      <td>0.064096</td>\n",
       "      <td>0.078445</td>\n",
       "      <td>-0.488434</td>\n",
       "      <td>-0.471657</td>\n",
       "      <td>-0.191620</td>\n",
       "      <td>-0.603220</td>\n",
       "      <td>-0.314101</td>\n",
       "      <td>-0.181082</td>\n",
       "      <td>-0.451622</td>\n",
       "      <td>-0.892360</td>\n",
       "      <td>-0.128866</td>\n",
       "      <td>-0.742886</td>\n",
       "      <td>-0.351631</td>\n",
       "      <td>-0.134918</td>\n",
       "      <td>-0.773317</td>\n",
       "      <td>0.610593</td>\n",
       "      <td>-0.103815</td>\n",
       "      <td>0.298418</td>\n",
       "      <td>-0.201138</td>\n",
       "      <td>-0.421818</td>\n",
       "      <td>0.180291</td>\n",
       "      <td>-0.705692</td>\n",
       "      <td>-0.867095</td>\n",
       "      <td>-0.634764</td>\n",
       "      <td>-0.802399</td>\n",
       "      <td>0.081335</td>\n",
       "      <td>-0.616396</td>\n",
       "      <td>-0.342446</td>\n",
       "      <td>0.317960</td>\n",
       "      <td>0.060715</td>\n",
       "      <td>-0.786776</td>\n",
       "      <td>-0.385327</td>\n",
       "      <td>-0.203725</td>\n",
       "      <td>0.470720</td>\n",
       "      <td>-0.591181</td>\n",
       "      <td>-0.584455</td>\n",
       "      <td>0.035867</td>\n",
       "      <td>0.029073</td>\n",
       "      <td>0.482117</td>\n",
       "      <td>-0.540381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-0.444471</td>\n",
       "      <td>-0.744455</td>\n",
       "      <td>-1.144983</td>\n",
       "      <td>-0.238167</td>\n",
       "      <td>-0.066611</td>\n",
       "      <td>-0.071252</td>\n",
       "      <td>-0.046452</td>\n",
       "      <td>-0.047508</td>\n",
       "      <td>-0.695491</td>\n",
       "      <td>-0.229231</td>\n",
       "      <td>0.038493</td>\n",
       "      <td>-0.018503</td>\n",
       "      <td>-0.534885</td>\n",
       "      <td>-0.440296</td>\n",
       "      <td>-0.197332</td>\n",
       "      <td>-0.603499</td>\n",
       "      <td>-0.406680</td>\n",
       "      <td>-0.225973</td>\n",
       "      <td>-0.536200</td>\n",
       "      <td>-0.851003</td>\n",
       "      <td>-0.117746</td>\n",
       "      <td>-0.842387</td>\n",
       "      <td>-0.328632</td>\n",
       "      <td>-0.091750</td>\n",
       "      <td>-0.772950</td>\n",
       "      <td>0.440728</td>\n",
       "      <td>-0.103665</td>\n",
       "      <td>0.292448</td>\n",
       "      <td>-0.268457</td>\n",
       "      <td>-0.444416</td>\n",
       "      <td>0.046257</td>\n",
       "      <td>-0.817280</td>\n",
       "      <td>-0.923338</td>\n",
       "      <td>-0.633430</td>\n",
       "      <td>-0.791956</td>\n",
       "      <td>-0.073334</td>\n",
       "      <td>-0.713670</td>\n",
       "      <td>-0.217366</td>\n",
       "      <td>0.139070</td>\n",
       "      <td>-0.013281</td>\n",
       "      <td>-0.878374</td>\n",
       "      <td>-0.389149</td>\n",
       "      <td>-0.257492</td>\n",
       "      <td>0.321313</td>\n",
       "      <td>-0.541157</td>\n",
       "      <td>-0.603567</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>-0.080363</td>\n",
       "      <td>0.473612</td>\n",
       "      <td>-0.593178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-0.407348</td>\n",
       "      <td>-0.766622</td>\n",
       "      <td>-1.046936</td>\n",
       "      <td>-0.264029</td>\n",
       "      <td>0.010924</td>\n",
       "      <td>-0.098146</td>\n",
       "      <td>0.041975</td>\n",
       "      <td>-0.062352</td>\n",
       "      <td>-0.647332</td>\n",
       "      <td>-0.217655</td>\n",
       "      <td>0.074673</td>\n",
       "      <td>-0.027880</td>\n",
       "      <td>-0.516483</td>\n",
       "      <td>-0.430003</td>\n",
       "      <td>-0.280274</td>\n",
       "      <td>-0.680702</td>\n",
       "      <td>-0.473448</td>\n",
       "      <td>-0.385390</td>\n",
       "      <td>-0.502434</td>\n",
       "      <td>-0.830922</td>\n",
       "      <td>-0.214442</td>\n",
       "      <td>-0.779374</td>\n",
       "      <td>-0.300121</td>\n",
       "      <td>-0.125021</td>\n",
       "      <td>-0.841854</td>\n",
       "      <td>0.473919</td>\n",
       "      <td>-0.232167</td>\n",
       "      <td>0.170210</td>\n",
       "      <td>-0.181790</td>\n",
       "      <td>-0.414545</td>\n",
       "      <td>0.095419</td>\n",
       "      <td>-0.738087</td>\n",
       "      <td>-0.800071</td>\n",
       "      <td>-0.584713</td>\n",
       "      <td>-0.842311</td>\n",
       "      <td>-0.106323</td>\n",
       "      <td>-0.620078</td>\n",
       "      <td>-0.256496</td>\n",
       "      <td>0.177221</td>\n",
       "      <td>-0.152958</td>\n",
       "      <td>-0.939001</td>\n",
       "      <td>-0.393399</td>\n",
       "      <td>-0.208871</td>\n",
       "      <td>0.340961</td>\n",
       "      <td>-0.559236</td>\n",
       "      <td>-0.654208</td>\n",
       "      <td>-0.034792</td>\n",
       "      <td>-0.188890</td>\n",
       "      <td>0.401005</td>\n",
       "      <td>-0.625489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-0.294956</td>\n",
       "      <td>-0.765670</td>\n",
       "      <td>-0.996639</td>\n",
       "      <td>-0.245609</td>\n",
       "      <td>0.043436</td>\n",
       "      <td>-0.106868</td>\n",
       "      <td>0.076046</td>\n",
       "      <td>-0.077551</td>\n",
       "      <td>-0.502347</td>\n",
       "      <td>-0.188983</td>\n",
       "      <td>0.095772</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>-0.453009</td>\n",
       "      <td>-0.373247</td>\n",
       "      <td>-0.226439</td>\n",
       "      <td>-0.612182</td>\n",
       "      <td>-0.342223</td>\n",
       "      <td>-0.248134</td>\n",
       "      <td>-0.476690</td>\n",
       "      <td>-0.696992</td>\n",
       "      <td>-0.167651</td>\n",
       "      <td>-0.736921</td>\n",
       "      <td>-0.305246</td>\n",
       "      <td>-0.040744</td>\n",
       "      <td>-0.704312</td>\n",
       "      <td>0.579026</td>\n",
       "      <td>-0.160436</td>\n",
       "      <td>0.214529</td>\n",
       "      <td>-0.283339</td>\n",
       "      <td>-0.326291</td>\n",
       "      <td>0.130536</td>\n",
       "      <td>-0.701800</td>\n",
       "      <td>-0.767109</td>\n",
       "      <td>-0.474682</td>\n",
       "      <td>-0.771208</td>\n",
       "      <td>-0.004712</td>\n",
       "      <td>-0.514406</td>\n",
       "      <td>-0.317304</td>\n",
       "      <td>0.295629</td>\n",
       "      <td>-0.118049</td>\n",
       "      <td>-0.744159</td>\n",
       "      <td>-0.357294</td>\n",
       "      <td>-0.243140</td>\n",
       "      <td>0.395433</td>\n",
       "      <td>-0.392658</td>\n",
       "      <td>-0.607326</td>\n",
       "      <td>-0.028940</td>\n",
       "      <td>-0.110241</td>\n",
       "      <td>0.514913</td>\n",
       "      <td>-0.593211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-0.226531</td>\n",
       "      <td>-0.624858</td>\n",
       "      <td>-1.045833</td>\n",
       "      <td>-0.216664</td>\n",
       "      <td>0.103967</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.248085</td>\n",
       "      <td>0.195723</td>\n",
       "      <td>-0.420404</td>\n",
       "      <td>-0.093614</td>\n",
       "      <td>0.101983</td>\n",
       "      <td>0.108455</td>\n",
       "      <td>-0.347899</td>\n",
       "      <td>-0.307311</td>\n",
       "      <td>-0.158280</td>\n",
       "      <td>-0.462670</td>\n",
       "      <td>-0.333382</td>\n",
       "      <td>-0.136108</td>\n",
       "      <td>-0.354866</td>\n",
       "      <td>-0.563184</td>\n",
       "      <td>-0.089638</td>\n",
       "      <td>-0.551036</td>\n",
       "      <td>-0.210481</td>\n",
       "      <td>0.045839</td>\n",
       "      <td>-0.563267</td>\n",
       "      <td>0.635207</td>\n",
       "      <td>-0.161909</td>\n",
       "      <td>0.347169</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>-0.351448</td>\n",
       "      <td>0.230860</td>\n",
       "      <td>-0.511024</td>\n",
       "      <td>-0.684868</td>\n",
       "      <td>-0.503427</td>\n",
       "      <td>-0.668270</td>\n",
       "      <td>0.202825</td>\n",
       "      <td>-0.474791</td>\n",
       "      <td>-0.284406</td>\n",
       "      <td>0.316892</td>\n",
       "      <td>-0.058361</td>\n",
       "      <td>-0.698515</td>\n",
       "      <td>-0.294348</td>\n",
       "      <td>-0.252675</td>\n",
       "      <td>0.419809</td>\n",
       "      <td>-0.374266</td>\n",
       "      <td>-0.441263</td>\n",
       "      <td>-0.009475</td>\n",
       "      <td>-0.083454</td>\n",
       "      <td>0.533952</td>\n",
       "      <td>-0.509425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-0.139772</td>\n",
       "      <td>-0.492243</td>\n",
       "      <td>-0.990570</td>\n",
       "      <td>-0.217012</td>\n",
       "      <td>0.122755</td>\n",
       "      <td>0.120765</td>\n",
       "      <td>0.270357</td>\n",
       "      <td>0.150552</td>\n",
       "      <td>-0.349848</td>\n",
       "      <td>-0.067147</td>\n",
       "      <td>0.034033</td>\n",
       "      <td>0.137926</td>\n",
       "      <td>-0.366197</td>\n",
       "      <td>-0.324328</td>\n",
       "      <td>-0.139339</td>\n",
       "      <td>-0.375902</td>\n",
       "      <td>-0.216955</td>\n",
       "      <td>-0.153289</td>\n",
       "      <td>-0.365351</td>\n",
       "      <td>-0.440958</td>\n",
       "      <td>-0.109694</td>\n",
       "      <td>-0.531821</td>\n",
       "      <td>-0.233782</td>\n",
       "      <td>-0.030048</td>\n",
       "      <td>-0.678199</td>\n",
       "      <td>0.556513</td>\n",
       "      <td>-0.201806</td>\n",
       "      <td>0.345959</td>\n",
       "      <td>-0.116704</td>\n",
       "      <td>-0.324819</td>\n",
       "      <td>0.174003</td>\n",
       "      <td>-0.453518</td>\n",
       "      <td>-0.642872</td>\n",
       "      <td>-0.419041</td>\n",
       "      <td>-0.680291</td>\n",
       "      <td>0.285923</td>\n",
       "      <td>-0.548898</td>\n",
       "      <td>-0.181670</td>\n",
       "      <td>0.219728</td>\n",
       "      <td>0.053468</td>\n",
       "      <td>-0.604663</td>\n",
       "      <td>-0.268753</td>\n",
       "      <td>-0.238110</td>\n",
       "      <td>0.463199</td>\n",
       "      <td>-0.303060</td>\n",
       "      <td>-0.367823</td>\n",
       "      <td>0.058702</td>\n",
       "      <td>-0.077745</td>\n",
       "      <td>0.568030</td>\n",
       "      <td>-0.468180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>-0.208736</td>\n",
       "      <td>-0.437711</td>\n",
       "      <td>-0.940507</td>\n",
       "      <td>-0.273828</td>\n",
       "      <td>0.170205</td>\n",
       "      <td>0.162187</td>\n",
       "      <td>0.162759</td>\n",
       "      <td>0.142317</td>\n",
       "      <td>-0.419040</td>\n",
       "      <td>-0.056057</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>0.183894</td>\n",
       "      <td>-0.427290</td>\n",
       "      <td>-0.156654</td>\n",
       "      <td>-0.218152</td>\n",
       "      <td>-0.469086</td>\n",
       "      <td>-0.221055</td>\n",
       "      <td>-0.157905</td>\n",
       "      <td>-0.392356</td>\n",
       "      <td>-0.514626</td>\n",
       "      <td>-0.012270</td>\n",
       "      <td>-0.559387</td>\n",
       "      <td>-0.291021</td>\n",
       "      <td>-0.012451</td>\n",
       "      <td>-0.636734</td>\n",
       "      <td>0.501226</td>\n",
       "      <td>-0.187773</td>\n",
       "      <td>0.293675</td>\n",
       "      <td>-0.111893</td>\n",
       "      <td>-0.323644</td>\n",
       "      <td>0.074169</td>\n",
       "      <td>-0.444773</td>\n",
       "      <td>-0.544543</td>\n",
       "      <td>-0.408209</td>\n",
       "      <td>-0.688172</td>\n",
       "      <td>0.205244</td>\n",
       "      <td>-0.569174</td>\n",
       "      <td>-0.297261</td>\n",
       "      <td>0.244742</td>\n",
       "      <td>0.081630</td>\n",
       "      <td>-0.539149</td>\n",
       "      <td>-0.290233</td>\n",
       "      <td>-0.103130</td>\n",
       "      <td>0.359859</td>\n",
       "      <td>-0.374461</td>\n",
       "      <td>-0.425712</td>\n",
       "      <td>0.140540</td>\n",
       "      <td>0.024348</td>\n",
       "      <td>0.478197</td>\n",
       "      <td>-0.546414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-0.120491</td>\n",
       "      <td>-0.428808</td>\n",
       "      <td>-0.925936</td>\n",
       "      <td>-0.185805</td>\n",
       "      <td>0.159544</td>\n",
       "      <td>0.070507</td>\n",
       "      <td>0.106393</td>\n",
       "      <td>0.123094</td>\n",
       "      <td>-0.377343</td>\n",
       "      <td>-0.014202</td>\n",
       "      <td>-0.012162</td>\n",
       "      <td>0.116930</td>\n",
       "      <td>-0.364892</td>\n",
       "      <td>-0.199911</td>\n",
       "      <td>-0.228716</td>\n",
       "      <td>-0.444896</td>\n",
       "      <td>-0.134398</td>\n",
       "      <td>-0.198605</td>\n",
       "      <td>-0.340516</td>\n",
       "      <td>-0.664790</td>\n",
       "      <td>-0.072915</td>\n",
       "      <td>-0.486502</td>\n",
       "      <td>-0.359910</td>\n",
       "      <td>-0.129482</td>\n",
       "      <td>-0.592870</td>\n",
       "      <td>0.589176</td>\n",
       "      <td>-0.059108</td>\n",
       "      <td>0.319616</td>\n",
       "      <td>-0.124588</td>\n",
       "      <td>-0.309140</td>\n",
       "      <td>0.079349</td>\n",
       "      <td>-0.459425</td>\n",
       "      <td>-0.502879</td>\n",
       "      <td>-0.379482</td>\n",
       "      <td>-0.751325</td>\n",
       "      <td>0.229921</td>\n",
       "      <td>-0.531423</td>\n",
       "      <td>-0.283877</td>\n",
       "      <td>0.257376</td>\n",
       "      <td>0.122964</td>\n",
       "      <td>-0.489059</td>\n",
       "      <td>-0.379075</td>\n",
       "      <td>-0.187222</td>\n",
       "      <td>0.409063</td>\n",
       "      <td>-0.348206</td>\n",
       "      <td>-0.431151</td>\n",
       "      <td>0.060036</td>\n",
       "      <td>0.014313</td>\n",
       "      <td>0.491447</td>\n",
       "      <td>-0.407211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       61527     9715      1266      26753     28629     187406    10453   \\\n",
       "0    0.372936  0.313453  0.361009  0.281325  0.335872  0.404536  0.358857   \n",
       "1    0.247632  0.189511  0.294154  0.279754  0.259953  0.328689  0.277413   \n",
       "2    0.058523  0.162405  0.191868  0.113815  0.079654  0.211740  0.237915   \n",
       "3    0.073664  0.114170  0.218529  0.122037  0.143496  0.203789  0.309487   \n",
       "4    0.015711  0.143272  0.137247  0.073499  0.076554  0.222898  0.284347   \n",
       "5   -0.079742  0.095236 -0.003763 -0.057279 -0.029884  0.083431  0.074889   \n",
       "6    0.069322  0.097980  0.084701  0.126759  0.068219  0.272452  0.165449   \n",
       "7   -0.152635  0.029626 -0.015289  0.061833  0.023036  0.263355  0.214671   \n",
       "8   -0.395712 -0.079549 -0.208092 -0.267113 -0.269032  0.043462 -0.124646   \n",
       "9   -0.326336 -0.082070 -0.081708 -0.162793 -0.216118  0.296902  0.130639   \n",
       "10  -0.361904 -0.167232 -0.468011 -0.217991 -0.204485  0.255593 -0.040046   \n",
       "11  -0.473304 -0.547676 -0.623182 -0.312157 -0.296103  0.016107 -0.322330   \n",
       "12  -0.312686 -0.537834 -0.675650 -0.145455 -0.420748  0.035508 -0.333433   \n",
       "13  -0.354687 -0.540751 -0.865755 -0.391292 -0.747320 -0.128471 -0.333748   \n",
       "14  -0.638777 -0.353745 -0.966301 -0.402861 -0.947130 -0.435667 -0.076658   \n",
       "15  -0.419912 -0.375699 -0.656453 -0.633559 -0.807960 -0.096499 -0.082185   \n",
       "16  -0.445354 -0.495739 -0.685296 -0.486845 -0.864911 -0.033199  0.038888   \n",
       "17  -0.477452 -0.466505 -0.794798 -0.552558 -1.153417 -0.276803 -0.082676   \n",
       "18  -0.099147 -0.576819 -0.717625 -0.122438 -0.789810 -0.291432  0.216458   \n",
       "19  -0.113152 -0.570533 -0.702088  0.043746 -0.570542 -0.259183  0.219803   \n",
       "20  -0.323203 -0.590595 -0.789562 -0.072279 -0.616411 -0.414006  0.023212   \n",
       "21  -0.058303 -0.365979 -0.565663 -0.171717 -0.551598 -0.357620  0.158941   \n",
       "22  -0.233204 -0.297721 -0.627629 -0.059300 -0.644264 -0.272925  0.020266   \n",
       "23  -0.248857 -0.334185 -0.747993 -0.204458 -0.855434 -0.523904 -0.171296   \n",
       "24  -0.093952 -0.401348 -0.511480 -0.199117 -0.584999 -0.375725  0.094324   \n",
       "25  -0.119947 -0.343754 -0.617669 -0.138506 -0.511433 -0.202593  0.107486   \n",
       "26  -0.093150 -0.254877 -0.698188 -0.242192 -0.745568 -0.416388 -0.118242   \n",
       "27   0.221684 -0.257151 -0.443545 -0.128777 -0.491406 -0.125168  0.064521   \n",
       "28   0.299479 -0.025881 -0.414921 -0.269469 -0.372970 -0.043432  0.087166   \n",
       "29   0.241191 -0.068831 -0.495555 -0.026650 -0.295675  0.079657  0.054626   \n",
       "30   0.337732  0.084558 -0.149958  0.033765 -0.202761  0.176888  0.261455   \n",
       "31   0.283355  0.128282 -0.241447  0.024655 -0.064947  0.091273  0.101926   \n",
       "32   0.185705  0.067191 -0.260612  0.084107 -0.014142  0.211832  0.269871   \n",
       "33   0.092207  0.069459 -0.158306 -0.021449 -0.121075  0.099605  0.024841   \n",
       "34   0.239682  0.016767 -0.186858 -0.033404  0.096997  0.189631  0.271441   \n",
       "35   0.212452  0.028994 -0.008484 -0.006845  0.262018  0.184854  0.271847   \n",
       "36   0.272077  0.183770  0.115216 -0.052327  0.244866  0.318728  0.198468   \n",
       "37   0.229940  0.153350  0.073676 -0.001591  0.236449  0.388763  0.264150   \n",
       "38   0.208968  0.086676  0.047656 -0.046397  0.260369  0.265992  0.313851   \n",
       "39   0.237435  0.055339 -0.011992 -0.042440  0.232035  0.223379  0.266863   \n",
       "40   0.244132  0.017398 -0.009038 -0.108043  0.150473  0.271137  0.275452   \n",
       "41   0.118393  0.066472 -0.085083 -0.038057  0.170126  0.361744  0.328254   \n",
       "42   0.112445  0.071174 -0.069540 -0.035583  0.173278  0.334832  0.305024   \n",
       "43   0.110832  0.013992 -0.026704 -0.044224  0.169486  0.335513  0.325394   \n",
       "44   0.091251 -0.010096 -0.090371  0.002733  0.141285  0.306524  0.317829   \n",
       "45   0.121130  0.086170  0.051572  0.014885  0.176143  0.304544  0.328401   \n",
       "46   0.077376  0.057850  0.042899 -0.039426  0.195169  0.279856  0.246526   \n",
       "47   0.079092  0.066502  0.041553 -0.025986  0.167237  0.188677  0.216455   \n",
       "48   0.118458  0.147674  0.026512 -0.028662  0.193007  0.168648  0.216027   \n",
       "49   0.108690  0.099256 -0.006159 -0.015199  0.186492  0.232423  0.215168   \n",
       "50   0.026312  0.067750 -0.002671 -0.057931  0.259651  0.239921  0.168358   \n",
       "51   0.091878  0.028262  0.024051 -0.008254  0.249992  0.275069  0.197814   \n",
       "52   0.171288  0.040411  0.120935  0.076483  0.306322  0.306045  0.299105   \n",
       "53   0.154015  0.075607  0.102427  0.032202  0.307978  0.425528  0.393017   \n",
       "54   0.187899  0.089427  0.123973  0.152481  0.357232  0.494137  0.406453   \n",
       "55   0.209309  0.051752  0.206793  0.122946  0.289489  0.430624  0.411857   \n",
       "56   0.133118 -0.011669  0.208242  0.214479  0.276153  0.356256  0.394918   \n",
       "57   0.150503  0.094728  0.172332  0.263880  0.278361  0.335092  0.420163   \n",
       "58  -0.002531  0.121276  0.054148  0.280607  0.106176  0.263749  0.372157   \n",
       "59   0.021983  0.004220 -0.071096  0.254715  0.097273  0.186482  0.264510   \n",
       "60   0.033865  0.021468 -0.033778  0.256992  0.106336  0.117153  0.368631   \n",
       "61  -0.026289 -0.022548 -0.106799  0.168658  0.077554 -0.000632  0.169330   \n",
       "62  -0.023880  0.081796 -0.185402  0.116585 -0.003554  0.050576  0.171311   \n",
       "63   0.068259  0.073943 -0.063131  0.183850  0.118494  0.144145  0.312818   \n",
       "64   0.051134  0.111172 -0.054856  0.078304  0.135942  0.118119  0.313867   \n",
       "65   0.121676  0.180153 -0.056253  0.140799  0.119376  0.192166  0.382296   \n",
       "66   0.261501  0.209623 -0.020533  0.187423  0.120617  0.233983  0.420320   \n",
       "67   0.126617  0.112898 -0.134353  0.194511  0.118138  0.211480  0.354434   \n",
       "68   0.115669  0.095581 -0.186018  0.171120  0.178077  0.162684  0.376077   \n",
       "69   0.038328  0.045418 -0.165224  0.182389  0.154289  0.119844  0.298279   \n",
       "70   0.000049 -0.087980 -0.249652  0.107834  0.067670  0.024569  0.231282   \n",
       "71  -0.074688 -0.237860 -0.241578 -0.000081  0.052596 -0.040789  0.184230   \n",
       "72  -0.065862 -0.282193 -0.335128 -0.067223  0.111335  0.039531  0.294426   \n",
       "73  -0.076830 -0.130516 -0.320829 -0.017380  0.003471  0.069318  0.312470   \n",
       "74  -0.063256 -0.114401 -0.266884 -0.004511  0.019436  0.138579  0.332169   \n",
       "75   0.129363 -0.118152 -0.184310  0.044556  0.298683  0.315979  0.562805   \n",
       "76   0.251120 -0.009689  0.011182  0.175504  0.363160  0.471729  0.666759   \n",
       "77   0.427792  0.047097  0.145848  0.225138  0.459016  0.605141  0.819142   \n",
       "78   0.432496 -0.049455  0.259924  0.264217  0.428149  0.773973  0.948736   \n",
       "79   0.645435  0.027889  0.299346  0.185867  0.577934  0.683297  0.948945   \n",
       "80   0.731511  0.027617  0.334726  0.419937  0.617568  0.886158  1.030034   \n",
       "81   0.653323  0.155283  0.340502  0.347349  0.493239  0.742252  0.871831   \n",
       "82   0.540177  0.127168  0.177339  0.329594  0.510804  0.645280  0.860413   \n",
       "83   0.550843  0.169514  0.178027  0.361779  0.571700  0.634739  0.791566   \n",
       "84   0.450493  0.205030  0.163388  0.379862  0.590442  0.527619  0.763699   \n",
       "85   0.410042  0.134144  0.191325  0.445950  0.498748  0.582979  0.725865   \n",
       "86   0.355135  0.170543  0.168009  0.254453  0.444263  0.520952  0.650190   \n",
       "87   0.371799  0.078531  0.056648  0.319930  0.449228  0.506252  0.672351   \n",
       "88   0.410381  0.148628  0.111801  0.302135  0.391321  0.557881  0.712781   \n",
       "89   0.440235  0.134752  0.160970  0.266348  0.461098  0.613223  0.779891   \n",
       "90   0.375384  0.134247  0.064683  0.237875  0.333110  0.555581  0.675226   \n",
       "91   0.352291  0.177269  0.033638  0.218599  0.352150  0.484300  0.663605   \n",
       "92   0.212316  0.183916  0.010849  0.200531  0.354037  0.476189  0.539305   \n",
       "93   0.050777  0.074348 -0.181897  0.126385  0.200468  0.324676  0.418355   \n",
       "94   0.011865  0.062157 -0.226055  0.158684  0.136097  0.269875  0.441153   \n",
       "95   0.054278  0.031232 -0.256227  0.078062  0.075380  0.228836  0.371564   \n",
       "96   0.041047  0.016671 -0.278156  0.019467  0.119749  0.162504  0.420302   \n",
       "97  -0.059629  0.043723 -0.471178  0.044962  0.014763  0.150542  0.304952   \n",
       "98   0.043697  0.109260 -0.449822 -0.072803 -0.063742  0.159645  0.313794   \n",
       "99   0.090776  0.182251 -0.363128  0.017907  0.106449  0.076399  0.376933   \n",
       "100 -0.105912 -0.009384 -0.475569 -0.176435  0.243234 -0.025413  0.142753   \n",
       "101  0.032943 -0.063721 -0.507996 -0.055573  0.024760 -0.189479  0.151669   \n",
       "102 -0.230056 -0.106300 -0.605046 -0.229202 -0.250253  0.005511  0.162587   \n",
       "103 -0.143011  0.010427 -0.861107 -0.254331 -0.161759  0.214745  0.178630   \n",
       "104 -0.006256 -0.103728 -0.998415 -0.195316 -0.228807  0.161459  0.152784   \n",
       "105 -0.031460 -0.260787 -0.559287 -0.137322 -0.178411  0.274208  0.168569   \n",
       "106 -0.084128 -0.335501 -0.604485 -0.124787 -0.133445  0.331794  0.105614   \n",
       "107 -0.095682 -0.417488 -0.691892 -0.139024  0.026213  0.425503  0.028687   \n",
       "108 -0.200797 -0.536283 -0.628329 -0.119022  0.029400  0.524026  0.097524   \n",
       "109 -0.296055 -0.298226 -0.904540 -0.231394  0.148490  0.488239 -0.013178   \n",
       "110 -0.407144 -0.506276 -0.926600 -0.270373 -0.001969  0.250637  0.063079   \n",
       "111 -0.473407 -0.493203 -1.032583 -0.407980 -0.006201  0.264895  0.016894   \n",
       "112 -0.357368 -0.455566 -1.082246 -0.423261  0.036216  0.242148  0.081271   \n",
       "113 -0.358538 -0.384976 -0.998727 -0.362298  0.039698  0.220972  0.056180   \n",
       "114 -0.355641 -0.386211 -0.908888 -0.363824 -0.051279  0.116043  0.069190   \n",
       "115 -0.461110 -0.527689 -0.982047 -0.232629 -0.108000  0.093951  0.030405   \n",
       "116 -0.394979 -0.654648 -1.200779 -0.245519 -0.114103  0.026339  0.073910   \n",
       "117 -0.444471 -0.744455 -1.144983 -0.238167 -0.066611 -0.071252 -0.046452   \n",
       "118 -0.407348 -0.766622 -1.046936 -0.264029  0.010924 -0.098146  0.041975   \n",
       "119 -0.294956 -0.765670 -0.996639 -0.245609  0.043436 -0.106868  0.076046   \n",
       "120 -0.226531 -0.624858 -1.045833 -0.216664  0.103967  0.034409  0.248085   \n",
       "121 -0.139772 -0.492243 -0.990570 -0.217012  0.122755  0.120765  0.270357   \n",
       "122 -0.208736 -0.437711 -0.940507 -0.273828  0.170205  0.162187  0.162759   \n",
       "123 -0.120491 -0.428808 -0.925936 -0.185805  0.159544  0.070507  0.106393   \n",
       "\n",
       "       188157    183257    137432    9846      65671     10232     12216   \\\n",
       "0    0.367288  0.302574  0.209094  0.198159  0.209285  0.215278  0.195743   \n",
       "1    0.231324  0.182667  0.155974  0.161146  0.141840  0.202451  0.155033   \n",
       "2    0.120882  0.070739 -0.026516  0.046043 -0.003559  0.183392  0.007820   \n",
       "3    0.211944  0.085880  0.067252  0.065528 -0.017248  0.367542  0.099089   \n",
       "4    0.205669  0.013518  0.067326  0.024752 -0.021081  0.268664  0.075927   \n",
       "5    0.124714 -0.068619 -0.067247 -0.100649 -0.155613  0.209775 -0.088601   \n",
       "6    0.233261  0.105181  0.057028  0.031725 -0.016970  0.298982  0.036071   \n",
       "7    0.009440 -0.003504  0.011736  0.056222 -0.075485  0.204089 -0.045828   \n",
       "8   -0.154744 -0.218230 -0.178641 -0.157338 -0.319617  0.130286 -0.246706   \n",
       "9   -0.123317 -0.129727  0.020368 -0.080409  0.003145  0.199008 -0.014780   \n",
       "10  -0.024514 -0.297009  0.145356  0.004218 -0.007344  0.257123 -0.260728   \n",
       "11  -0.305331 -0.561365 -0.251529 -0.364605 -0.255505 -0.065601 -0.565420   \n",
       "12  -0.377377 -0.649795 -0.272984 -0.304594 -0.334070 -0.315408 -0.858876   \n",
       "13  -0.462422 -0.801041 -0.303570 -0.222938 -0.246239 -0.356380 -0.690930   \n",
       "14  -0.497688 -1.072940 -0.369848 -0.210237 -0.210895 -0.483279 -0.844235   \n",
       "15  -0.187428 -0.997987 -0.241157 -0.284238 -0.128679 -0.086361 -0.526763   \n",
       "16  -0.186348 -1.060373 -0.179427 -0.126552 -0.146691 -0.405920 -0.595306   \n",
       "17  -0.210985 -1.190040 -0.096890 -0.373259 -0.304887 -0.226744 -0.853855   \n",
       "18   0.074015 -0.919503  0.254655 -0.253172 -0.001306 -0.023094 -0.325656   \n",
       "19  -0.130700 -0.957726  0.135747  0.177071 -0.170973  0.213725 -0.356890   \n",
       "20  -0.111910 -1.019267 -0.126561 -0.032537 -0.243629 -0.163071 -0.638171   \n",
       "21  -0.046497 -0.871112 -0.069697 -0.035745 -0.186854 -0.162032 -0.582020   \n",
       "22  -0.180071 -1.150598 -0.018256  0.022773  0.027153 -0.318072 -0.439517   \n",
       "23  -0.327118 -1.180107 -0.160041 -0.218263 -0.144482 -0.426617 -0.559686   \n",
       "24  -0.161325 -1.064787  0.045012 -0.191031 -0.092878 -0.176216 -0.513977   \n",
       "25  -0.171895 -1.014368  0.124855 -0.160450  0.062563 -0.292424 -0.393284   \n",
       "26  -0.371322 -1.072381 -0.072901 -0.139292 -0.097723 -0.316012 -0.572853   \n",
       "27  -0.006716 -0.813251  0.133657 -0.062038  0.037017 -0.054493 -0.433926   \n",
       "28  -0.049431 -0.703887  0.325597 -0.099760 -0.073830  0.005494 -0.421843   \n",
       "29  -0.161373 -0.696140  0.219122 -0.056401 -0.263356  0.026452 -0.397401   \n",
       "30   0.092872 -0.556546  0.236991  0.031084 -0.117949  0.158459 -0.367730   \n",
       "31   0.166767 -0.354895  0.267401  0.015954 -0.302673  0.213345 -0.174456   \n",
       "32   0.050864 -0.424314  0.395322  0.062009 -0.118675  0.177033 -0.160424   \n",
       "33   0.012963 -0.441962  0.175487  0.083897 -0.169306  0.100601 -0.324354   \n",
       "34   0.159305 -0.266150  0.213640  0.239561 -0.150573  0.144969 -0.259650   \n",
       "35   0.115913 -0.060793  0.135884  0.207226  0.109689  0.233840 -0.102682   \n",
       "36   0.195519 -0.027727  0.067549  0.240249  0.141516  0.235544 -0.037572   \n",
       "37   0.168034  0.041388  0.038507  0.192907  0.160682  0.272291  0.056607   \n",
       "38   0.304539  0.066747  0.144210  0.134072  0.224165  0.336483  0.103389   \n",
       "39   0.147200  0.039996  0.094997  0.162328  0.137864  0.216822  0.017387   \n",
       "40   0.188434  0.141179  0.053046  0.147330  0.170623  0.248383  0.154533   \n",
       "41   0.196131  0.125258  0.135561  0.135682  0.134484  0.295801  0.130443   \n",
       "42   0.134222  0.082485  0.114683  0.150533  0.127184  0.260715  0.119747   \n",
       "43   0.149996  0.129051  0.079284  0.133319  0.103259  0.223445  0.114011   \n",
       "44   0.106359  0.117060  0.150110  0.116383  0.106592  0.216880  0.073806   \n",
       "45   0.093039  0.172392  0.116871  0.189424  0.140577  0.237462  0.082102   \n",
       "46   0.129622  0.145211  0.057704  0.213794  0.074806  0.236637  0.015125   \n",
       "47   0.116040  0.151626 -0.032688  0.116451  0.065548  0.216217  0.043726   \n",
       "48   0.125948  0.168217 -0.019208  0.116808  0.099276  0.293212  0.072510   \n",
       "49   0.081099  0.185889 -0.068452  0.104821  0.107632  0.305360  0.107356   \n",
       "50   0.075303  0.168857 -0.012798  0.050117  0.123670  0.257548  0.204139   \n",
       "51   0.122857  0.117712  0.055132  0.046964  0.192510  0.395373  0.180430   \n",
       "52   0.232276  0.192978  0.079203  0.141386  0.267995  0.485828  0.283842   \n",
       "53   0.181757  0.214637  0.236302  0.187417  0.292921  0.434479  0.284318   \n",
       "54   0.239350  0.287791  0.346295  0.344147  0.363749  0.429845  0.306157   \n",
       "55   0.306197  0.304576  0.289548  0.261257  0.361785  0.370141  0.229574   \n",
       "56   0.226345  0.327706  0.213627  0.288251  0.260669  0.364902  0.176811   \n",
       "57   0.261674  0.326497  0.225491  0.314413  0.294526  0.362024  0.212999   \n",
       "58   0.239144  0.214807  0.234057  0.225468  0.333460  0.251943  0.226732   \n",
       "59   0.224768  0.144749  0.271956  0.166504  0.295199  0.161507  0.190426   \n",
       "60   0.236423  0.099360  0.249822  0.167338  0.273093  0.236997  0.120677   \n",
       "61   0.206034 -0.002725  0.117606  0.124846  0.257664  0.091419  0.037722   \n",
       "62   0.200667 -0.025147  0.147270  0.128180  0.262923  0.051957 -0.037389   \n",
       "63   0.315135  0.040921  0.200504  0.164189  0.360917  0.125662  0.117169   \n",
       "64   0.308086 -0.012693  0.146533  0.172051  0.361804  0.099609  0.073463   \n",
       "65   0.329788  0.024349  0.181619  0.196882  0.373459  0.124085  0.166430   \n",
       "66   0.407405  0.040060  0.275832  0.209819  0.477809  0.213916  0.239012   \n",
       "67   0.415182  0.017530  0.253663  0.250597  0.439696  0.188176  0.177375   \n",
       "68   0.375000  0.016078  0.183161  0.338651  0.400229  0.158054  0.160862   \n",
       "69   0.299123 -0.106252  0.163446  0.287102  0.308370  0.106916  0.090034   \n",
       "70   0.280085 -0.216353  0.105581  0.270153  0.276174  0.057206 -0.003538   \n",
       "71   0.185114 -0.232827 -0.055294  0.208907  0.194934  0.014166 -0.012432   \n",
       "72   0.228230 -0.126687  0.017197  0.180796  0.222381  0.069607 -0.029327   \n",
       "73   0.134519 -0.135219  0.007036  0.192897  0.290739 -0.011786 -0.032248   \n",
       "74   0.232928 -0.086077  0.110410  0.221553  0.294135 -0.023490  0.082489   \n",
       "75   0.452498  0.057792  0.298391  0.236111  0.456461  0.181523  0.260428   \n",
       "76   0.444359  0.252108  0.299098  0.298665  0.558421  0.147990  0.469864   \n",
       "77   0.377721  0.397509  0.455313  0.452775  0.487407  0.257942  0.517118   \n",
       "78   0.489221  0.383428  0.523475  0.589762  0.618416  0.170393  0.568347   \n",
       "79   0.729909  0.468352  0.650926  0.535800  0.550536  0.343096  0.547598   \n",
       "80   0.852172  0.552298  0.539232  0.698426  0.655720  0.443543  0.650264   \n",
       "81   0.716868  0.518277  0.504939  0.648966  0.503269  0.475469  0.489889   \n",
       "82   0.768017  0.454190  0.431523  0.573306  0.507160  0.354401  0.415357   \n",
       "83   0.844083  0.377910  0.453375  0.562732  0.627387  0.446985  0.523615   \n",
       "84   0.828596  0.468224  0.307312  0.537819  0.608547  0.425488  0.435829   \n",
       "85   0.585391  0.408426  0.198118  0.583074  0.598683  0.415132  0.452948   \n",
       "86   0.638950  0.393521  0.196680  0.509478  0.582740  0.323506  0.428957   \n",
       "87   0.626087  0.336397  0.227441  0.466806  0.536561  0.222848  0.445115   \n",
       "88   0.620094  0.355353  0.322753  0.451941  0.489417  0.310851  0.452212   \n",
       "89   0.583693  0.401960  0.299508  0.417287  0.468878  0.283189  0.449302   \n",
       "90   0.502286  0.301345  0.295643  0.391856  0.466215  0.245626  0.328557   \n",
       "91   0.580379  0.300572  0.299785  0.341885  0.416513  0.236834  0.317504   \n",
       "92   0.462062  0.209154  0.269202  0.341964  0.391065  0.192925  0.217464   \n",
       "93   0.348062  0.095623  0.189524  0.293168  0.209746  0.072617  0.125952   \n",
       "94   0.291157  0.087147  0.153955  0.319744  0.307323 -0.046223  0.185424   \n",
       "95   0.354360  0.048680  0.199520  0.305659  0.344864 -0.068835  0.077109   \n",
       "96   0.405568  0.010130  0.181122  0.292486  0.252121 -0.031053  0.120854   \n",
       "97   0.323823 -0.080780  0.089348  0.210250  0.294519 -0.227811  0.083205   \n",
       "98   0.383455 -0.121095  0.125035  0.235514  0.356154 -0.197161  0.020281   \n",
       "99   0.515313  0.117376  0.143870  0.249972  0.346916 -0.172421  0.079740   \n",
       "100  0.247872  0.013244  0.266356  0.170271  0.359759 -0.332601  0.161123   \n",
       "101  0.190592  0.213512  0.101837  0.183858  0.169553 -0.185534  0.162440   \n",
       "102  0.120182  0.081261  0.006963  0.081847  0.212915 -0.205681  0.051942   \n",
       "103  0.125751  0.132565  0.019563 -0.050050  0.041839 -0.106710  0.073896   \n",
       "104 -0.006901  0.124758  0.004892 -0.194107 -0.115874 -0.047685  0.072811   \n",
       "105  0.076340  0.105762 -0.049116  0.103312 -0.053807  0.178113 -0.049179   \n",
       "106  0.091405  0.196956 -0.193518  0.261353 -0.157694  0.194749 -0.138098   \n",
       "107  0.043396  0.055553 -0.282512  0.147766 -0.240160  0.256720 -0.427631   \n",
       "108  0.199408  0.054746 -0.232358  0.343331 -0.002036  0.227223 -0.516567   \n",
       "109  0.197644  0.059067 -0.156554  0.211850  0.042462  0.065064 -0.361115   \n",
       "110  0.045365 -0.330692  0.051531 -0.050101  0.051361 -0.139920 -0.228524   \n",
       "111  0.121520 -0.299160  0.006799 -0.235790 -0.058078 -0.046172 -0.354483   \n",
       "112  0.119610 -0.343998  0.049478 -0.264148  0.024313 -0.182029 -0.388488   \n",
       "113  0.003732 -0.354246 -0.047236 -0.109261  0.029531 -0.273708 -0.274871   \n",
       "114  0.002944 -0.413427 -0.092029 -0.085912  0.066186 -0.337785 -0.266735   \n",
       "115 -0.019029 -0.568640 -0.133166  0.001238  0.064632 -0.369495 -0.296756   \n",
       "116  0.088317 -0.607866 -0.095426  0.064096  0.078445 -0.488434 -0.471657   \n",
       "117 -0.047508 -0.695491 -0.229231  0.038493 -0.018503 -0.534885 -0.440296   \n",
       "118 -0.062352 -0.647332 -0.217655  0.074673 -0.027880 -0.516483 -0.430003   \n",
       "119 -0.077551 -0.502347 -0.188983  0.095772  0.042700 -0.453009 -0.373247   \n",
       "120  0.195723 -0.420404 -0.093614  0.101983  0.108455 -0.347899 -0.307311   \n",
       "121  0.150552 -0.349848 -0.067147  0.034033  0.137926 -0.366197 -0.324328   \n",
       "122  0.142317 -0.419040 -0.056057 -0.000698  0.183894 -0.427290 -0.156654   \n",
       "123  0.123094 -0.377343 -0.014202 -0.012162  0.116930 -0.364892 -0.199911   \n",
       "\n",
       "       20089     1718      112754    163118    180466    27965     144235  \\\n",
       "0    0.352122  0.253826  0.348131  0.219558  0.269325  0.266666  0.347717   \n",
       "1    0.245930  0.217812  0.306169  0.109960  0.157142  0.217545  0.298609   \n",
       "2    0.175308  0.073529  0.110757  0.064913  0.144177  0.068862  0.083351   \n",
       "3    0.249496  0.059909  0.128803  0.048902  0.216848  0.147681  0.112468   \n",
       "4    0.209668 -0.019635  0.114066  0.098024  0.184648  0.107594  0.083285   \n",
       "5    0.112394 -0.070185  0.026698 -0.073622  0.109167 -0.038995 -0.073830   \n",
       "6    0.240418 -0.019781  0.095429  0.190542  0.131572  0.130716  0.047422   \n",
       "7    0.235217 -0.048512  0.218550  0.180063 -0.109804 -0.045635  0.072894   \n",
       "8   -0.116321 -0.413040 -0.039938 -0.097018 -0.173248 -0.292369 -0.137237   \n",
       "9    0.229470 -0.309483  0.079347  0.020901  0.080169 -0.286900 -0.109094   \n",
       "10   0.236208 -0.342761 -0.106322 -0.185359 -0.014785 -0.614176 -0.077744   \n",
       "11   0.174470 -0.482054 -0.420815 -0.408419 -0.408951 -0.730861 -0.222490   \n",
       "12  -0.038033 -0.720228 -0.163709 -0.411480 -0.663141 -0.856824 -0.120436   \n",
       "13  -0.166254 -0.983501 -0.284073 -0.355618 -0.990834 -0.736393 -0.302266   \n",
       "14  -0.343883 -1.133619 -0.292958 -0.308613 -0.750303 -0.815577 -0.376557   \n",
       "15  -0.171466 -0.842419 -0.347031 -0.197935 -0.443031 -0.530300 -0.257730   \n",
       "16  -0.069270 -0.777290 -0.425913 -0.428001 -0.645835 -0.755365 -0.063607   \n",
       "17  -0.177248 -0.637043 -0.469824 -0.588503 -0.726256 -0.941813 -0.302522   \n",
       "18   0.103543 -0.322369 -0.223730 -0.171729 -0.437926 -0.595665 -0.161409   \n",
       "19   0.153675 -0.252570 -0.119382 -0.089626 -0.306704 -0.627201 -0.212944   \n",
       "20  -0.353071 -0.378975 -0.424863 -0.495467 -0.465294 -0.668326 -0.240808   \n",
       "21  -0.278005 -0.478323 -0.104313 -0.691665 -0.394297 -0.400157 -0.277395   \n",
       "22  -0.372117 -0.473702  0.006629 -0.797097 -0.545798 -0.516350 -0.337099   \n",
       "23  -0.447109 -0.594312 -0.235571 -0.895917 -0.656339 -0.716629 -0.485110   \n",
       "24  -0.293423 -0.346215 -0.014445 -0.622958 -0.440341 -0.525846 -0.356794   \n",
       "25  -0.177934 -0.272332 -0.035252 -0.598175 -0.553891 -0.457386 -0.368328   \n",
       "26  -0.295231 -0.412721 -0.215055 -0.793909 -0.579305 -0.632328 -0.460615   \n",
       "27  -0.125769 -0.230832  0.065305 -0.527434 -0.307529 -0.409877 -0.134882   \n",
       "28   0.219003 -0.138713  0.086654 -0.404976 -0.290044 -0.367531  0.021847   \n",
       "29   0.020473  0.034212 -0.062282 -0.446012 -0.305546 -0.249090 -0.096218   \n",
       "30   0.280027  0.154771  0.147339 -0.205356 -0.036759 -0.047753  0.135499   \n",
       "31   0.348848  0.228108  0.150428 -0.063813 -0.043208 -0.084307  0.184320   \n",
       "32   0.226826  0.290298  0.105610 -0.205263  0.020716  0.161832  0.118702   \n",
       "33   0.162320  0.100761 -0.087295 -0.064072 -0.090819  0.076418 -0.035717   \n",
       "34   0.315856  0.123701  0.057455  0.064231 -0.033810  0.200677  0.147455   \n",
       "35   0.375502  0.177606  0.029015  0.120448  0.145122  0.242722  0.246002   \n",
       "36   0.383390  0.262143 -0.142080  0.186038  0.118690  0.210716  0.314643   \n",
       "37   0.484368  0.229158 -0.075726  0.280287  0.128606  0.253850  0.367582   \n",
       "38   0.506623  0.260113  0.034380  0.383385  0.112884  0.304894  0.462505   \n",
       "39   0.417009  0.304360  0.048029  0.358203  0.129994  0.214830  0.415176   \n",
       "40   0.492197  0.245277  0.105691  0.370964  0.133152  0.187532  0.442611   \n",
       "41   0.399116  0.283122  0.047819  0.269629  0.060521  0.195798  0.375945   \n",
       "42   0.433899  0.211382  0.028118  0.246711  0.004060  0.184720  0.370142   \n",
       "43   0.424805  0.167258  0.001023  0.231628 -0.004985  0.153718  0.364236   \n",
       "44   0.408572  0.148984 -0.037699  0.223690 -0.049333  0.147138  0.319742   \n",
       "45   0.411423  0.179017 -0.066061  0.278528 -0.021790  0.250669  0.336252   \n",
       "46   0.340918  0.147206 -0.105339  0.247464 -0.018838  0.177978  0.330272   \n",
       "47   0.381771  0.096489 -0.025495  0.173611  0.007723  0.171467  0.345834   \n",
       "48   0.304324  0.176478  0.011075  0.266013  0.030060  0.213260  0.269361   \n",
       "49   0.391568  0.136449  0.031318  0.305214  0.054801  0.264640  0.290637   \n",
       "50   0.346479  0.056906  0.142350  0.301902  0.073265  0.166516  0.284892   \n",
       "51   0.355474  0.132615  0.260949  0.295228  0.157305  0.173153  0.377902   \n",
       "52   0.432719  0.140901  0.261151  0.279842  0.188940  0.263056  0.384571   \n",
       "53   0.460856  0.168763  0.262524  0.357582  0.131950  0.210581  0.380608   \n",
       "54   0.535291  0.175332  0.191405  0.385754  0.167129  0.231705  0.516689   \n",
       "55   0.380801  0.196846  0.174951  0.369359  0.116365  0.141429  0.433157   \n",
       "56   0.360618  0.170794  0.122981  0.269434  0.039005  0.136582  0.389441   \n",
       "57   0.366234  0.201379  0.122230  0.372495  0.063357  0.183368  0.295628   \n",
       "58   0.392620  0.125993  0.145961  0.332198  0.054221  0.100158  0.261788   \n",
       "59   0.328642  0.035156  0.093698  0.286002 -0.042589  0.090785  0.224669   \n",
       "60   0.276351  0.075609  0.174477  0.203336 -0.042460  0.003001  0.196690   \n",
       "61   0.246602 -0.058531  0.128115  0.160145 -0.131508 -0.037176  0.181015   \n",
       "62   0.224305 -0.109834  0.138318  0.075062 -0.161301 -0.118933  0.079499   \n",
       "63   0.246564  0.019497  0.148266  0.226875 -0.065951  0.067944  0.203365   \n",
       "64   0.292342  0.041935  0.210255  0.239872 -0.119767  0.023541  0.235662   \n",
       "65   0.277997  0.043119  0.220648  0.204421 -0.105685  0.037251  0.216162   \n",
       "66   0.358995  0.057843  0.269562  0.345200  0.069818  0.114976  0.161174   \n",
       "67   0.408374  0.016981  0.230863  0.358755  0.015781  0.102055  0.179922   \n",
       "68   0.345718 -0.006819  0.260063  0.340603 -0.003565  0.007383  0.216943   \n",
       "69   0.340154 -0.039969  0.136596  0.341631 -0.170410 -0.084060  0.173387   \n",
       "70   0.247633 -0.193673 -0.012859  0.194574 -0.186651 -0.218310  0.029517   \n",
       "71   0.153190 -0.302165 -0.001414  0.207016 -0.135902 -0.286887  0.080874   \n",
       "72   0.227664 -0.300895  0.015381  0.212895 -0.116654 -0.225244  0.050365   \n",
       "73   0.224480 -0.283836  0.033439  0.132340 -0.131370 -0.214970  0.088088   \n",
       "74   0.198593 -0.256112  0.086844  0.214365 -0.167833 -0.203541  0.117047   \n",
       "75   0.416620 -0.062598  0.305420  0.325000  0.069247  0.007621  0.448820   \n",
       "76   0.508411  0.104035  0.352197  0.488056  0.198769  0.103764  0.575307   \n",
       "77   0.654881  0.174017  0.378032  0.518292  0.162722  0.230643  0.584960   \n",
       "78   0.719403  0.237492  0.342650  0.674513  0.251111  0.235644  0.708350   \n",
       "79   0.666145  0.326516  0.338305  0.636876  0.425427  0.179918  0.725300   \n",
       "80   0.884753  0.494539  0.291224  0.658520  0.614026  0.355676  0.785687   \n",
       "81   0.795440  0.394902  0.188715  0.634860  0.441845  0.181569  0.554260   \n",
       "82   0.758171  0.376423  0.244202  0.615304  0.453764  0.240648  0.551837   \n",
       "83   0.736818  0.313616  0.246600  0.610211  0.470719  0.290408  0.583737   \n",
       "84   0.552461  0.311971  0.232068  0.539785  0.442470  0.350903  0.567352   \n",
       "85   0.611850  0.181933  0.348222  0.590861  0.355012  0.410044  0.521039   \n",
       "86   0.502316  0.116351  0.383532  0.525823  0.323461  0.282386  0.511636   \n",
       "87   0.461410  0.142464  0.396865  0.416947  0.317448  0.214240  0.468953   \n",
       "88   0.469516  0.190634  0.304952  0.409768  0.332938  0.230797  0.463954   \n",
       "89   0.530198  0.253528  0.354477  0.492180  0.345396  0.248476  0.449737   \n",
       "90   0.618325  0.141313  0.283012  0.408491  0.255798  0.150438  0.464946   \n",
       "91   0.501193  0.143010  0.279859  0.315758  0.240825  0.109455  0.429027   \n",
       "92   0.464096  0.064293  0.176050  0.303656  0.136063  0.111042  0.389124   \n",
       "93   0.372574 -0.032602  0.074431  0.152314  0.050750 -0.047935  0.229171   \n",
       "94   0.399050 -0.069682  0.098887  0.146587  0.079765 -0.057666  0.214238   \n",
       "95   0.402443 -0.086878 -0.074477  0.176115 -0.023592 -0.068868  0.171690   \n",
       "96   0.387814 -0.072154 -0.017399  0.117944 -0.051100 -0.099568  0.169706   \n",
       "97   0.296290 -0.059819 -0.020285  0.074707 -0.173353 -0.141329  0.091311   \n",
       "98   0.301711 -0.032721 -0.098900  0.093370 -0.310110 -0.093888  0.106394   \n",
       "99   0.325000  0.033850 -0.132233  0.375060 -0.216929  0.025901  0.188875   \n",
       "100  0.470010  0.084470 -0.024247  0.352142 -0.202780 -0.085382  0.340767   \n",
       "101  0.320189  0.096207 -0.029831  0.290575 -0.152706 -0.196288  0.436943   \n",
       "102  0.191335 -0.126508  0.184524  0.207141 -0.265420 -0.307064  0.333149   \n",
       "103  0.575488 -0.258363  0.182165  0.037481 -0.230483 -0.271915  0.319029   \n",
       "104  0.608588 -0.238325  0.105529  0.069604  0.011442 -0.353805  0.298706   \n",
       "105  0.721278 -0.340353  0.012205 -0.012463 -0.168979 -0.521436  0.542542   \n",
       "106  0.464695 -0.431526 -0.124109 -0.021795 -0.278921 -0.602953  0.229912   \n",
       "107  0.616692 -0.484862 -0.230161  0.032591 -0.224364 -0.586135 -0.023670   \n",
       "108  0.468056 -0.458783 -0.239627  0.299717 -0.140644 -0.363761 -0.012720   \n",
       "109  0.332055 -0.521644 -0.145104  0.098012 -0.080606 -0.474197 -0.144435   \n",
       "110  0.046876 -0.520904 -0.225409 -0.044308 -0.265053 -0.655629 -0.004615   \n",
       "111 -0.032015 -0.639005 -0.206611  0.015567 -0.345981 -0.762888 -0.116998   \n",
       "112 -0.000909 -0.602391 -0.133452  0.097764 -0.383680 -0.637301  0.038735   \n",
       "113 -0.129552 -0.578049 -0.137655 -0.195747 -0.371047 -0.774954  0.070769   \n",
       "114 -0.191787 -0.618790 -0.187768 -0.203289 -0.335110 -0.737838  0.103255   \n",
       "115 -0.100821 -0.619203 -0.204114 -0.109604 -0.364762 -0.873383  0.063146   \n",
       "116 -0.191620 -0.603220 -0.314101 -0.181082 -0.451622 -0.892360 -0.128866   \n",
       "117 -0.197332 -0.603499 -0.406680 -0.225973 -0.536200 -0.851003 -0.117746   \n",
       "118 -0.280274 -0.680702 -0.473448 -0.385390 -0.502434 -0.830922 -0.214442   \n",
       "119 -0.226439 -0.612182 -0.342223 -0.248134 -0.476690 -0.696992 -0.167651   \n",
       "120 -0.158280 -0.462670 -0.333382 -0.136108 -0.354866 -0.563184 -0.089638   \n",
       "121 -0.139339 -0.375902 -0.216955 -0.153289 -0.365351 -0.440958 -0.109694   \n",
       "122 -0.218152 -0.469086 -0.221055 -0.157905 -0.392356 -0.514626 -0.012270   \n",
       "123 -0.228716 -0.444896 -0.134398 -0.198605 -0.340516 -0.664790 -0.072915   \n",
       "\n",
       "       24832     2271      127282    19580     116504    20949     182701  \\\n",
       "0    0.284155  0.271331  0.216798  0.271040  0.271145  0.195531  0.262811   \n",
       "1    0.235861  0.213686 -0.018245  0.252988  0.157969  0.216606  0.195708   \n",
       "2    0.177589  0.206479 -0.025643  0.194804  0.088915  0.103093  0.031859   \n",
       "3    0.089752  0.166870  0.102114  0.103849  0.102405  0.152297  0.159705   \n",
       "4    0.102307  0.142782  0.119033  0.125184  0.156690  0.207526  0.041764   \n",
       "5   -0.020948 -0.025234  0.115233 -0.028842  0.092637  0.161262 -0.086275   \n",
       "6    0.148510  0.115993  0.127789  0.106464  0.146827  0.224910  0.060305   \n",
       "7    0.137141  0.136315  0.086111  0.035894  0.150088  0.101508  0.067199   \n",
       "8   -0.236763 -0.041914  0.002008 -0.204750  0.089817 -0.247513 -0.133512   \n",
       "9   -0.130708  0.149289  0.199875 -0.080769  0.157991  0.132997 -0.194768   \n",
       "10  -0.217088 -0.014837  0.180212 -0.238953 -0.022820  0.015202 -0.321828   \n",
       "11  -0.295325 -0.201226  0.036253 -0.375870 -0.294305 -0.102914 -0.415590   \n",
       "12  -0.241743 -0.274898  0.054365 -0.439969 -0.249143 -0.365627 -0.325716   \n",
       "13  -0.573248 -0.329084 -0.075131 -0.751161 -0.379354 -0.507032 -0.380995   \n",
       "14  -0.562630 -0.311164  0.014953 -0.860834 -0.118722 -0.281836 -0.580791   \n",
       "15  -0.384252 -0.280217  0.075741 -0.723302  0.026294 -0.327641 -0.237731   \n",
       "16  -0.322219 -0.451009  0.157744 -0.426568  0.027712 -0.194782 -0.202735   \n",
       "17  -0.559103 -0.461226  0.322271 -0.515065 -0.118187 -0.428195 -0.373750   \n",
       "18  -0.312172 -0.166559  0.300614 -0.404764  0.187709 -0.096079 -0.203769   \n",
       "19  -0.320686 -0.108504  0.279748 -0.324380  0.218616 -0.193110 -0.212544   \n",
       "20  -0.517083 -0.406692  0.300411 -0.400089  0.284891 -0.342362 -0.137779   \n",
       "21  -0.482791 -0.234716  0.437736 -0.392082  0.333748 -0.339846 -0.213267   \n",
       "22  -0.475602 -0.416355  0.360659 -0.462535  0.052153 -0.416984 -0.334816   \n",
       "23  -0.635559 -0.491881  0.184162 -0.572735  0.037157 -0.510533 -0.449865   \n",
       "24  -0.271588 -0.439465  0.365313 -0.400121  0.067378 -0.269158 -0.284778   \n",
       "25  -0.211248 -0.378510  0.194517 -0.389961  0.073132 -0.380239 -0.211511   \n",
       "26  -0.342051 -0.481747  0.309348 -0.583552  0.133725 -0.410639 -0.403472   \n",
       "27   0.041973 -0.270358  0.376254 -0.275744  0.049864 -0.079302 -0.104733   \n",
       "28   0.038738 -0.159562  0.177280 -0.349064  0.046150 -0.359076 -0.205058   \n",
       "29   0.028639 -0.112747  0.338608 -0.258084  0.142223 -0.300052 -0.147134   \n",
       "30   0.211213 -0.117822  0.309307 -0.158914  0.248157 -0.169085  0.019538   \n",
       "31   0.174617  0.036116  0.260319 -0.157878  0.197778 -0.154091 -0.130581   \n",
       "32   0.225087  0.056401  0.306708 -0.082354  0.293728 -0.113810 -0.036196   \n",
       "33   0.179373 -0.110134  0.165194 -0.106065  0.279456 -0.130768 -0.109952   \n",
       "34   0.287473  0.090814  0.266477 -0.035396  0.255170 -0.004970 -0.122286   \n",
       "35   0.424176  0.046147  0.081957  0.010713  0.298345  0.024984  0.058484   \n",
       "36   0.355979  0.047739 -0.069619 -0.014972  0.323072 -0.062918 -0.005171   \n",
       "37   0.430337  0.064957 -0.005062  0.031460  0.157286 -0.035941  0.103056   \n",
       "38   0.409074  0.148424  0.019833  0.000033  0.237264  0.012401  0.259076   \n",
       "39   0.341164  0.040399  0.026388 -0.069507  0.255928  0.016051  0.216605   \n",
       "40   0.322607  0.067965  0.032642  0.018842  0.158856  0.003933  0.263993   \n",
       "41   0.379026  0.033139  0.125646  0.070971  0.206696  0.109154  0.235349   \n",
       "42   0.329382  0.092618  0.105124  0.041289  0.205625  0.095944  0.186710   \n",
       "43   0.303576  0.105697  0.137746  0.097640  0.208945  0.057657  0.165451   \n",
       "44   0.293748  0.113360  0.057237  0.061708  0.173601  0.042053  0.171886   \n",
       "45   0.284208  0.050255  0.056100  0.081830  0.169413  0.043488  0.172752   \n",
       "46   0.230687  0.048758  0.022660  0.023692  0.136932 -0.043261  0.115359   \n",
       "47   0.201395  0.044126 -0.014237 -0.003892  0.200308 -0.033159  0.142090   \n",
       "48   0.249993  0.055655  0.013662  0.038497  0.233475  0.016759  0.167357   \n",
       "49   0.221696 -0.006247 -0.017184 -0.015764  0.113879  0.029433  0.245329   \n",
       "50   0.196866  0.081641  0.024215  0.006399  0.105355  0.107942  0.254527   \n",
       "51   0.285773  0.060179  0.023954  0.054936  0.252552  0.188929  0.245828   \n",
       "52   0.375572  0.154031  0.124358  0.178543  0.310131  0.235696  0.382203   \n",
       "53   0.370433  0.157731  0.126444  0.137863  0.308762  0.245547  0.336693   \n",
       "54   0.341186  0.238077  0.130733  0.200018  0.335982  0.253505  0.394433   \n",
       "55   0.408958  0.331366  0.174192  0.282703  0.327964  0.289032  0.279315   \n",
       "56   0.290888  0.290677  0.082627  0.233947  0.287268  0.215439  0.210495   \n",
       "57   0.250712  0.460041  0.149862  0.227898  0.323962  0.158701  0.215710   \n",
       "58   0.145112  0.394244  0.108885  0.186248  0.247509  0.165225  0.242332   \n",
       "59   0.033179  0.349375  0.185575  0.115958  0.201773  0.085308  0.129568   \n",
       "60  -0.029529  0.255395  0.225215  0.088886  0.264878  0.073793  0.134167   \n",
       "61  -0.125469  0.207267  0.104794 -0.037282  0.240670 -0.030373  0.068005   \n",
       "62  -0.086999  0.209478  0.145357 -0.047605  0.257967 -0.033157  0.057639   \n",
       "63   0.019354  0.254911  0.239617  0.099657  0.341655  0.051687  0.103961   \n",
       "64   0.004533  0.281216  0.213239  0.118544  0.404570 -0.043176  0.124941   \n",
       "65  -0.022723  0.271292  0.247559  0.107527  0.374333  0.029015  0.163585   \n",
       "66   0.147619  0.422885  0.207396  0.146352  0.533854  0.100411  0.262730   \n",
       "67   0.152159  0.297564  0.239999  0.152014  0.473269  0.051872  0.236091   \n",
       "68   0.089185  0.290593  0.218347  0.066858  0.390655  0.048444  0.266986   \n",
       "69   0.083343  0.225649  0.239273  0.002131  0.396628 -0.126036  0.262457   \n",
       "70  -0.032846  0.192564  0.183968 -0.130574  0.329455 -0.225589  0.134100   \n",
       "71  -0.023585  0.090958  0.172126 -0.190911  0.330125 -0.188968  0.096930   \n",
       "72   0.022652  0.079209  0.272709 -0.143354  0.257423 -0.253761  0.179367   \n",
       "73  -0.022401  0.046903  0.260029 -0.174534  0.192489 -0.310312  0.266621   \n",
       "74   0.008244  0.093922  0.338975 -0.170080  0.329439 -0.333262  0.289695   \n",
       "75   0.282278  0.137065  0.308975 -0.003428  0.383065 -0.059154  0.443320   \n",
       "76   0.512826  0.294995  0.282081  0.186450  0.474745 -0.068999  0.735142   \n",
       "77   0.490000  0.314550  0.303369  0.222916  0.559837 -0.011303  0.790401   \n",
       "78   0.538092  0.386183  0.325228  0.235533  0.591923  0.093600  0.857094   \n",
       "79   0.569004  0.522818  0.399519  0.236081  0.759188  0.173672  0.719584   \n",
       "80   0.703598  0.453851  0.410535  0.368355  0.761181  0.256161  0.762041   \n",
       "81   0.440779  0.441820  0.358041  0.237754  0.692157  0.080627  0.730315   \n",
       "82   0.392100  0.376327  0.416131  0.223059  0.701385  0.195049  0.590684   \n",
       "83   0.417487  0.410611  0.315682  0.312024  0.620656  0.139548  0.657768   \n",
       "84   0.325753  0.225126  0.299862  0.225362  0.801622  0.175663  0.635923   \n",
       "85   0.382488  0.233841  0.114435  0.179769  0.688506  0.195393  0.732390   \n",
       "86   0.441292  0.195092  0.206934  0.174265  0.636971  0.203826  0.786574   \n",
       "87   0.371018  0.269659  0.246433  0.188632  0.537165  0.277833  0.690402   \n",
       "88   0.461467  0.218030  0.271698  0.211097  0.602373  0.241022  0.675270   \n",
       "89   0.406320  0.294870  0.259616  0.237245  0.616881  0.231912  0.671559   \n",
       "90   0.393988  0.309444  0.318603  0.176249  0.622346  0.088207  0.594046   \n",
       "91   0.350963  0.348782  0.370016  0.153112  0.555334  0.118780  0.481442   \n",
       "92   0.237506  0.250391  0.259349  0.049693  0.455441 -0.060549  0.371199   \n",
       "93   0.051508  0.203651  0.255447 -0.073614  0.380030 -0.152123  0.250304   \n",
       "94   0.025210  0.192028  0.285711 -0.020737  0.354523 -0.060765  0.291472   \n",
       "95   0.092163  0.118130  0.272827 -0.031728  0.370537 -0.147595  0.174414   \n",
       "96  -0.044548  0.100722  0.291133 -0.044849  0.227723 -0.201317  0.109313   \n",
       "97  -0.086186  0.098764  0.292036 -0.082429  0.312240 -0.231258  0.038634   \n",
       "98  -0.142988 -0.009513  0.318447 -0.137208  0.338985 -0.307182  0.041045   \n",
       "99   0.024965 -0.190352  0.201151  0.000873  0.544686 -0.206904  0.225361   \n",
       "100 -0.027275 -0.182386 -0.010679 -0.230168  0.625192 -0.144453  0.002417   \n",
       "101  0.008765 -0.261586  0.119033 -0.276747  0.524200 -0.055541  0.174991   \n",
       "102 -0.036032 -0.053872  0.146751 -0.362828  0.534544 -0.165869  0.077566   \n",
       "103 -0.065951 -0.388609 -0.047571 -0.454932  0.603498 -0.086522  0.277680   \n",
       "104 -0.190259 -0.233252 -0.203463 -0.656325  0.519796  0.065549  0.320221   \n",
       "105 -0.049288 -0.151794 -0.268851 -0.529287  0.354372  0.194280  0.293981   \n",
       "106 -0.444776 -0.123518 -0.183836 -0.574667  0.415130  0.138655  0.366891   \n",
       "107 -0.386664 -0.020201 -0.340898 -0.658010  0.762235  0.013345  0.303080   \n",
       "108 -0.326641  0.082434 -0.234553 -0.616362  0.614326  0.210649  0.357517   \n",
       "109 -0.266437  0.125179 -0.228199 -0.427602  0.520241  0.121872  0.456544   \n",
       "110 -0.488368 -0.101059 -0.002840 -0.600729  0.418729 -0.024273  0.155786   \n",
       "111 -0.577974 -0.278375 -0.029444 -0.612127  0.378086 -0.156501  0.148460   \n",
       "112 -0.576708 -0.224380 -0.047668 -0.734744  0.402004 -0.149891  0.183223   \n",
       "113 -0.702428 -0.171751 -0.082291 -0.778365  0.407445 -0.117659  0.154086   \n",
       "114 -0.763943 -0.266002 -0.223304 -0.791731  0.539270 -0.160443  0.087258   \n",
       "115 -0.755307 -0.266991 -0.158804 -0.676095  0.587626 -0.070131  0.202960   \n",
       "116 -0.742886 -0.351631 -0.134918 -0.773317  0.610593 -0.103815  0.298418   \n",
       "117 -0.842387 -0.328632 -0.091750 -0.772950  0.440728 -0.103665  0.292448   \n",
       "118 -0.779374 -0.300121 -0.125021 -0.841854  0.473919 -0.232167  0.170210   \n",
       "119 -0.736921 -0.305246 -0.040744 -0.704312  0.579026 -0.160436  0.214529   \n",
       "120 -0.551036 -0.210481  0.045839 -0.563267  0.635207 -0.161909  0.347169   \n",
       "121 -0.531821 -0.233782 -0.030048 -0.678199  0.556513 -0.201806  0.345959   \n",
       "122 -0.559387 -0.291021 -0.012451 -0.636734  0.501226 -0.187773  0.293675   \n",
       "123 -0.486502 -0.359910 -0.129482 -0.592870  0.589176 -0.059108  0.319616   \n",
       "\n",
       "       14954     16582     8497      9372      111961    10247     146669  \\\n",
       "0    0.308864  0.379743  0.263345  0.217624  0.251623  0.272728  0.321540   \n",
       "1    0.240630  0.348939  0.056084  0.097883  0.206605  0.235600  0.209253   \n",
       "2    0.095810  0.289610 -0.013152  0.126501  0.128803  0.042756  0.161213   \n",
       "3    0.167432  0.318652  0.080127  0.071383  0.054716  0.096657  0.195862   \n",
       "4    0.139821  0.289175  0.106451  0.087394  0.075093  0.117162  0.169748   \n",
       "5   -0.019982  0.164529  0.088248  0.023545  0.001334  0.011478  0.068365   \n",
       "6    0.047767  0.278523  0.236458  0.070263  0.122270  0.117528  0.154738   \n",
       "7    0.093556  0.156266  0.139910 -0.016109 -0.039529  0.019016  0.007419   \n",
       "8   -0.195840  0.089234  0.130273 -0.220309 -0.072417 -0.061472 -0.106618   \n",
       "9    0.007549  0.211394  0.082543  0.031185  0.093658  0.134398  0.186392   \n",
       "10   0.059648  0.160644  0.212175  0.030965  0.077540 -0.059546  0.131257   \n",
       "11  -0.274121 -0.084977 -0.069345 -0.142698 -0.273367 -0.102407 -0.178602   \n",
       "12  -0.481110  0.031201  0.114467 -0.240774 -0.359459 -0.227468 -0.297503   \n",
       "13  -0.611857  0.073608 -0.172680 -0.486497 -0.200909 -0.272332 -0.555172   \n",
       "14  -0.720648 -0.182303 -0.255371 -0.535371 -0.208387 -0.470044 -0.516519   \n",
       "15  -0.487260 -0.173630 -0.266871 -0.451418 -0.278086 -0.361810 -0.341219   \n",
       "16  -0.338154 -0.270107 -0.238484 -0.340429 -0.283157 -0.202123 -0.298893   \n",
       "17  -0.600341 -0.205353 -0.101212 -0.379254 -0.440199 -0.595475 -0.531208   \n",
       "18  -0.619645  0.117189  0.262083 -0.273097  0.050328 -0.023427 -0.274098   \n",
       "19  -0.574532  0.149585  0.173695 -0.091008  0.101715  0.068913 -0.428288   \n",
       "20  -0.631191  0.007779 -0.128003 -0.198710 -0.075384 -0.097648 -0.485263   \n",
       "21  -0.470527  0.175283 -0.056798 -0.176943 -0.061528  0.102082 -0.266714   \n",
       "22  -0.329536  0.024499 -0.269844 -0.163587 -0.029979  0.040993 -0.375129   \n",
       "23  -0.608093 -0.166079 -0.326907 -0.185370 -0.182775 -0.076523 -0.526778   \n",
       "24  -0.410558  0.063769 -0.072416  0.034866 -0.090505  0.114643 -0.267714   \n",
       "25  -0.230605  0.121126 -0.010859  0.152335 -0.037542  0.258103 -0.234436   \n",
       "26  -0.400104  0.100304 -0.203570  0.069070 -0.040113  0.152169 -0.208915   \n",
       "27  -0.114602  0.329796 -0.076823  0.351718  0.100807  0.397383 -0.154493   \n",
       "28  -0.024535  0.313252  0.062871  0.492148  0.201741  0.454150  0.032517   \n",
       "29  -0.078189  0.386397 -0.179665  0.456874  0.386352  0.384758  0.179822   \n",
       "30   0.049786  0.410954 -0.060121  0.365966  0.426923  0.283083  0.209684   \n",
       "31  -0.024947  0.365287  0.221679  0.642724  0.372438  0.349408  0.397217   \n",
       "32   0.157970  0.380963  0.143721  0.584024  0.420571  0.373094  0.484658   \n",
       "33   0.066434  0.279491 -0.023118  0.459728  0.269724  0.107173  0.289330   \n",
       "34   0.220513  0.430611  0.244335  0.514055  0.314248  0.217314  0.328544   \n",
       "35   0.231664  0.394620  0.211846  0.597202  0.415737  0.308853  0.460203   \n",
       "36   0.247076  0.510946  0.096031  0.568160  0.372044  0.362033  0.496261   \n",
       "37   0.289299  0.392317  0.124410  0.744387  0.338966  0.456089  0.419231   \n",
       "38   0.253604  0.460769  0.163713  0.615613  0.394064  0.452450  0.361065   \n",
       "39   0.148489  0.447625  0.137347  0.602756  0.269037  0.484370  0.251957   \n",
       "40   0.105154  0.480220  0.232260  0.538695  0.389636  0.363560  0.362057   \n",
       "41   0.188731  0.489340  0.177528  0.471282  0.273236  0.257971  0.386658   \n",
       "42   0.166407  0.498658  0.165218  0.448243  0.192344  0.286764  0.373461   \n",
       "43   0.197670  0.471248  0.139592  0.408264  0.249281  0.219508  0.354515   \n",
       "44   0.182193  0.452540  0.133759  0.412593  0.239884  0.220689  0.313186   \n",
       "45   0.239376  0.504079  0.080412  0.411569  0.244873  0.169905  0.327182   \n",
       "46   0.177633  0.494236  0.052394  0.430148  0.229147  0.168884  0.285890   \n",
       "47   0.092513  0.507334  0.110768  0.370528  0.232400  0.171383  0.293245   \n",
       "48   0.067169  0.434095  0.086706  0.381107  0.277393  0.230720  0.308187   \n",
       "49   0.009404  0.471773  0.117414  0.366033  0.171087  0.196903  0.321292   \n",
       "50   0.052013  0.458768  0.131481  0.323521  0.212170  0.174793  0.252336   \n",
       "51   0.090475  0.504120  0.231210  0.315257  0.327689  0.254919  0.310461   \n",
       "52   0.158414  0.535149  0.291585  0.300139  0.306936  0.233615  0.387824   \n",
       "53   0.256226  0.528512  0.310872  0.361774  0.278536  0.266094  0.353642   \n",
       "54   0.265456  0.549314  0.291106  0.418792  0.236342  0.261263  0.301466   \n",
       "55   0.335115  0.463313  0.197650  0.309958  0.299800  0.277595  0.225826   \n",
       "56   0.300379  0.410943  0.287322  0.255416  0.227572  0.250735  0.199928   \n",
       "57   0.273064  0.442086  0.329525  0.345776  0.211775  0.279763  0.215876   \n",
       "58   0.174949  0.350452  0.222351  0.238772  0.202846  0.278031  0.108695   \n",
       "59   0.140505  0.300043  0.264338  0.242334  0.155369  0.134148  0.061888   \n",
       "60   0.149490  0.257772  0.308963  0.177982  0.183224  0.179977  0.084643   \n",
       "61  -0.002488  0.222583  0.283989  0.086833  0.137723  0.138646  0.074169   \n",
       "62   0.018631  0.218843  0.157408  0.057508  0.023253  0.073618  0.006653   \n",
       "63   0.128481  0.256487  0.262444  0.214216  0.111588  0.164780  0.088459   \n",
       "64   0.116404  0.263123  0.246480  0.210592  0.068523  0.176474  0.038214   \n",
       "65   0.096278  0.350617  0.363182  0.229370  0.093261  0.133573  0.063852   \n",
       "66   0.150257  0.390128  0.442671  0.266943  0.234756  0.246949  0.187679   \n",
       "67   0.135018  0.355663  0.437818  0.304368  0.187621  0.209235  0.127028   \n",
       "68   0.196182  0.308119  0.524469  0.241770  0.139985  0.238607  0.099209   \n",
       "69   0.090530  0.306694  0.415797  0.182399  0.214067  0.182271  0.079623   \n",
       "70   0.046650  0.241180  0.316007  0.158407  0.128242  0.179664 -0.030965   \n",
       "71  -0.071116  0.230175  0.316966  0.135409  0.012168  0.181828 -0.144101   \n",
       "72  -0.004948  0.254156  0.459136  0.245930  0.062210  0.290411 -0.051059   \n",
       "73  -0.056839  0.304380  0.433753  0.223684 -0.026599  0.347986 -0.099427   \n",
       "74   0.066933  0.361100  0.375435  0.268118 -0.011477  0.386209 -0.087392   \n",
       "75   0.342347  0.527526  0.583632  0.386762  0.063460  0.597127  0.026536   \n",
       "76   0.387640  0.689479  0.719612  0.544675  0.216488  0.607238  0.229327   \n",
       "77   0.587333  0.796219  0.644682  0.468712  0.268359  0.691825  0.361905   \n",
       "78   0.701115  0.879994  0.677179  0.640274  0.279345  0.614286  0.297550   \n",
       "79   0.763612  0.918375  0.642244  0.640246  0.412624  0.654167  0.503092   \n",
       "80   0.816562  1.005298  0.765106  0.818629  0.512736  0.825357  0.710951   \n",
       "81   0.673089  0.890134  0.605834  0.718989  0.328779  0.645234  0.546608   \n",
       "82   0.620224  0.852377  0.554346  0.628327  0.319027  0.649689  0.404341   \n",
       "83   0.525459  0.838796  0.564115  0.715795  0.385804  0.613085  0.387778   \n",
       "84   0.479006  0.774473  0.495971  0.602479  0.346684  0.530464  0.455898   \n",
       "85   0.454586  0.725862  0.565967  0.564794  0.266289  0.537763  0.344605   \n",
       "86   0.473486  0.696212  0.431732  0.434208  0.213100  0.389791  0.310553   \n",
       "87   0.411047  0.639858  0.446176  0.427221  0.246992  0.475032  0.283260   \n",
       "88   0.501252  0.678832  0.445015  0.476123  0.215444  0.409835  0.397858   \n",
       "89   0.440173  0.698625  0.486705  0.469019  0.174193  0.467478  0.334513   \n",
       "90   0.413437  0.694443  0.536697  0.451170  0.129794  0.355564  0.358540   \n",
       "91   0.422012  0.700601  0.452701  0.400520  0.218185  0.291692  0.330662   \n",
       "92   0.416701  0.562688  0.364592  0.359092  0.164912  0.314417  0.268178   \n",
       "93   0.240008  0.474700  0.302752  0.229442  0.071875  0.247848  0.173238   \n",
       "94   0.224325  0.462363  0.316547  0.194261  0.070102  0.216808  0.197053   \n",
       "95   0.189858  0.355007  0.280133  0.214297  0.050383  0.162015  0.147456   \n",
       "96   0.171828  0.386234  0.273952  0.203528  0.023796  0.155604  0.177317   \n",
       "97   0.071270  0.287992  0.267050  0.189311  0.005879  0.161658  0.157351   \n",
       "98   0.055862  0.310512  0.200196  0.263520 -0.007282  0.108980  0.076196   \n",
       "99   0.085276  0.446104  0.091031  0.302508 -0.043087  0.133643  0.064855   \n",
       "100  0.112632  0.416698  0.115231  0.337159 -0.236209  0.197708 -0.113051   \n",
       "101 -0.074451  0.541599  0.023166  0.242740 -0.401293  0.267086 -0.058245   \n",
       "102 -0.244372  0.472507 -0.053651 -0.056730 -0.345577  0.316835  0.035797   \n",
       "103 -0.157003  0.544600 -0.108947  0.022642 -0.700718  0.213722  0.042545   \n",
       "104 -0.208204  0.516745 -0.025849 -0.095242 -0.731635  0.249239  0.118760   \n",
       "105 -0.179790  0.393622 -0.284805 -0.019740 -0.652995  0.192709  0.225770   \n",
       "106 -0.053656  0.297031 -0.085684 -0.086127 -0.756597 -0.042751 -0.019225   \n",
       "107 -0.052895  0.287575  0.036543 -0.445590 -0.813945 -0.085499 -0.245741   \n",
       "108 -0.023697  0.256378  0.086838 -0.230365 -0.686484 -0.232435 -0.110533   \n",
       "109  0.021385  0.134513  0.159049 -0.312396 -0.714217 -0.312767 -0.391434   \n",
       "110 -0.069071 -0.118625  0.173190 -0.550500 -0.704629 -0.443806 -0.412356   \n",
       "111 -0.126244 -0.270806  0.139653 -0.554679 -0.727666 -0.627501 -0.564904   \n",
       "112 -0.131635 -0.339942  0.243946 -0.669929 -0.655053 -0.519376 -0.625792   \n",
       "113 -0.171460 -0.407437  0.076026 -0.576082 -0.582552 -0.577036 -0.679779   \n",
       "114 -0.304937 -0.486210  0.067091 -0.597420 -0.690070 -0.499602 -0.787291   \n",
       "115 -0.251829 -0.548908  0.118721 -0.658860 -0.845005 -0.527439 -0.820606   \n",
       "116 -0.201138 -0.421818  0.180291 -0.705692 -0.867095 -0.634764 -0.802399   \n",
       "117 -0.268457 -0.444416  0.046257 -0.817280 -0.923338 -0.633430 -0.791956   \n",
       "118 -0.181790 -0.414545  0.095419 -0.738087 -0.800071 -0.584713 -0.842311   \n",
       "119 -0.283339 -0.326291  0.130536 -0.701800 -0.767109 -0.474682 -0.771208   \n",
       "120 -0.012152 -0.351448  0.230860 -0.511024 -0.684868 -0.503427 -0.668270   \n",
       "121 -0.116704 -0.324819  0.174003 -0.453518 -0.642872 -0.419041 -0.680291   \n",
       "122 -0.111893 -0.323644  0.074169 -0.444773 -0.544543 -0.408209 -0.688172   \n",
       "123 -0.124588 -0.309140  0.079349 -0.459425 -0.502879 -0.379482 -0.751325   \n",
       "\n",
       "       29143     64549     6565      63383     65142     175741    174663  \\\n",
       "0    0.358869  0.277360  0.265544  0.277809  0.289896  0.320668  0.323520   \n",
       "1    0.224642  0.185036  0.172388  0.227713  0.277210  0.271938  0.247293   \n",
       "2    0.113067  0.073122  0.063851  0.079764  0.139080  0.208870  0.161428   \n",
       "3    0.159630  0.051918  0.190569  0.156976  0.109007  0.352991  0.217857   \n",
       "4    0.141135 -0.084092  0.101683  0.089265  0.112456  0.365963  0.126538   \n",
       "5    0.021097 -0.109810 -0.032682  0.045321  0.140841  0.269546  0.064223   \n",
       "6    0.185960 -0.097929  0.077106  0.292083  0.353519  0.369430  0.189685   \n",
       "7    0.188593 -0.058683  0.038524  0.062262  0.363722  0.312214  0.128012   \n",
       "8   -0.135268 -0.073102 -0.241012  0.009123  0.349697 -0.007304 -0.076554   \n",
       "9   -0.003937 -0.026910 -0.026312  0.214065  0.358064  0.329146  0.215607   \n",
       "10  -0.012506 -0.065761 -0.105310  0.224070  0.413903  0.204807  0.146606   \n",
       "11  -0.193331 -0.401381 -0.060041 -0.036428  0.101469  0.173273 -0.283664   \n",
       "12  -0.325283 -0.396153 -0.190282 -0.115896 -0.071274  0.028402 -0.253241   \n",
       "13  -0.434007 -0.404185 -0.270488 -0.142555 -0.226011 -0.058979 -0.459488   \n",
       "14  -0.599964 -0.445595 -0.605811 -0.300207 -0.387447 -0.232115 -0.531548   \n",
       "15  -0.391964 -0.353001 -0.266106 -0.051790 -0.080152  0.097663 -0.665680   \n",
       "16  -0.296774 -0.444393 -0.434338 -0.157869 -0.092879 -0.077929 -0.573161   \n",
       "17  -0.610333 -0.342577 -0.398561 -0.178419 -0.277926 -0.230459 -0.648294   \n",
       "18  -0.450924 -0.399095  0.054326  0.201704 -0.105383 -0.024619 -0.056391   \n",
       "19  -0.371383 -0.292584  0.177370 -0.064540 -0.053942  0.148540  0.157017   \n",
       "20  -0.595111 -0.496723 -0.175718 -0.196086 -0.286914 -0.280693 -0.206552   \n",
       "21  -0.437182 -0.441155  0.038610 -0.220798 -0.257072 -0.039743 -0.244916   \n",
       "22  -0.314224 -0.626615 -0.143426 -0.306423 -0.355609 -0.396656 -0.330061   \n",
       "23  -0.355133 -0.621783 -0.255630 -0.442908 -0.226397 -0.431213 -0.524664   \n",
       "24  -0.185482 -0.490071 -0.078362 -0.286852 -0.099757 -0.205380 -0.372149   \n",
       "25  -0.119028 -0.467909  0.050196 -0.364634 -0.152790 -0.299874 -0.381079   \n",
       "26  -0.189361 -0.549816 -0.216873 -0.539123 -0.266901 -0.309148 -0.355715   \n",
       "27  -0.010883 -0.352991  0.067412 -0.219556 -0.112376  0.038722 -0.346731   \n",
       "28   0.211554 -0.120089  0.177500 -0.304272 -0.003808  0.311292 -0.244720   \n",
       "29   0.085938 -0.151383  0.097019 -0.286963 -0.120168  0.165053 -0.185007   \n",
       "30   0.135950 -0.002342  0.318931 -0.043615 -0.047313  0.205492 -0.107308   \n",
       "31   0.343638  0.015797  0.465856 -0.053840  0.080165  0.348362 -0.158535   \n",
       "32   0.305217  0.052367  0.314115 -0.157641  0.102845  0.227820  0.084413   \n",
       "33   0.347107  0.128389  0.210550 -0.184585 -0.189992  0.227775 -0.033463   \n",
       "34   0.410128  0.350625  0.259685 -0.004973  0.118126  0.366862 -0.066923   \n",
       "35   0.457386  0.340760  0.346815 -0.088053  0.213479  0.370100 -0.015575   \n",
       "36   0.441086  0.264223  0.335482 -0.098146  0.261060  0.412097  0.073054   \n",
       "37   0.340379  0.319811  0.364292  0.040145  0.305408  0.414928  0.038359   \n",
       "38   0.451790  0.289278  0.190578  0.097270  0.321604  0.452046  0.145693   \n",
       "39   0.421395  0.208098  0.134623  0.026831  0.316499  0.336899  0.132352   \n",
       "40   0.407438  0.229459  0.198096  0.120689  0.387715  0.395746  0.049767   \n",
       "41   0.431168  0.103530  0.216883  0.088554  0.380187  0.355356  0.110359   \n",
       "42   0.420693  0.081491  0.200712  0.062363  0.380636  0.357319  0.085180   \n",
       "43   0.433607  0.134113  0.145181  0.089435  0.383921  0.352445  0.055227   \n",
       "44   0.418158  0.148771  0.199931  0.043461  0.390295  0.324970  0.032385   \n",
       "45   0.334231  0.182687  0.194583  0.001998  0.399819  0.368820  0.113439   \n",
       "46   0.263396  0.242414  0.127577  0.059169  0.420136  0.324292  0.148288   \n",
       "47   0.186796  0.263650  0.039759  0.079609  0.395107  0.373424  0.098621   \n",
       "48   0.281288  0.317997  0.033508  0.160698  0.382458  0.314506  0.100389   \n",
       "49   0.177392  0.309079  0.063994  0.113432  0.421381  0.304008  0.103211   \n",
       "50   0.213773  0.259620  0.063328  0.160012  0.434600  0.332082  0.144982   \n",
       "51   0.249123  0.299194  0.160446  0.171107  0.526446  0.335213  0.122867   \n",
       "52   0.336902  0.365228  0.288760  0.162496  0.557444  0.334231  0.171958   \n",
       "53   0.416935  0.340497  0.447963  0.150187  0.563931  0.342123  0.221887   \n",
       "54   0.430224  0.303516  0.397720  0.146011  0.596045  0.487866  0.302082   \n",
       "55   0.388211  0.286810  0.370077  0.131925  0.558233  0.440850  0.308253   \n",
       "56   0.347175  0.299826  0.290260  0.113288  0.587581  0.354855  0.230133   \n",
       "57   0.376295  0.280615  0.288543  0.144858  0.630674  0.332793  0.269440   \n",
       "58   0.285174  0.223685  0.200029  0.144796  0.521038  0.295552  0.199654   \n",
       "59   0.238945  0.171509  0.140265  0.127287  0.442055  0.222594  0.202178   \n",
       "60   0.194117  0.243351  0.106597  0.072277  0.494721  0.160748  0.185416   \n",
       "61   0.131306  0.219903  0.053484  0.140162  0.342467  0.063399  0.102892   \n",
       "62   0.194284  0.108746  0.090615  0.147209  0.290271  0.029376  0.115819   \n",
       "63   0.336669  0.119875  0.164258  0.189784  0.342112  0.087548  0.180645   \n",
       "64   0.305004  0.173971  0.230083  0.180036  0.395705  0.094982  0.132554   \n",
       "65   0.277432  0.157316  0.230695  0.266239  0.479107  0.133082  0.159430   \n",
       "66   0.440953  0.263325  0.313323  0.342350  0.593628  0.254613  0.202466   \n",
       "67   0.454831  0.314650  0.238989  0.297532  0.583372  0.162772  0.269670   \n",
       "68   0.392879  0.288608  0.247603  0.327748  0.647989  0.104407  0.204441   \n",
       "69   0.223022  0.162925  0.284192  0.210192  0.685010  0.156286  0.127775   \n",
       "70   0.137689  0.117759  0.239213  0.109727  0.535766  0.041367  0.161521   \n",
       "71   0.057542  0.088797 -0.008297  0.097756  0.490016 -0.064452  0.028102   \n",
       "72   0.155376  0.081191  0.111885  0.055379  0.612643  0.047436  0.071143   \n",
       "73   0.093606 -0.018608  0.129297  0.053738  0.669140  0.030576  0.098062   \n",
       "74   0.154548 -0.048739  0.183692  0.108284  0.686909  0.120299  0.005181   \n",
       "75   0.491686  0.227154  0.359230  0.263846  0.826286  0.169168  0.149575   \n",
       "76   0.652452  0.275465  0.418086  0.351705  0.962605  0.159046  0.160367   \n",
       "77   0.774292  0.445634  0.595381  0.407728  1.004600  0.267915  0.274232   \n",
       "78   0.708833  0.515985  0.520283  0.427728  0.968420  0.261640  0.301907   \n",
       "79   0.830205  0.499130  0.653146  0.460253  0.958566  0.441767  0.315008   \n",
       "80   0.759335  0.611559  0.574051  0.510731  0.986930  0.528847  0.471746   \n",
       "81   0.700410  0.466780  0.560387  0.446124  0.855859  0.486068  0.369748   \n",
       "82   0.628599  0.430781  0.436330  0.509544  0.770945  0.426720  0.376018   \n",
       "83   0.567778  0.379748  0.476731  0.458707  0.830171  0.366391  0.409321   \n",
       "84   0.495429  0.329238  0.389939  0.416809  0.767649  0.264276  0.380364   \n",
       "85   0.437050  0.339358  0.380534  0.484948  0.800331  0.317920  0.318146   \n",
       "86   0.501191  0.239298  0.302096  0.398948  0.741906  0.164693  0.266430   \n",
       "87   0.488303  0.197887  0.267703  0.434198  0.799074  0.120420  0.291477   \n",
       "88   0.458661  0.101124  0.355529  0.376020  0.732055  0.149704  0.275623   \n",
       "89   0.524454  0.188625  0.352918  0.428654  0.711913  0.216036  0.277792   \n",
       "90   0.485911  0.108507  0.329572  0.352682  0.680823  0.214842  0.290159   \n",
       "91   0.498740  0.076782  0.299411  0.271141  0.709878  0.265979  0.287702   \n",
       "92   0.416097  0.074257  0.331707  0.239158  0.675755  0.212378  0.223534   \n",
       "93   0.309547  0.005452  0.240642  0.192954  0.561260  0.081849  0.126164   \n",
       "94   0.297638 -0.024240  0.143186  0.256078  0.457041  0.123057  0.014268   \n",
       "95   0.365207  0.016919  0.174602  0.251988  0.360759  0.056107  0.044573   \n",
       "96   0.316193  0.026790  0.155601  0.232943  0.393921  0.030396  0.086588   \n",
       "97   0.255592 -0.093921  0.098810  0.270332  0.210935 -0.057574 -0.012216   \n",
       "98   0.321808 -0.106703  0.120518  0.272473  0.271469  0.001243 -0.032903   \n",
       "99   0.443285 -0.139177 -0.060163  0.330560  0.410834  0.103810 -0.106102   \n",
       "100  0.276426 -0.049549  0.024321  0.287705  0.518452  0.206914 -0.026250   \n",
       "101  0.198074 -0.311093 -0.106978  0.271346  0.446020  0.158273 -0.367698   \n",
       "102  0.177404 -0.275494 -0.162467  0.306875  0.427603 -0.066818 -0.514406   \n",
       "103  0.251403 -0.210076 -0.234225  0.468969  0.561245 -0.038268 -0.483473   \n",
       "104 -0.046350 -0.416500 -0.037427  0.396160  0.605872  0.133646 -0.361435   \n",
       "105 -0.039570 -0.189487  0.182260  0.352576  0.474021  0.333918 -0.219099   \n",
       "106 -0.088461 -0.031695 -0.117137  0.365448  0.332235 -0.019133  0.195405   \n",
       "107 -0.021320 -0.191700 -0.052647  0.394315  0.365636 -0.044337  0.039991   \n",
       "108  0.010782 -0.333180  0.090505  0.355061  0.512118 -0.055713  0.341199   \n",
       "109  0.031446 -0.427699  0.145654  0.237173  0.509993 -0.125646 -0.009774   \n",
       "110 -0.014157 -0.518234 -0.167985  0.112004  0.150521 -0.226835 -0.060699   \n",
       "111  0.073504 -0.373302 -0.284249  0.232145 -0.026649 -0.336666 -0.278033   \n",
       "112  0.067903 -0.419841 -0.349145  0.267589 -0.070433 -0.405777 -0.323521   \n",
       "113  0.044525 -0.638243 -0.328388  0.260935 -0.078059 -0.540825 -0.336686   \n",
       "114  0.028274 -0.695797 -0.342201  0.280080 -0.006830 -0.597909 -0.454566   \n",
       "115  0.093894 -0.613468 -0.302810  0.313496  0.038458 -0.600131 -0.393005   \n",
       "116  0.081335 -0.616396 -0.342446  0.317960  0.060715 -0.786776 -0.385327   \n",
       "117 -0.073334 -0.713670 -0.217366  0.139070 -0.013281 -0.878374 -0.389149   \n",
       "118 -0.106323 -0.620078 -0.256496  0.177221 -0.152958 -0.939001 -0.393399   \n",
       "119 -0.004712 -0.514406 -0.317304  0.295629 -0.118049 -0.744159 -0.357294   \n",
       "120  0.202825 -0.474791 -0.284406  0.316892 -0.058361 -0.698515 -0.294348   \n",
       "121  0.285923 -0.548898 -0.181670  0.219728  0.053468 -0.604663 -0.268753   \n",
       "122  0.205244 -0.569174 -0.297261  0.244742  0.081630 -0.539149 -0.290233   \n",
       "123  0.229921 -0.531423 -0.283877  0.257376  0.122964 -0.489059 -0.379075   \n",
       "\n",
       "       10420     28317     176343    5977      27119     12304     3813    \\\n",
       "0    0.282735  0.239620  0.207744  0.372803  0.330268  0.286602  0.276973   \n",
       "1    0.216092  0.222373  0.274162  0.357947  0.220470  0.170743  0.174281   \n",
       "2    0.112787  0.222864  0.035919  0.247249  0.021399  0.147159  0.100773   \n",
       "3    0.109674  0.337363  0.136518  0.228692  0.079239  0.150963  0.194843   \n",
       "4    0.122090  0.276541  0.191310  0.177421  0.020299  0.030568  0.199866   \n",
       "5   -0.035656  0.246404  0.032535  0.044332 -0.124832  0.029706 -0.002131   \n",
       "6    0.005874  0.318495  0.101868  0.226494  0.062536  0.286916  0.078775   \n",
       "7   -0.007997  0.350361  0.012420  0.187150  0.025412  0.268333  0.119426   \n",
       "8   -0.148497  0.251708 -0.096017 -0.002080 -0.008839  0.105078 -0.099958   \n",
       "9    0.166750  0.509753  0.021276  0.151219  0.138169  0.274923  0.211489   \n",
       "10   0.195828  0.543502 -0.065858 -0.042332 -0.016582  0.137951  0.072579   \n",
       "11  -0.088006  0.130056 -0.350578 -0.484415 -0.329986  0.235003 -0.114855   \n",
       "12  -0.123871 -0.097177 -0.509481 -0.543864 -0.299990 -0.071562 -0.217935   \n",
       "13  -0.310817  0.052909 -0.368690 -0.709470 -0.441586 -0.086878 -0.312617   \n",
       "14  -0.353836 -0.008093 -0.726058 -0.704853 -0.477034 -0.309188 -0.395085   \n",
       "15  -0.040810  0.176289 -0.474043 -0.539643 -0.621413 -0.076252 -0.205322   \n",
       "16   0.291723  0.217401 -0.670375 -0.382362 -0.412916 -0.274443  0.078820   \n",
       "17   0.226803  0.108789 -0.834684 -0.583402 -0.502980 -0.272357  0.025125   \n",
       "18   0.222617  0.395175 -0.448804 -0.087718 -0.119534 -0.152898  0.213055   \n",
       "19   0.454961  0.588418 -0.061545 -0.003374 -0.299626 -0.020425  0.331586   \n",
       "20   0.168341  0.322726 -0.382836 -0.223809 -0.277988 -0.253766  0.118273   \n",
       "21   0.378590  0.383700 -0.270207 -0.151587 -0.066642 -0.143735  0.087526   \n",
       "22   0.317393  0.289593 -0.304699 -0.357932 -0.115106 -0.355575  0.007658   \n",
       "23   0.064248  0.085154 -0.579398 -0.410483 -0.208944 -0.376097 -0.177956   \n",
       "24   0.236946  0.259790 -0.374144 -0.172638 -0.112593 -0.197375 -0.113204   \n",
       "25   0.325032  0.431922 -0.262184 -0.155832 -0.047852 -0.276972 -0.042246   \n",
       "26   0.232469  0.278947 -0.522542 -0.287117 -0.053359 -0.184592 -0.037816   \n",
       "27   0.511480  0.180097 -0.207570 -0.050917  0.049245  0.019841  0.057573   \n",
       "28   0.345253  0.214391  0.094602 -0.077869 -0.082630  0.073468 -0.121854   \n",
       "29   0.519966  0.321931 -0.138413 -0.137511 -0.066904  0.235733  0.049317   \n",
       "30   0.526907  0.405029  0.055953  0.136046  0.169276  0.259972  0.248659   \n",
       "31   0.505134  0.492937  0.066431  0.105676  0.155362  0.285251  0.209752   \n",
       "32   0.605071  0.520939  0.138616  0.062120  0.193460  0.148404  0.200188   \n",
       "33   0.425279  0.324358  0.008245  0.061004  0.091690  0.134124  0.176470   \n",
       "34   0.613744  0.541150  0.124177  0.055244  0.095457  0.195924  0.226630   \n",
       "35   0.525821  0.441318  0.308818  0.059176  0.147086  0.274574  0.239855   \n",
       "36   0.515420  0.357288  0.373923  0.135309  0.162839  0.215694  0.388545   \n",
       "37   0.591661  0.291189  0.182949  0.156419  0.155681  0.331382  0.268293   \n",
       "38   0.459985  0.302819  0.323507  0.111646  0.133428  0.202715  0.295044   \n",
       "39   0.452461  0.357539  0.219454  0.098929  0.096777  0.239592  0.317615   \n",
       "40   0.459271  0.351551  0.158860  0.169331  0.109532  0.315321  0.392553   \n",
       "41   0.398311  0.337611  0.189862  0.163930  0.090570  0.320674  0.350196   \n",
       "42   0.389249  0.322706  0.130184  0.138095  0.085868  0.333378  0.295501   \n",
       "43   0.375311  0.330913  0.124402  0.146491  0.038983  0.332657  0.309353   \n",
       "44   0.379635  0.275494  0.121216  0.149566  0.090764  0.315061  0.292397   \n",
       "45   0.342897  0.242929  0.205391  0.238798  0.091846  0.385289  0.277086   \n",
       "46   0.304514  0.144105  0.150762  0.172026  0.101500  0.358612  0.182199   \n",
       "47   0.239575  0.175225  0.200428  0.142512  0.101472  0.367649  0.222477   \n",
       "48   0.249284  0.190628  0.179180  0.155891  0.105653  0.396334  0.204329   \n",
       "49   0.220820  0.122105  0.111107  0.106830  0.165300  0.365275  0.154413   \n",
       "50   0.236338  0.165760  0.132539  0.129653  0.070452  0.361894  0.088078   \n",
       "51   0.240305  0.295851  0.114652  0.090671  0.133932  0.372435  0.149286   \n",
       "52   0.290277  0.320856  0.050322  0.217549  0.172532  0.398218  0.285946   \n",
       "53   0.347931  0.364419  0.165338  0.237702  0.297385  0.350518  0.254859   \n",
       "54   0.327899  0.399695  0.158884  0.228272  0.356598  0.441077  0.355779   \n",
       "55   0.314409  0.445771  0.205412  0.291074  0.298172  0.421801  0.406623   \n",
       "56   0.195467  0.440810  0.183517  0.270408  0.326170  0.382697  0.411252   \n",
       "57   0.262164  0.459170  0.245837  0.211193  0.406526  0.381470  0.439900   \n",
       "58   0.191035  0.469922  0.213282  0.166313  0.382094  0.367091  0.418988   \n",
       "59   0.149365  0.437307  0.107946  0.189552  0.362703  0.287359  0.313995   \n",
       "60   0.188051  0.421227  0.087421  0.180820  0.300380  0.270700  0.262940   \n",
       "61   0.127435  0.304167 -0.004300  0.072074  0.323523  0.207387  0.223379   \n",
       "62   0.168009  0.341543  0.029361  0.094539  0.313866  0.223267  0.250968   \n",
       "63   0.249203  0.409597  0.054733  0.200423  0.418050  0.344322  0.321840   \n",
       "64   0.267557  0.405589  0.060526  0.156964  0.400036  0.307537  0.402769   \n",
       "65   0.302525  0.470409  0.054221  0.205163  0.486732  0.371827  0.348605   \n",
       "66   0.324053  0.551838  0.177812  0.307054  0.570551  0.412120  0.477947   \n",
       "67   0.279823  0.579756  0.123660  0.234813  0.516528  0.477458  0.457738   \n",
       "68   0.285627  0.566049  0.147020  0.244477  0.515074  0.439262  0.349563   \n",
       "69   0.148779  0.494828  0.141004  0.223620  0.456602  0.440597  0.398329   \n",
       "70   0.171382  0.516808  0.014412  0.043070  0.495604  0.329570  0.336816   \n",
       "71  -0.037702  0.396132  0.012434  0.054706  0.326202  0.209781  0.323230   \n",
       "72  -0.017917  0.526589  0.048834  0.049331  0.306036  0.321707  0.326683   \n",
       "73  -0.040896  0.525648  0.137194 -0.028719  0.502395  0.376029  0.401021   \n",
       "74  -0.006110  0.630140 -0.033322  0.070278  0.547994  0.474078  0.501910   \n",
       "75   0.161518  0.787915  0.035719  0.187524  0.740466  0.563273  0.624715   \n",
       "76   0.109876  0.757280  0.175538  0.383550  0.710439  0.728924  0.703565   \n",
       "77   0.323047  0.990006  0.135232  0.433452  0.936919  0.776300  0.927966   \n",
       "78   0.384475  0.987429  0.233392  0.546356  1.029085  0.732486  1.018149   \n",
       "79   0.434391  1.038088  0.273456  0.623992  0.926662  0.698786  1.092783   \n",
       "80   0.420347  1.011146  0.419572  0.584572  0.964626  0.811801  1.093010   \n",
       "81   0.338829  0.866177  0.424892  0.546112  0.808299  0.777177  1.015281   \n",
       "82   0.298030  0.840045  0.341176  0.506241  0.829947  0.684722  0.937854   \n",
       "83   0.350690  0.823635  0.417902  0.633355  0.758615  0.739372  0.859858   \n",
       "84   0.294030  0.803909  0.324134  0.550633  0.671626  0.649428  0.782275   \n",
       "85   0.307008  0.763605  0.259671  0.524743  0.720530  0.693355  0.771372   \n",
       "86   0.206162  0.716022  0.216543  0.432954  0.675316  0.591173  0.757972   \n",
       "87   0.264606  0.761676  0.247811  0.426517  0.680524  0.561686  0.770253   \n",
       "88   0.240235  0.800615  0.259055  0.474554  0.635406  0.607779  0.737868   \n",
       "89   0.245780  0.787603  0.254591  0.573000  0.656272  0.579869  0.755292   \n",
       "90   0.194525  0.725700  0.197261  0.500395  0.694344  0.632177  0.775630   \n",
       "91   0.207082  0.726032  0.245248  0.522224  0.644992  0.560725  0.723855   \n",
       "92   0.162234  0.642820  0.239308  0.419174  0.563699  0.554169  0.617220   \n",
       "93   0.168853  0.567697  0.111853  0.218152  0.441338  0.422142  0.487484   \n",
       "94   0.165559  0.567223  0.124337  0.181877  0.460207  0.390053  0.588141   \n",
       "95   0.157755  0.524977 -0.009340  0.141392  0.395773  0.337668  0.590919   \n",
       "96   0.147113  0.500501  0.008648  0.041157  0.319795  0.329312  0.568579   \n",
       "97   0.221432  0.405606 -0.022907  0.071924  0.339529  0.226669  0.536224   \n",
       "98   0.181681  0.333695 -0.038551  0.128170  0.385173  0.302241  0.480900   \n",
       "99   0.133906  0.202660 -0.050767  0.128843  0.367465  0.299734  0.501948   \n",
       "100  0.175636  0.208941 -0.126529 -0.121008  0.402500  0.230546  0.353292   \n",
       "101  0.256410  0.194983 -0.126364 -0.132619  0.444136  0.348525  0.421028   \n",
       "102  0.125824  0.116657 -0.333242 -0.068800  0.486677  0.377819  0.608305   \n",
       "103  0.001576  0.102490 -0.416520 -0.122304  0.231484  0.441285  0.611524   \n",
       "104  0.140897  0.028180 -0.331623  0.061601  0.136862  0.152212  0.321760   \n",
       "105  0.039660  0.115842 -0.444859  0.085213  0.174879  0.371092  0.489644   \n",
       "106 -0.135127  0.241389 -0.368135 -0.140788 -0.052181  0.243826  0.377674   \n",
       "107 -0.450840  0.296177 -0.232529 -0.237388 -0.224103  0.367801  0.413194   \n",
       "108 -0.398345  0.702751 -0.173656 -0.217061  0.026488  0.281158  0.398930   \n",
       "109 -0.194873  0.560392 -0.219471 -0.364147  0.021825  0.213372  0.497666   \n",
       "110 -0.297972  0.541164 -0.393991 -0.378160  0.133846  0.250690  0.459112   \n",
       "111 -0.343210  0.353283 -0.414424 -0.530677 -0.116641  0.128181  0.485628   \n",
       "112 -0.291451  0.359641 -0.354754 -0.572186 -0.115395  0.053713  0.525728   \n",
       "113 -0.159033  0.321065 -0.312229 -0.562511 -0.114711  0.018710  0.435935   \n",
       "114 -0.214784  0.302136 -0.333198 -0.632531 -0.038848 -0.014516  0.406933   \n",
       "115 -0.155445  0.410641 -0.516826 -0.566514 -0.003146  0.102523  0.554587   \n",
       "116 -0.203725  0.470720 -0.591181 -0.584455  0.035867  0.029073  0.482117   \n",
       "117 -0.257492  0.321313 -0.541157 -0.603567 -0.049870 -0.080363  0.473612   \n",
       "118 -0.208871  0.340961 -0.559236 -0.654208 -0.034792 -0.188890  0.401005   \n",
       "119 -0.243140  0.395433 -0.392658 -0.607326 -0.028940 -0.110241  0.514913   \n",
       "120 -0.252675  0.419809 -0.374266 -0.441263 -0.009475 -0.083454  0.533952   \n",
       "121 -0.238110  0.463199 -0.303060 -0.367823  0.058702 -0.077745  0.568030   \n",
       "122 -0.103130  0.359859 -0.374461 -0.425712  0.140540  0.024348  0.478197   \n",
       "123 -0.187222  0.409063 -0.348206 -0.431151  0.060036  0.014313  0.491447   \n",
       "\n",
       "       162198  \n",
       "0    0.357234  \n",
       "1    0.243080  \n",
       "2    0.243362  \n",
       "3    0.241494  \n",
       "4    0.235520  \n",
       "5    0.141588  \n",
       "6    0.296743  \n",
       "7    0.245892  \n",
       "8    0.046074  \n",
       "9    0.190111  \n",
       "10   0.110238  \n",
       "11  -0.167627  \n",
       "12  -0.069784  \n",
       "13  -0.176702  \n",
       "14  -0.387250  \n",
       "15  -0.397105  \n",
       "16  -0.317417  \n",
       "17  -0.376921  \n",
       "18  -0.123759  \n",
       "19  -0.060002  \n",
       "20  -0.277574  \n",
       "21  -0.339020  \n",
       "22  -0.408648  \n",
       "23  -0.342394  \n",
       "24  -0.248433  \n",
       "25  -0.118993  \n",
       "26  -0.183753  \n",
       "27  -0.105378  \n",
       "28  -0.016229  \n",
       "29  -0.015027  \n",
       "30   0.173399  \n",
       "31   0.269499  \n",
       "32   0.147639  \n",
       "33   0.035072  \n",
       "34   0.096350  \n",
       "35   0.042991  \n",
       "36   0.213212  \n",
       "37   0.191701  \n",
       "38   0.254788  \n",
       "39   0.233233  \n",
       "40   0.314569  \n",
       "41   0.263606  \n",
       "42   0.237679  \n",
       "43   0.249582  \n",
       "44   0.227926  \n",
       "45   0.233666  \n",
       "46   0.124255  \n",
       "47   0.084796  \n",
       "48   0.106827  \n",
       "49   0.130489  \n",
       "50   0.158419  \n",
       "51   0.300656  \n",
       "52   0.359922  \n",
       "53   0.399992  \n",
       "54   0.362212  \n",
       "55   0.316919  \n",
       "56   0.278949  \n",
       "57   0.330482  \n",
       "58   0.278142  \n",
       "59   0.250811  \n",
       "60   0.249680  \n",
       "61   0.213712  \n",
       "62   0.105096  \n",
       "63   0.215147  \n",
       "64   0.259276  \n",
       "65   0.306989  \n",
       "66   0.423327  \n",
       "67   0.410230  \n",
       "68   0.406612  \n",
       "69   0.347064  \n",
       "70   0.294753  \n",
       "71   0.149619  \n",
       "72   0.165981  \n",
       "73   0.214729  \n",
       "74   0.262495  \n",
       "75   0.476326  \n",
       "76   0.549702  \n",
       "77   0.688747  \n",
       "78   0.672520  \n",
       "79   0.727346  \n",
       "80   0.647061  \n",
       "81   0.613944  \n",
       "82   0.541729  \n",
       "83   0.502252  \n",
       "84   0.445027  \n",
       "85   0.402620  \n",
       "86   0.457521  \n",
       "87   0.413503  \n",
       "88   0.424015  \n",
       "89   0.518833  \n",
       "90   0.449919  \n",
       "91   0.487993  \n",
       "92   0.334042  \n",
       "93   0.243624  \n",
       "94   0.222799  \n",
       "95   0.209613  \n",
       "96   0.225634  \n",
       "97   0.214722  \n",
       "98   0.216345  \n",
       "99   0.172506  \n",
       "100  0.042312  \n",
       "101  0.051965  \n",
       "102  0.006897  \n",
       "103 -0.067771  \n",
       "104 -0.179830  \n",
       "105 -0.120232  \n",
       "106 -0.309708  \n",
       "107 -0.258929  \n",
       "108 -0.257243  \n",
       "109 -0.396594  \n",
       "110 -0.385848  \n",
       "111 -0.508580  \n",
       "112 -0.455838  \n",
       "113 -0.630411  \n",
       "114 -0.575018  \n",
       "115 -0.448823  \n",
       "116 -0.540381  \n",
       "117 -0.593178  \n",
       "118 -0.625489  \n",
       "119 -0.593211  \n",
       "120 -0.509425  \n",
       "121 -0.468180  \n",
       "122 -0.546414  \n",
       "123 -0.407211  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame.from_dict(gvkey_dict)\n",
    "display(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm = LinearRegression()\n",
    "# lm.fit(X_train, Y_train)\n",
    "# pred_train = lm.predict(X_train)\n",
    "# Y_pred = lm.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
